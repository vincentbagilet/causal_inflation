---
title: "Simulations IV"
description: "In this document, we run a simulation exercise to illustrate how using an Instrumental Variable (IV) strategy to avoid confounders may create type M error."
author:
  - name: Vincent Bagilet 
    url: https://vincentbagilet.github.io/
    affiliation: Columbia University
    affiliation_url: https://www.columbia.edu/
  - name: Léo Zabrocki 
    url: https://www.parisschoolofeconomics.eu/en/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/en/
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
editor_options: 
  chunk_output_type: console
---

<style>
body {
text-align: justify}
</style>

```{r setup_IV, echo=FALSE, results='hide', warning=FALSE}
library(knitr)
opts_chunk$set(fig.path = "images/",
               cache.path = "cache/",
               cache = FALSE,
               echo = TRUE, #set to false to hide code
               message = FALSE,
               warning = FALSE,
               out.width = "85%",
               dpi = 300,
               fig.align = "center",
               dev.args = list(bg="transparent"))  
```  

```{r packages_IV, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse) 
library(knitr) 
library(mediocrethemes)
library(broom)
library(AER)
library(tictoc)
library(here)
library(beepr)
library(ggridges)

set_mediocre_all(pal = "coty")
```

## Summary and intuition

In the case of the IV, the confounding/type M trade-off is  mediated by the 'strength' of the instrument considered. When the instrument does not explain a lot of the variation in the explanatory variable, the IV can still be successful in avoiding confounders but the power can low, potentially leading to high rates of type M error. 

## An illustrative example

For readability and to illustrate this loss in power, we consider an example setting. For this illustration we could consider  a large variety of distribution parameter for the variables. We narrow this down to an example setting, considering an analysis of the impact of voter turnout on election results, instrumenting voter turnout with rainfall on the day of the election. Our point should stand in more general settings and the choice of values is mostly for illustration. 

A threat of confounders often arises when analyzing the link between voter turnout and election results. To estimate such an effect causally, one can consider exogeneous shocks to voter turnout such as rainfall. Some potential exclusion restriction problems [have been highlighted](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3715610) in this instance but we abstract from them and simulate no exclusion restriction violations here.

### Modeling choices

For simplicity, we consider several assumptions. These assumptions is not representative of the existing literature but the objective is only to calibrate our simulation with somehow realistic parameter values. Again, this illustration is very simplistic. The high level assumptions are:

- We abstract from the panel dimension in this analysis and consider only one time period. This is could be considered as looking at the outcomes of a unique election.
- We only consider the impact of rain on the day of the election.
- We assume no correlation in rainfall between locations. This could be equivalent to considering only a set of remote locations.
- We assume simplify the data generating process and thus do not add any exclusion restriction violations.

The DGP can be represented using the following Directed Acyclic Graph (DAG): 

```{r DAG_RDD, echo=FALSE, out.width='70%'}
include_graphics(here("images/DAG_IV.png"))
```

The DGP for the vote share of let's say the republican party in location $i$, $Share_i$, is defined as follows:

$$Share_{i} = \alpha + \beta Turnout_{i} + \delta u_{i} + e^{(S)}_{i}$$

Where $\alpha$ is a constant, $u$ represents an unobserved variable and $e^{(S)} \sim \mathcal{N}(0, \sigma_{e_S})$ noise. $\beta$ is the parameter of interest. We call it 'treatment effect'.

The DGP for the turnout data is as follows: 

$$Turnout_{i} = \gamma + \lambda Rain_{i} + \eta u_{i} + e^{(T)}_{i}$$

Where $\mu$ is a constant, $Rain$ is either a continuous variable (amount of rain in location $i$ on the day of the election) or a dummy variable (whether it rained or not) and $e^{(T)} \sim \mathcal{N}(0, \sigma_{e_T})$ noise. We refer to $\lambda$ as "IV strength".

The impact on voter turnout on election outcome (share of the republican party) is estimated using 2 Stages Least Squares.

More precisely, we set: 

- $N$ the number of observations
- $Rain \sim \text{Gamma}(k, \theta)$, $Rain \sim \mathcal{N}(0, \sigma_{R}^{2})$ or $Rain \sim \text{Bernoulli}(p_R)$ the instrument
- $u \sim \mathcal{N}(0, \sigma_{u}^{2})$ the unobserved variable
- $e^{(S)} \sim \mathcal{N}(0, \sigma_{e_S}^{2})$
- $e^{(T)} \sim \mathcal{N}(0, \sigma_{e_T}^{2})$
- We assume that $\delta = -\eta$ for simplicity. There is no actual basis for that and we may change that in the future. The opposite sign is just to get an upward bias, which makes the comparison between OLS and IV easier since the bias and type M go in the same direction.

If one abstract from the name of the variable, they can notice that this setting is actually very general.

### Data generation

We write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis. 

Note that the parameter `type_rain` describes whether $Rain$ is a random sample from a normal or Bernoulli distribution. The distributions of rainfall heights can be approximated with a gamma distribution. The Bernoulli distribution is used if one only consider the impact of rain or no rain on voter turnout. A normal distribution does not represent actual rainfall distributions but is added to run these simulations in other contexts than linking rainfall, voter turnout and election outcomes.

`type_rain` can take the values `gamma`, `bernoulli` or `normal`. `param_rain` represents either $\sigma_R$ if $Rain$ is normal, $p_R$ if it is Bernoulli or a vector of shape and scale parameters for the gamma distribution.

Note that, for readability, in this document, we only display the chunks of code that may be important to understand the assumptions behind our simulations and the way we built our simulation. We do not display all the arguably "technical" code, in particular the one used to generate tables and graphs. All this code is however openly available on the GitHub of the project.
 
```{r DGP_IV}
generate_data_IV <- function(N,
                             type_rain, #"gamma", "normal" or "bernoulli"
                             param_rain,
                             sigma_u,
                             sigma_es,
                             sigma_et,
                             alpha,
                             gamma,
                             treatment_effect,
                             iv_strength,
                             ovb_intensity
                             ) {
  
  if (type_rain == "bernoulli") {
    rain_gen <- rbernoulli(N, param_rain[1])
  } else if (type_rain == "normal") {
    rain_gen <- rnorm(N, 0, param_rain[1])
  } else if (type_rain == "gamma") {
    rain_gen <- rgamma(N, shape = param_rain[1], scale = param_rain[2])
  } else {
    stop("type_rain must be either 'bernoulli', 'gamma' or 'normal'")
  }
  
  data <- tibble(id = 1:N) %>%
    mutate(
      rain = rain_gen,
      u = rnorm(nrow(.), 0, sigma_u),
      e_s = rnorm(nrow(.), 0, sigma_es),
      e_t = rnorm(nrow(.), 0, sigma_et),
      turnout = gamma + iv_strength*rain - ovb_intensity*u + e_t,
      share = alpha + treatment_effect*turnout + ovb_intensity*u + e_s
    )

  return(data)
}
```

We set baseline values for the parameters to emulate a somehow realistic observational study. We add the parameter value for delta separately as we will vary the value later and will reuse the vector `baseline_param_IV`.

We get "inspiration" for the values of parameters from 
[Fujiwara et al.](https://www.aeaweb.org/articles?id=10.1257/app.20140533)
and 
[Cooperman](https://www.cambridge.org/core/journals/political-analysis/article/randomization-inference-with-rainfall-data-using-historical-weather-patterns-for-variance-estimation/2F86BE9EB79FDFF9FF97C8C5CC4A2ED3) 
who replicates a work by 
[Gomez et al.](https://www.jstor.org/stable/10.1111/j.1468-2508.2007.00565.x?pq-origsite=360link&seq=1#metadata_info_tab_contents). 

We consider that:

- turnout and vote share are expressed in percent 
- Fujiwara et al. find that "The trends specifications suggest that 1 millimeter of rainfall decreases turnout by 0.05–0.07 percentage points" and Gomez et al. (and thus Cooperman) find "a county that receives one inch of rainfall on election day is likely to have approximately 1 percentage point lower voter turnout" which is equivalent to a 1mm increase in rainfall is associated with about a 0.04 percentage points decrease in voter turnout.
- For simplicity in interpretation, when rainfall is not a dummy, it is expressed in centimeters. So, we will consider iv_strength in the range -0.1 and -1
- We set the standard deviation of the omitted variable bias to be of the order of magnitude of the treatment effect
- We calibrate the distribution parameters to fit a mix if information from table 1 from both Fujiwara et al. and Cooperman (converting the rainfall into centimeters):
  - A gamma distribution represents well the distribution of rainfall. Gamma distribution can have two parameters a shape and a scale. The mean is $shape \times scale$ and the variance $shape \times scale^{2}$. The parameters of the distribution of rainfall are comparable in both papers (mean 2.4 and standard deviation 6.6). We solve the system of mean and variance for shape and scale and get 0.13 and 18.
  - We set the intercepts and standard deviations of the errors to produce turnouts and vote shares consistent with the papers. Voter turnout parameters are roughly similar in both papers (mean 58 sd 14) and mean and standard deviation of Republican vote share are given in Fujiwara et al. (mean 55.3 and sd 14.2). We may actually take values from a recent election (*eg* the last presidential election)

We thus consider the following parameters:

```{r simple_param_IV, echo=FALSE}
baseline_param_IV <- tibble(
  N = 500,
  # type_rain = "bernoulli",
  # param_rain = 0.4,
  type_rain = "gamma",
  param_rain = list(c(0.13, 18)),
  sigma_u = 2,
  sigma_es = 9,
  sigma_et = 10,
  alpha = 112,
  gamma = 58,
  treatment_effect = -1
)

baseline_param_IV %>% kable()
```

Here is an example of data created with our data generating process:

```{r example_data_IV, echo=FALSE}
baseline_param_IV %>% 
  mutate(N = 10, iv_strength = -0.5, ovb_intensity = -1) %>% 
  pmap_dfr(generate_data_IV) %>% #use pmap to pass the set of parameters
  kable()
```

#### Exploring the distribution of the data

We just quickly explore the distribution of the data for a baseline set of parameters. For this, we consider a mid range value for IV strength (-0.5).

```{r explore_data_IV, echo=FALSE}
ex_data <- baseline_param_IV %>% 
  mutate(N = 10000, iv_strength = -0.5, ovb_intensity = -1) %>% 
  pmap_dfr(generate_data_IV) 

ex_data %>% 
  ggplot(aes(x = turnout)) +
  geom_density() + 
  labs(
    title = "Distribution of turnout",
    x = "Turnout (in %)",
    y = "Density"
  ) +
  xlim(c(0,100))

# ex_data %>%
#   ggplot(aes(x = rain)) +
#   geom_density()

ex_data %>% 
  ggplot(aes(x = share)) +
  geom_density() +
  labs(
    title = "Distribution of Republican shares",
    x = "Share (in %)",
    y = "Density"
  ) +
  xlim(c(0,100))
```

We also check the standard deviation and means of the parameters:

```{r check_sd_mean, echo=FALSE}
ex_data_mean <- ex_data %>% 
  summarise(across(.cols = c(share, turnout, rain), mean)) %>% 
  mutate(Statistic = "Mean") %>% 
  select(Statistic, everything())

ex_data_sd <- ex_data %>% 
  summarise(across(.cols = c(share, turnout, rain), sd)) %>% 
  mutate(Statistic = "Standard Deviation") %>% 
  select(Statistic, everything())

ex_data_mean %>% 
  rbind(ex_data_sd) %>% 
  kable()
```

### Estimation

After generating the data, we can run an estimation. We want to compare the IV and the OLS for different IV strength values. Hence, we need to estimate both an IV and an OLS and return both set of outcomes of interest.

```{r estimate_IV}
estimate_IV <- function(data) {
  reg_IV <- AER::ivreg(
    data = data, 
    formula = share ~ turnout | rain
    ) 
  
  fstat_IV <- summary(
    reg_IV, 
    diagnostics = TRUE
  )$diagnostics["Weak instruments", "statistic"]
  
  reg_IV <- reg_IV %>% 
    broom::tidy() %>%
    mutate(
      model = "IV",
      fstat = fstat_IV
    )
  
  reg_OLS <- lm(
    data = data, 
    formula = share ~ turnout
    ) %>% 
    broom::tidy() %>%
    mutate(
      model = "OLS",
      fstat = NA
    )
  
  reg_OLS_unbiased <- lm(
    data = data, 
    formula = share ~ turnout + u
    ) %>% 
    broom::tidy() %>%
    mutate(
      model = "OLS unbiased",
      fstat = NA
    )
  
  reg <- reg_IV %>% 
    rbind(reg_OLS) %>% 
    rbind(reg_OLS_unbiased) %>% 
    filter(term == "turnout") %>%
    rename(p_value = p.value, se = std.error) %>%
    select(estimate, p_value, se, fstat, model) %>% 
  
  return(reg)
}
```

### One simulation

We can now run a simulation, combining `generate_data_IV` and `estimate_IV`. To do so we create the function `compute_sim_IV`. This simple function takes as input the various parameters. It returns a table with the estimate of the treatment, its p-value and standard error, the F-statistic for the IV, the true effect, the IV strength and the intensity of the OVB considered (ovb_intensity). Note for now, that we do not store the values of the other parameters for simplicity because we consider them fixed over the study.

```{r compute_sim_IV}
compute_sim_IV <- function(N,
                           type_rain,
                           param_rain,
                           sigma_u,
                           sigma_es,
                           sigma_et,
                           alpha,
                           gamma,
                           treatment_effect,
                           iv_strength,
                           ovb_intensity) {
  generate_data_IV(
    N = N,
    type_rain = type_rain,
    sigma_u = sigma_u,
    param_rain = param_rain,
    sigma_es = sigma_es,
    sigma_et = sigma_et,
    alpha = alpha,
    gamma = gamma,
    treatment_effect = treatment_effect,
    iv_strength = iv_strength,
    ovb_intensity = ovb_intensity
  ) %>%
    estimate_IV() %>%
    mutate(
      iv_strength = iv_strength,
      ovb_intensity = ovb_intensity,
      true_effect = treatment_effect
    )
} 
```

### All simulations

We will run the simulations for different sets of parameters by mapping our `compute_sim_IV` function on each set of parameters. We thus create a table with all the values of the parameters we want to test, `param_IV`. Note that in this table each set of parameters appears `n_iter` times as we want to run the analysis $n_{iter}$ times for each set of parameters.

```{r set_param_IV, echo=FALSE}
fixed_parameters <- baseline_param_IV #%>% rbind(...)
vect_iv_strength <- c(seq(0.05, 0.4, 0.05), seq(0.4, 0.6, 0.1))
# vect_iv_strength <- c(0.1)
vect_ovb_intensity <- c(-1)
n_iter <- 1000

param_IV <- fixed_parameters %>% 
  crossing(vect_iv_strength, vect_ovb_intensity) %>% 
  rename(iv_strength = vect_iv_strength, ovb_intensity = vect_ovb_intensity) %>% 
  crossing(rep_id = 1:n_iter) %>% 
  select(-rep_id)
```

We then run the simulations by mapping our `compute_sim_IV` function on `param_IV`.

```{r run_sim_IV, eval=FALSE, echo=FALSE}
tic()
sim_IV <- pmap_dfr(param_IV, compute_sim_IV)
beep()
toc()

# saveRDS(sim_IV, here("Outputs/sim_IV.RDS"))
```

## Analysis of the results

### Quick exploration

First, we quickly explore the results.

```{r exploration_results_IV, echo=FALSE, fig.asp=0.7}
sim_IV <- readRDS(here("Outputs/sim_IV.RDS"))

sim_IV %>% 
  filter(between(estimate, -2, 0)) %>%
  filter(ovb_intensity == sample(vect_ovb_intensity, 1)) %>% 
  filter(iv_strength %in% c(0.1, 0.2, 0.4, 0.6)) %>% 
  mutate(iv_strength = str_c("IV strength: ", iv_strength)) %>% 
  ggplot(aes(x = estimate, fill = model, color = model)) +
  geom_vline(xintercept = -1) +
  geom_density() +
  facet_wrap(~ iv_strength) +
  labs(
    title = "Distribution of the estimates of the treatment effect",
    subtitle = "For different IV strengths and models",
    color = "",
    fill = "",
    x = "Estimate of the treatment effect",
    y = "Density",
    caption = "The vertical line represents the true effect"
  )

sim_IV %>%
  filter(between(estimate, -3, 1)) %>%
  filter(model == "IV") %>%
  filter(ovb_intensity == sample(vect_ovb_intensity, 1)) %>%
  ggplot() +
  # geom_density_ridges(aes(
  geom_density(aes(
    x = estimate, 
    # y = iv_strength,
    color = as.factor(iv_strength)),
    alpha = 0
  ) +
  labs(
    title = "Distribution of the estimates of the treatment effect",
    subtitle = "Comparison across IV strengths",
    color = "IV strength",
    fill = "IV strength",
    x = "Estimate of the treatment effect",
    y = "Density",
    caption = "For readibility, extreme estimates are filtered out"
  )

data_one_sim_IV <- sim_IV %>% 
  filter(between(estimate, -3, 1)) %>%
  filter(iv_strength == 0.1) %>% 
  filter(ovb_intensity == sample(vect_ovb_intensity, 1)) %>% 
  mutate(significant = ifelse(p_value < 0.05, "Significant", "Non significant")) 

data_one_sim_IV %>% 
  ggplot(aes(x = estimate, fill = significant)) +
  geom_vline(xintercept = -1) +
  geom_histogram() +
  facet_wrap(~ model) +
  labs(
    title = "Distribution of the estimates of the treatment effect conditional on significativity",
    subtitle = paste(
      "For different models (IV strength =", 
      unique(data_one_sim_IV$iv_strength), 
      "and OVB intensity = ", 
      unique(data_one_sim_IV$ovb_intensity), ")"
    ),
    x = "Estimate of the treatment effect",
    y = "Count",
    fill = "",
    caption = "The sample is restricted to estimates relatively close to the true value"
  )
```

We notice that the OLS is always biased and that the IV is never biased. However, for limited IV strengths, the distribution of the estimates flattens. The smaller the IV strength, the most like it is to get an estimate away from the true value, even though the expected value remains equal to the true effect size. 
<!-- We can notice that statistically significant estimates are on average located further away from zero that  -->

```{r distrib_for_presentation, eval=TRUE, include=FALSE}
#Graph only for presentations, not compiled in the main .Rmd
sim_IV %>% 
  # filter(between(estimate, 0.5, 1.7)) %>%
  filter(ovb_intensity == sample(vect_ovb_intensity, 1)) %>% 
  filter(iv_strength == 0.4) %>% 
  mutate(iv_strength = str_c("IV strength: ", iv_strength)) %>% 
  ggplot(aes(x = estimate, fill = model, color = model)) +
  geom_vline(xintercept = -1) +
  geom_density() +
  # facet_wrap(~ iv_strength) +
  labs(
    title = "Distribution of the estimates of the treatment effect",
    subtitle = "Comparison across models different models",
    color = "",
    fill = "",
    x = "Estimate of the treatment effect",
    y = "Density",
    caption = "The vertical line represents the true effect"
  ) +
  theme_mediocre(pal = "coty", background = TRUE)
```


### Computing bias and type M

We want to compare $\mathbb{E}[\beta_0 - \widehat{\beta_{i}}]$ and $\mathbb{E}[|\beta_0 - \widehat{\beta_{IV}}||signif]$. The first term represents the bias and the second term represents the type M error. This terms depend on the effect size. To enable comparison across simulation and getting terms independent of effect sizes, we also compute the average of the ratios between the estimate and the true effect, conditional on significance. 

```{r summarise_IV}
summarise_simulations <- function(data) {
  data %>%
    mutate(significant = (p_value <= 0.05)) %>% 
    group_by(ovb_intensity, iv_strength, model) %>%
    summarise(
      power = mean(significant, na.rm = TRUE)*100, 
      type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE),
      bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),
      bias_all = mean(estimate/true_effect, na.rm = TRUE),
      bias_all_median = median(estimate/true_effect, na.rm = TRUE),
      median_fstat = mean(fstat, na.rm = TRUE),
      .groups	= "drop"
    ) %>% 
    ungroup()
} 

summary_sim_IV <- summarise_simulations(sim_IV)
# saveRDS(summary_sim_IV, here("Outputs/summary_sim_IV.RDS"))
```

### Graph

To analyze our results, we build a unique and simple graph:

```{r graph_results_IV, echo=FALSE, fig.asp=0.7}
summary_sim_IV %>% 
  # filter(model %in% c("OLS", "IV")) %>% 
  mutate(
    ovb_intensity_name = paste("OVB intensity:", ovb_intensity)
  ) %>%
  ggplot(aes(x = iv_strength, y = bias_signif, color = model)) + 
  # geom_point() +
  geom_line(size = 0.8) +
  facet_wrap(~ ovb_intensity_name) +
  labs(
    x = "IV strength", 
    y = expression(paste("Average  ", frac("Estimate", "True Effect"))),
    color = "Model",
    title = "Evolution of bias with intensity of the IV",
    subtitle = "For statistically significant estimates"
  ) 

# summary_sim_IV %>% 
#   pivot_longer(c(bias_signif, bias_all), names_to = "bias_type", values_to = "bias") %>% 
#   ggplot(aes(x = iv_strength, y = bias, color = bias_type)) + 
#   geom_line(size = 0.8) 
```

Of course, if one considers all estimates, as the IV is unbiased, this issue does not arise. For now, we consider the median because for very low IV strength, we get very extreme values. We need to investigate this further.

```{r graph_results_all_IV, echo=FALSE, fig.asp=0.7}
summary_sim_IV %>% 
  mutate(
    ovb_intensity_name = paste("OVB intensity:", ovb_intensity)
  ) %>%
  ggplot(aes(x = iv_strength, y = bias_all_median, color = model)) + 
  # geom_point() +
  geom_line(size = 0.8) +
  facet_wrap(~ ovb_intensity_name) +
  labs(
    x = "IV strength", 
    y = expression(paste("Median  ", frac("Estimate", "True Effect"))),
    color = "Model",
    title = "Evolution of bias with intensity of the IV",
    subtitle = "For all estimates"
  ) +
  ylim(c(0.9, 1.4))
```


### F-statistic analysis

We then run some exploratory analysis to see the link between type M and F-stat (under construction).

```{r fstat_bias_graph, echo=FALSE, fig.asp=0.7}
sim_IV %>% 
  filter(model == "IV") %>% 
  mutate(significant = (p_value <= 0.05)) %>% 
  mutate(bias = estimate/true_effect) %>% 
  filter(fstat > 10) %>%  
  # .$bias %>% mean(., na.rm = TRUE)
  # filter(abs(bias) < 10) %>% 
  ggplot(aes(x = fstat, y = bias, color = significant)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Bias as a function of the F-statistic in the simulations",
    subtitle = "By significance and only for F-stat above 10",
    x = "F-statistic",
    y = expression(paste(frac("Estimate", "True Effect"))),
    color = "Significant"
  )
```

We can notice that there is a correlation between what we call IV strength and the F statistic. When looking in more details at the distribution of F-stats, we can notice that, even for some IV strength, there are a a good chunk of significant estimates with F-stats greater thant the standard but arbitrary threshold of 10.

```{r IV_strength_fstat_graph, echo=FALSE, fig.asp=0.8}
sim_IV %>% 
  filter(model == "IV") %>% 
  mutate(significant = (p_value <= 0.05)) %>% 
  ggplot(aes(x = iv_strength, y = fstat, color = significant)) +
  geom_point(alpha = 0.5) +
  geom_jitter(alpha = 0.5) +
  labs(
    title = "A correlation between IV strength and F-statistic",
    subtitle = "By significance",
    x = "IV strength",
    y = "F-statistic",
    color = "Significant"
  )
  # ylim(c(0, 40))

# lm(data = sim_IV, fstat ~ iv_strength) %>% 
#   summary() %>% 
#   .$adj.r.squared

sim_IV %>% 
  mutate(significant = (p_value <= 0.05)) %>% 
  filter(model == "IV") %>% 
  ggplot() +
  geom_density_ridges(aes(x = fstat, y = factor(iv_strength), fill = significant, color = significant), alpha = 0.6)+
  coord_flip() +
  xlim(c(0, 50)) +
  labs(
    title = "F-statistics larger than 10, even for small IV strength",
    subtitle = "Distribution of F-statistics by IV strength and significance",
    x = "F-statistic",
    y = "IV strength",
    fill = "Significant",
    color = "Significant"
  )

# sim_IV %>% 
#   filter(model == "IV") %>% 
#   mutate(
#     significant = (p_value <= 0.05),
#     bias = abs((estimate - true_effect)/true_effect)
#   ) %>% 
#   filter(fstat > 10) %>% 
#   ggplot(aes(x = iv_strength, y = fstat, color = bias)) +
#   geom_point(alpha = 0.5) +
#   geom_jitter(alpha = 0.5) +
#   labs(
#     title = "A correlation between IV strength and F-statistic",
#     subtitle = "By significance",
#     x = "IV strength",
#     y = "F-statistic"
#     # color = "Significant"
#   )

# sim_IV %>% 
#   filter(model == "IV") %>% 
#   mutate(
#     significant = (p_value <= 0.05)
#   ) %>% 
#   group_by(iv_strength) %>% 
#   summarise(
#     mean_fstat = mean(fstat),
#     type_m = median(ifelse(significant, abs(estimate/true_effect), NA), na.rm = TRUE)
#   ) %>% 
#   ggplot(aes(x = iv_strength, y = mean_fstat, color = type_m)) +
#   geom_point() +
#   # geom_jitter(alpha = 0.5) +
#   labs(
#     title = "A correlation between IV strength and F-statistic",
#     subtitle = "By significance",
#     x = "IV strength",
#     y = "F-statistic"
#     # color = "Significant"
#   ) +
#   ylim(c(0,20))
```

We cannot compute directly the bias of interest against the F-statistic because the F-statistic is not a parameter of the simulations and we do not control them, only the IV strength. To overcome this, we compute the median power by binned F-statistic. However, this is not correct as we end up comparing and pulling together simulations with different parameter values. We still display the graph:

```{r binned_fstat, echo=FALSE, fig.asp=0.8}
sim_IV %>% 
  filter(model == "IV") %>%
  mutate(
    significant = (p_value <= 0.05),
    bin_fstat = cut_number(fstat, n = 20) %>% 
      paste() %>% 
      str_extract("(?<=,)(\\d|\\.)+") %>% 
      as.numeric()
  ) %>% 
  group_by(ovb_intensity, bin_fstat) %>%
  summarise(
    power = mean(significant, na.rm = TRUE)*100, 
    type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE),
    bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),
    bias_all = mean(estimate/true_effect, na.rm = TRUE),
    bias_all_median = median(estimate/true_effect, na.rm = TRUE),
    median_fstat = mean(fstat, na.rm = TRUE),
    .groups	= "drop"
  ) %>% 
  ungroup() %>% 
  ggplot(aes(x = bin_fstat, y = bias_signif)) +
  geom_line(linetype = "dashed") +
  geom_vline(xintercept = 10) +
  xlim(c(0, 50)) +
  labs(
    x = "Binned F-statistic", 
    y = expression(paste("Average  ", frac("Estimate", "True Effect"))),
    color = "Model",
    title = "Evolution of bias with binned F-statistic",
    subtitle = "For statistically significant estimates",
    caption = "This graph does not acurately represent 
    what wwe are interested in"
  ) 
```

```{r binned_fstat_facet, echo=FALSE, fig.asp=0.8}
sim_IV %>% 
  filter(model == "IV") %>%
  mutate(
    significant = (p_value <= 0.05),
    bin_fstat = cut_number(fstat, n = 20) %>% 
      paste() %>% 
      str_extract("(?<=,)(\\d|\\.)+") %>% 
      as.numeric()
  ) %>% 
  group_by(ovb_intensity, bin_fstat, iv_strength) %>%
  summarise(
    power = mean(significant, na.rm = TRUE)*100, 
    type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE),
    bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),
    bias_all = mean(estimate/true_effect, na.rm = TRUE),
    bias_all_median = median(estimate/true_effect, na.rm = TRUE),
    median_fstat = mean(fstat, na.rm = TRUE),
    .groups	= "drop"
  ) %>% 
  ungroup() %>% 
  ggplot(aes(x = bin_fstat, y = bias_signif)) +
  geom_line(linetype = "dashed") +
  geom_vline(xintercept = 10) +
  xlim(c(0, 50)) +
  facet_wrap(~ iv_strength) +
  labs(
    x = "Binned F-statistic", 
    y = expression(paste("Average  ", frac("Estimate", "True Effect"))),
    color = "Model",
    title = "Evolution of bias with binned F-statistic",
    subtitle = "For statistically significant estimates",
    caption = "This graph does not acurately represent 
    what wwe are interested in"
  ) 
```

# A basic example

For simplicity and for communication purposes, we considered an applied example. However, our results can also hold in general settings. We illustrate this, considering that most of the variables are distributed according to standard normal distributions. We keep the same DAG as it is the classic IV DAG. We also keep the same variable names but one should abstract from their meaning as they do not represent the same measure any longer.

We define the following parameters:

```{r set_param_IV_simple,echo=FALSE}
simple_param_IV <- tibble(
  N = 250,
  type_rain = "normal",
  param_rain = 1,
  sigma_u = 1,
  sigma_es = 1,
  sigma_et = 1,
  alpha = 0,
  gamma = 0,
  treatment_effect = -0.1
)

simple_param_IV %>% kable()
```

We then run the whole analysis as before, with an OVB intensity of 0.4 so that it is not extremely large.

```{r sim_simple, echo=FALSE}
fixed_parameters <- simple_param_IV #%>% rbind(...)
vect_iv_strength <- c(seq(0.05, 0.4, 0.05), seq(0.4, 0.6, 0.1))
# vect_iv_strength <- c(0.1)
vect_ovb_intensity <- c(-0.4)
n_iter <- 1000

param_IV_simple <- fixed_parameters %>% 
  crossing(vect_iv_strength, vect_ovb_intensity) %>% 
  rename(iv_strength = vect_iv_strength, ovb_intensity = vect_ovb_intensity) %>% 
  crossing(rep_id = 1:n_iter) %>% 
  select(-rep_id)

tic()
sim_IV_simple <- pmap_dfr(param_IV_simple, compute_sim_IV)
beep()
toc()

saveRDS(sim_IV_simple, here("Outputs/sim_IV_simple.RDS"))
# sim_IV_simple <- readRDS(here("Outputs/sim_IV_simple.RDS"))

sim_IV_simple %>% 
  summarise_simulations() %>% 
  # filter(model %in% c("OLS", "IV")) %>% 
  mutate(
    ovb_intensity_name = paste("OVB intensity:", ovb_intensity)
  ) %>%
  ggplot(aes(x = iv_strength, y = bias_signif, color = model)) + 
  # geom_point() +
  geom_line(size = 0.8) +
  facet_wrap(~ ovb_intensity_name) +
  labs(
    x = "IV strength", 
    y = expression(paste("Average  ", frac("Estimate", "True Effect"))),
    color = "Model",
    title = "Evolution of bias with intensity of the IV",
    subtitle = "For statistically significant estimates"
  ) 
```

The results and the overall illustration are comparable with the political economy example.

```{r bined_fstat_simple, echo=FALSE, fig.asp=0.8}
sim_IV_simple %>% 
  filter(model == "IV") %>%
  mutate(
    significant = (p_value <= 0.05),
    bin_fstat = cut_number(fstat, n = 10) %>% 
      paste() %>% 
      str_extract("(?<=,)(\\d|\\.)+") %>% 
      as.numeric()
  ) %>% 
  group_by(ovb_intensity, bin_fstat) %>%
  summarise(
    power = mean(significant, na.rm = TRUE)*100, 
    type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE),
    bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),
    bias_all = mean(estimate/true_effect, na.rm = TRUE),
    bias_all_median = median(estimate/true_effect, na.rm = TRUE),
    median_fstat = mean(fstat, na.rm = TRUE),
    .groups	= "drop"
  ) %>% 
  ungroup() %>% 
  ggplot(aes(x = bin_fstat, y = bias_signif)) +
  geom_line() +
  geom_vline(xintercept = 10) +
  xlim(c(0, 50)) +
  labs(
    x = "Binned F-statistic", 
    y = expression(paste("Average  ", frac("Estimate", "True Effect"))),
    color = "Model",
    title = "Evolution of bias with binned F-statistic",
    subtitle = "For statistically significant estimates",
    caption = "This graph does not acurately represent 
    what wwe are interested in"
  ) 
```


```{r fstat_bias_simple_graph, echo=FALSE, fig.asp=0.7}
sim_IV_simple %>% 
  filter(model == "IV") %>% 
  mutate(significant = (p_value <= 0.05)) %>% 
  mutate(bias = estimate/true_effect) %>% 
  filter(fstat > 10) %>%  
  # .$bias %>% mean(., na.rm = TRUE)
  # filter(abs(bias) < 10) %>% 
  ggplot(aes(x = fstat, y = bias, color = significant)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Bias as a function of the F-statistic in the simulations",
    subtitle = "By significance and only for F-stat above 10",
    x = "F-statistic",
    y = expression(paste(frac("Estimate", "True Effect"))),
    color = "Significant"
  )
```
