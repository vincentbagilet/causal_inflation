---
title: "Computing and reporting power calculations"
description: "Under construction. In this document, we will discuss and illustrate how to run power calculations."
author:
  - name: Vincent Bagilet 
    url: https://vincentbagilet.github.io/
    affiliation: Columbia University
    affiliation_url: https://www.columbia.edu/
  - name: LÃ©o Zabrocki 
    url: https://www.parisschoolofeconomics.eu/en/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/en/
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
editor_options: 
  chunk_output_type: console
---

<style>
body {
text-align: justify}
</style>

```{r setup_IV, include=FALSE, results='hide', warning=FALSE}
library(knitr)
opts_chunk$set(fig.path = "images/",
               cache.path = "cache/",
               cache = FALSE,
               echo = TRUE, #set to false to hide code
               message = FALSE,
               warning = FALSE,
               out.width = "85%",
               dpi = 300,
               fig.align = "center",
               dev.args = list(bg="transparent"))  
```  

```{r packages_IV, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse) 
library(knitr) 
library(mediocrethemes)
library(here)
library(retrodesign)


set_mediocre_all(pal = "coty")
```


## Post estimation analysis

Let's focus on the example of described for the [RDD simulations](RDD.html), studying the impact of a school teaching program on student final scores. Assume that using real world data, we find an estimate of the treatment effect to be equal to 0.22 with standard deviation of 0.2. We want to compute what could be the power and exaggeration. These values depend on the true effect size. We therefore compute them for a range of credible true effect sizes. Another way to look at the problem is to wonder whether, if the true effect was smaller, the design of this study would be "good enough" to detect an effect and by how much we can expect the estimate to be inflated.

Replicating the analysis with the same design would yield an estimate with a similar standard error as the original study. We therefore postulate different true effect sizes and feed them to `retrodesign`:

```{r retrodesign_generate}
se <- 0.2

retro <- retrodesign::retro_design(as.list(seq(0.05, 0.4, by = 0.01)), se) %>%
  unnest(cols = c(effect_size, power, type_s, type_m)) %>%
  select(-type_s) %>% 
  mutate(power = power * 100) %>%
  rename(
    "Statistical Power (%)" = power,
    "Type-M Error (Exaggeration Ratio)" = type_m
  ) %>%
  pivot_longer(
    cols = -c(effect_size),
    names_to = "statistic",
    values_to = "value"
  )
```

We can then build simple graphs representing what would be the power and exaggeration ratio for a range of hypothetical true effect sizes:

```{r retrodesign_graph}
retro %>% 
  ggplot(aes(x = effect_size, y  = value)) +
  geom_line(size = 1.1) +
  facet_wrap( ~ statistic, scales = "free") +
  # geom_vline(aes(xintercept = 0.4)) +
  geom_vline(aes(xintercept = 0.22)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 7)) +
  labs(
    title = "Evolution of power and exaggeration with true effect size",
    x ="Hypothetical True Effect Size",
    y = "",
    caption = paste("Standard error =", se)
  )
  
```




