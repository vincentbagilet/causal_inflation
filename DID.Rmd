---
title: "Simulations Event study/DID"
description: "In this document, we run a simulation exercise to illustrate the loss in power and resulting type M error when the number of events in a Difference In Differences design decreases."
author:
  - name: Vincent Bagilet 
    url: https://vincentbagilet.github.io/
    affiliation: Columbia University
    affiliation_url: https://www.columbia.edu/
  - name: LÃ©o Zabrocki 
    url: https://www.parisschoolofeconomics.eu/en/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/en/
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
editor_options: 
  chunk_output_type: console
---

<style>
body {
text-align: justify}
</style>

```{r setup_RDD, include=FALSE, results='hide', warning=FALSE}
library(knitr)
opts_chunk$set(fig.path = "images/",
               cache.path = "cache/",
               cache = FALSE,
               echo = TRUE, #set to false to hide code
               message = FALSE,
               warning = FALSE,
               out.width = "85%",
               dpi = 200,
               fig.align = "center")  
```  

```{r packages_RDD, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse) 
library(knitr) 
library(mediocrethemes)
library(tictoc)
library(here)
library(beepr)

set_mediocre_all(pal = "coty") #, background = TRUE) #for presentations
```

## Summary and intuition

In the case of Event studies and DiD, the OVB/type M trade-off is  mediated by the number of events.

## An illustrative example

For readability and to illustrate this loss in power, we consider an example setting. For this illustration we could use a large variety of Data Genereting Processes (DGP), both in terms of distribution of the variables and of relations between them. We narrow this down to an example setting, considering an analysis of health impacts of air pollution. Our point should stand in more general settings. 

A threat of confounders often arises when analyzing the health effects of air pollution. To estimate such an effect causally, one can consider exogeneous shocks to air pollution. In the present analysis, we consider the example of plant closures as exogeneous shocks.

### Modelisation choices

In the present analysis, we build our simulations to replicate an analysis of the causal health effects of air pollution, using plant closures as an exogeneous shifter in air pollution levels. In such analyses, the data is often at the city-daily level. Hospital admissions are usual health outcomes considered in such analyses. 

The DGP can be represented using the following Directed Acyclic Graph (DAG): 

```{r DAG_RDD, echo=FALSE, out.width='40%'}
include_graphics(here("images/DAG_DID.png"))
```

This DAG makes it clear that in substance, we are instrumenting air pollution level by plant closure.

The DGP for the number of admissions at the hospital in city $c$ at time $t$ is as follows:

$$Admissions_{ct} = \xi + \gamma Poll_{ct} + \delta U_{ct} + e_{ct}$$
Where $\xi$ is a constant, $U$ represents an unobserved variable and $e \sim \mathcal{N}(0, \sigma_{e)$ noise. The DGP for the pollution data is as follows: 

$$Poll_{ct} = \mu + \lambda T_{ct} + \eta U_{ct} + \tilde{e}_{ct}$$
Where $\mu$ is a constant,$T_{ct}$ is the treatment, equal to 1 if there is a plant closure in city $c$ at time $t$ and zero otherwise and $\tilde{e} \sim \mathcal{N}(0, \sigma_{\tilde{e})$ noise.

The effect of plant closures, the treatment, on health is often estimated using a reduced form approach, regressing health in city $c$ at time $t$ on the treatment. In our case, that yields to estimating the following equation:
m
$$Admissions_{ct} = \alpha + \beta T_{ct} + \epsilon_{ct}$$
To simplify, we consider the following assumptions:

- Pollution and hospital admissions are not correlated across cities nor time. This is very simplistic but if anything should make it easier to identify the effect of interest,
- The unobserved variable $U$ is drawn from a normal distribution, 
- In a first step, we consider homogeneous treatment effects

- A proportion $p_{treat}$ of individuals are ever treated over the period. Hence, a proportion of $1-p_{treat}$ individuals are never treated over the period. I draw these individual at random. Note that the value of the individual identifiers do not matter here. So I could assume that the non-treated individuals are those with the larger individual ids for instance,
- The implementation of the treatment can be staggered or not. If it is not staggered, the treatment date is set to be in the middle of the period
- The treatment can vary along two dimensions, time and individual. Details are given below.

More precisely, I set: 

- $N_C$ the number of cities
- $N_T$ the number of periods
- $U_{ct} \sim \mathcal{N}(\mu_{u}, \sigma_{u}^{2})$
- $e_{it} \sim \mathcal{N}(0, \sigma_{e}^{2})$, $\tilde{e}_{it} \sim \mathcal{N}(0, \sigma_{\tilde{e}}^{2})$ noises
- $T_{ct}$ represent the treatment allocation, it is equal to one if a plant closes in city $c$ at time $t$ and 0 otherwise,
- $Poll$ and $Amissions$ are created as described above

- $\beta_{it}$ is represents the magnitude of the treatment effect and is linked to the input parameter `beta`. 

  - Across individuals, the treatment can either be:
  
    - homogeneous: `het_indiv == homogeneous`, for each individual, the treatment is equal to `beta`, 
    - random: `het_indiv == random`, for each individual, the treatment is drawn from  $\mathcal{U}(0.5\beta, 1.5\beta)$,
    - larger for those that are treated first: `het_indiv == large_first`, for each individual, the treatment is equal to $N_T - \beta$.
  
  - Across time, the effect of the treatment can either be 
    
    - constant: `het_time == constant`,
    - increasing linearly in time: `het_time == linear`.

I also create a bunch of variables that can be useful:

- $InTreatment_i$ equal to 1 if individual $i$ ever gets treated,
- $t^{event}_i$ equal to the date at which individual $i$ gets treated,
- $t^{centered}_i$ representing the distance in terms of period to the beginning of the treatment for individual $i$,
- $Post_{it}$ equal to 1 if the period $t$ is after the treatment has begun for individual $i$. This variable is only useful for non-staggered treatment allocation,

### Data generation

I write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis. 

```{r DGP}
generate_data_TWFE <- function(N_C,
                               N_T,
                               sigma_e,
                               p_treat,
                               staggered,
                               het_indiv,
                               het_time,
                               alpha,
                               beta,
                               mu_indiv_fe = 0, 
                               sigma_indiv_fe = 0,
                               mu_time_fe = 0, 
                               sigma_time_fe = 0,
                               mu_x = 0, 
                               sigma_x = 0,
                               gamma = 0
                             ) {

  if (!is.logical(staggered)) {stop("staggered must be logical")} 
  if (!(het_indiv %in% c("large_first", "random", "homogeneous"))) {
    stop('het_indiv must be either "large_first", "random" or "homogeneous"')
  } 
  if (!(het_time %in% c("constant", "linear"))) {
    stop('het_time must be either "constant" or "linear"')
  } 
  
  data <- tibble(indiv = 1:N_C) %>%
    mutate(InTreatment = (indiv %in% sample(1:N_C, floor(N_C*p_treat)))) %>% 
    crossing(t = 1:N_T) %>%
    group_by(indiv) %>%
    mutate(
      indiv_fe = rnorm(1, mu_indiv_fe, sigma_indiv_fe),
      t_event = ifelse(staggered, sample(2:(N_T - 1), 1), floor(N_T/2)), 
        #I use 2:(N_T-1) to have a pre and post period
      t_event = ifelse(InTreatment, t_event, NA),
      beta_i = case_when(
        het_indiv == "large_first" ~ N_T-t_event,
        het_indiv == "random" ~ runif(1, beta*0.5, beta*1.5), 
        het_indiv == "homogeneous" ~ beta
      ),
      beta_i = ifelse(is.na(t_event), 0, beta_i)
    ) %>%
    ungroup() %>%
    group_by(t) %>%
    mutate(time_fe = rnorm(1, mu_time_fe, sigma_time_fe)) %>%
    ungroup() %>%
    mutate(
      post = (t > t_event),
      treated = InTreatment & post, 
      beta_i = ifelse(
        het_time == "linear" & post & !is.na(t_event),
        beta_i*(t - t_event), 
        beta_i
      ),
      t_centered = t - t_event,
      x = rnorm(nrow(.), mu_x, sigma_x),
      e = rnorm(nrow(.), 0, sigma_e),
      y0 = alpha + gamma * x + indiv_fe + time_fe + e,
      y1 = y0 + beta_i,
      y = treated*y1 + (1 - treated)*y0
    )
  
  return(data)
}
```

I set baseline values for the parameters as very standard. These values are arbitrary.

```{r baseline_param}
baseline_parameters_TWFE <- tibble(
  N_C = 20,
  N_T = 50,
  sigma_e = 1,
  p_treat = 0.8,
  staggered = TRUE,
  het_indiv = "homogeneous",
  het_time = "constant",
  alpha = 1,
  beta = 1
)
```

Here is an example of data created with the data generating process and baseline parameter values, for 2 individuals and 8 time periods:

```{r example_data, echo=FALSE}
baseline_parameters_TWFE %>% 
  mutate(N_C = 2, N_T = 8) %>%
  pmap_dfr(generate_data_TWFE) %>% #use pmap to pass the set of parameters
  select(indiv, t, y, InTreatment, post, treated, t_centered, e) %>% 
  kable()
```

<!-- ### Estimation -->

<!-- After generating the data, we can run an estimation.  -->

<!-- Note that to run power calculations, we need to have access to the true effects. Therefore, before running the estimation, we write a short function to compute the average treatment effect on the treated (ATET). We will add this information to the estimation results.  -->

<!-- ```{r compute_true_effect_RDD} -->
<!-- compute_true_effect_rdd <- function(data) { -->
<!--   treated_data <- data %>%  -->
<!--     filter(treated)  -->
<!--   return(mean(treated_data$final1 - treated_data$final0)) -->
<!-- }   -->
<!-- ``` -->

<!-- We then run the estimation. To do so, we only consider observations within the bandwidth and regress the final test scores on the treatment, the qualification score and their interaction. Note that we include this interaction term to allow more flexibility and to mimic an realistic estimation. Yet, we know that this interaction term does not appear in the DGP. Including it or not do not change the results. Also note that, of course, we do not include the unobserved ability in this model to create an OVB.  -->

<!-- ```{r estimate_RDD} -->
<!-- estimate_rdd <- function(data, bw) { -->
<!--   data_in_bw <- data %>%  -->
<!--     define_bw(bw = bw) %>%  -->
<!--     filter(!is.na(treated_bw)) -->

<!--   reg <- lm( -->
<!--     data = data_in_bw,  -->
<!--     formula = final ~ treated + qual -->
<!--   ) %>%  -->
<!--     broom::tidy() %>% -->
<!--     filter(term == "treatedTRUE") %>% -->
<!--     rename(p_value = p.value, se = std.error) %>% -->
<!--     select(estimate, p_value, se) %>% -->
<!--     mutate( -->
<!--       true_effect = compute_true_effect_rdd(data), -->
<!--       bw = bw -->
<!--     ) -->

<!--   return(reg) -->
<!-- } -->
<!-- ``` -->

<!-- ### One simulation -->

<!-- We can now run a simulation, combining `generate_data_rdd` and `estimate_rdd`. To do so we create the function `compute_sim_RDD`. This simple function takes as input the various parameters along with a vector of bandwidth sizes, `vect_bw`. If we want to run several simulations with different bandwidths, we can reuse the same data, hence why we allow to passing a vector of bandwidths and not only one bandwidth. The function returns a table with the estimate of the treatment, its p-value and standard error, the true effect and the bandwidth and intensity of the OVB considered (delta). Note for now, that we do not store the values of the other parameters for simplicity because we consider them fixed over the study. -->

<!-- ```{r compute_sim_RDD} -->
<!-- compute_sim_RDD <- function(N, -->
<!--                             sigma_u, -->
<!--                             mu_h, -->
<!--                             sigma_h, -->
<!--                             sigma_e, -->
<!--                             alpha, -->
<!--                             beta, -->
<!--                             gamma, -->
<!--                             delta, -->
<!--                             q_c, -->
<!--                             vect_bw) { -->

<!--   data <- generate_data_rdd( -->
<!--     N = N, -->
<!--     sigma_u = sigma_u, -->
<!--     mu_h = mu_h, -->
<!--     sigma_h = sigma_h, -->
<!--     sigma_e = sigma_e, -->
<!--     alpha = alpha, -->
<!--     beta = beta, -->
<!--     gamma = gamma, -->
<!--     delta = delta, -->
<!--     q_c = q_c -->
<!--   )  -->

<!--   map_dfr(vect_bw, estimate_rdd, data = data) %>% -->
<!--     mutate(delta = delta) -->
<!-- }  -->
<!-- ``` -->

<!-- Here is an example of an output of this function. -->

<!-- ```{r example_output_sim_RDD, echo=FALSE} -->
<!-- baseline_parameters_RDD %>%  -->
<!--   mutate(delta = 1) %>%  -->
<!--   pmap_dfr(compute_sim_RDD, vect_bw = c(0.1, 0.2)) -->
<!-- ``` -->

<!-- ### All simulations -->

<!-- We will run the simulations for different sets of parameters by mapping our `compute_sim_RDD` function on each set of parameters. We thus create a table with all the values of the parameters we want to test `param_rdd`. Note that in this table each set of parameters appears `N_Cter` times as we want to run the analysis $n_{iter}$ times for each set of parameters. -->

<!-- ```{r set_param_RDD} -->
<!-- simple_parameters_RDD <- tibble( -->
<!--   N = 500, -->
<!--   sigma_u = 1, -->
<!--   mu_h = 0, -->
<!--   sigma_h = 1, -->
<!--   sigma_e = 0.5, -->
<!--   alpha = 1, -->
<!--   beta = 1, -->
<!--   gamma = 0.7, -->
<!--   q_c = 0.5 -->
<!-- ) -->

<!-- fixed_parameters_RDD <- simple_parameters_RDD #%>% rbind(...) -->
<!-- # vect_bw <- seq(0.05, 0.4, 0.05) -->
<!-- vect_bw <- c(seq(0.05, 0.4, 0.05), seq(0.4, 1, 0.1)) -->
<!-- vect_delta <- c(3) -->
<!-- N_Cter <- 1000 -->

<!-- param_rdd <- fixed_parameters_RDD %>%  -->
<!--   crossing(delta = vect_delta) %>%  -->
<!--   mutate(vect_bw = list(vect_bw)) %>%  -->
<!--   crossing(rep_id = 1:N_Cter) %>%  -->
<!--   select(-rep_id) -->
<!-- ``` -->

<!-- We then run the simulations by mapping our `compute_sim_RDD` function on `param_rdd`. -->

<!-- ```{r run_sim_RDD, eval=FALSE} -->
<!-- tic() -->
<!-- simulations_rdd <- pmap_dfr(param_rdd, compute_sim_RDD) -->
<!-- beep() -->
<!-- toc() -->

<!-- # saveRDS(simulations_rdd, here("Outputs/simulations_rdd.RDS")) -->
<!-- ``` -->

<!-- ## Analysis of the results -->

<!-- ### Quick exploration -->

<!-- First, we quickly explore the results. -->

<!-- ```{r exploration_results_RDD, echo=FALSE} -->
<!-- simulations_rdd <- readRDS(here("Outputs/simulations_rdd.RDS")) -->

<!-- simulations_rdd %>% -->
<!--   # filter(bw == vect_bw[5]) %>% -->
<!--   mutate(bw_name = str_c("Bandwidth: ", bw)) %>%  -->
<!--   ggplot(aes(x = estimate)) + -->
<!--   geom_density() + -->
<!--   # geom_vline(aes(xintercept = mean(estimate))) + -->
<!--   geom_vline(aes(xintercept = true_effect), linetype = "dashed") + -->
<!--   facet_wrap(~ bw_name) + -->
<!--   labs( -->
<!--     title = "Distribution of the estimates of the treatement effect", -->
<!--     subtitle = "For different bandwidth sizes", -->
<!--     x = "Estimate of the treatement effect", -->
<!--     y = "Density", -->
<!--   ) -->

<!-- simulations_rdd %>%  -->
<!--   filter(bw == vect_bw[2]) %>% -->
<!--   mutate(significant = ifelse(p_value < 0.05, "Significant", "Non significant")) %>%  -->
<!--   ggplot(aes(x = estimate, fill = significant)) +  -->
<!--   geom_histogram(bins = 25) + -->
<!--   geom_vline( -->
<!--     aes(xintercept = mean(abs(estimate[significant == "Significant"]))), -->
<!--     linetype = "solid" -->
<!--   ) + -->
<!--   geom_vline(aes(xintercept = 1)) + -->
<!--   # facet_wrap(~ bw) + -->
<!--   labs( -->
<!--     title = "Distribution of the estimates of the treatement effect", -->
<!--     subtitle = str_c("For a bandwidth containing ", vect_bw[2]*100, "% of the observations"), -->
<!--     x = "Estimate of the treatement effect", -->
<!--     y = "Count", -->
<!--     fill = "", -->
<!--     caption = "The solid line represents the average mean effect for significant  -->
<!--     estimates (in absolute value), the dashed line represents the true effect" -->
<!--   )  -->

<!-- # simulations_rdd %>%  -->
<!-- #   filter(bw == 0.2) %>%  -->
<!-- #   mutate(significant = (p_value < 0.05)) %>%  -->
<!-- #   group_by(delta) %>%  -->
<!-- #   mutate(sim_id = row_number()) %>%  -->
<!-- #   ungroup() %>%  -->
<!-- #   ggplot(aes(x = estimate, color = significant)) +  -->
<!-- #   geom_point(aes(x = sim_id, y = estimate)) + -->
<!-- #   geom_hline(aes(yintercept = mean(estimate))) + -->
<!-- #   facet_wrap(~ delta) -->
<!-- #  -->
<!-- # simulations_rdd %>%  -->
<!-- #   group_by(delta, bw) %>%  -->
<!-- #   summarise(average_effect = mean(estimate)) -->
<!-- ``` -->

<!-- ### Computing bias and type M -->

<!-- We want to compare $\mathbb{E}[\beta_0 - \widehat{\beta_{RDD}}]$ and $\mathbb{E}[|\beta_0 - \widehat{\beta_{RDD}}||signif]$. The first term represents the bias and the second term represents the type M error. This terms depend on the effect size. To enable comparison across simulation and getting terms independent of effect sizes, we also compute the average of the ratios between the estimate and the true effect, conditional on significance.  -->

<!-- ```{r summarise_RDD} -->
<!-- summarise_simulations <- function(data) { -->
<!--   data %>% -->
<!--     mutate(significant = (p_value <= 0.05)) %>%  -->
<!--     group_by(delta, bw) %>% -->
<!--     summarise( -->
<!--       power = mean(significant, na.rm = TRUE)*100,  -->
<!--       type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE), -->
<!--       bias_sign = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE), -->
<!--       bias_all = mean(estimate/true_effect, na.rm = TRUE), -->
<!--       .groups	= "drop" -->
<!--     ) %>%  -->
<!--     ungroup() -->
<!-- }  -->

<!-- summary_simulations_rdd <- summarise_simulations(simulations_rdd) -->
<!-- # saveRDS(summary_simulations_rdd, here("Outputs/summary_simulations_rdd.RDS")) -->
<!-- ``` -->

<!-- ### Graph -->

<!-- To analyze our results, we build a unique and simple graph: -->

<!-- ```{r graph_results_RDD, echo=FALSE} -->
<!-- summary_simulations_rdd %>%  -->
<!--   pivot_longer(cols = c(bias_sign, bias_all), names_to = "measure") %>%  -->
<!--   mutate( -->
<!--     measure = ifelse(measure == "bias_sign", "Significant", "All"), -->
<!--     delta_name = paste("OVB intensity:", delta) -->
<!--   ) %>%  -->
<!--   ggplot(aes(x = bw, y = value, color = measure)) +  -->
<!--   # geom_point() + -->
<!--   geom_line(size = 0.8) + -->
<!--   # facet_wrap(~Â delta_name) + -->
<!--   labs( -->
<!--     x = "Bandwidth size",  -->
<!--     y = expression(paste("Average  ", frac("|Estimate|", "True Effect"))), -->
<!--     color = "Estimates", -->
<!--     title = "Evolution of bias with bandwith size, conditional on significativity", -->
<!--     # subtitle = "For several values of OVB intensity", -->
<!--     caption = "Bandwidth size as a proportion of the total number of observations" -->
<!--   )  -->
<!-- ``` -->


