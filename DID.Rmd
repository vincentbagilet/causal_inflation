---
title: "Simulations DID / Event study"
description: "In this document, we run a simulation exercise to illustrate how using a Difference-in-Differences (DiD) or event study approach to avoid confounders may lead to a loss in power and inflated effect sizes."
author:
  - name: Vincent Bagilet 
    url: https://vincentbagilet.github.io/
    affiliation: Columbia University
    affiliation_url: https://www.columbia.edu/
  - name: Léo Zabrocki 
    url: https://www.parisschoolofeconomics.eu/en/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/en/
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
editor_options: 
  chunk_output_type: console
---

<style>
body {
text-align: justify}
</style>

```{r setup_RDD, include=FALSE, results='hide', warning=FALSE}
library(knitr)
opts_chunk$set(fig.path = "images/",
               cache.path = "cache/",
               cache = FALSE,
               echo = TRUE, #set to false to hide code
               message = FALSE,
               warning = FALSE,
               out.width = "85%",
               dpi = 300,
               fig.align = "center",
               dev.args = list(bg="transparent"))  
```  

```{r packages_RDD, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse) 
library(knitr) 
library(fixest)
library(mediocrethemes)
library(broom)
library(tictoc)
library(here)
library(beepr)

set_mediocre_all(pal = "coty")
set.seed(12)
```

## Summary and intuition

In the case of event studies, DiD or basically any study using discrete exogenous shocks, the unconfoundedness / exaggeration trade-off is  mediated by the number of observations treated. In some classic DiD settings, while the number of observations is large, the number of events might be limited. Pinpointing exogenous shocks is never easy and we are sometimes only able to find a limited number of occurrences of this shock or shocks affecting a small portion of the population. More precisely, the number of observations with a non null treatment status might be small. In this instance, the variation available to identify the treatment is limited, possibly leading power to be low and exaggeration issues to arise. 

The number of treated observations can be decomposed into two parts: the total number of observations times the proportion of observations in the treated group. Of course, if one reduces the total sample size, precision and thus power will decrease. Now, we all remember that power is maximized when the proportion of treated observations is equal to the proportion of untreated ones. If we consider a fixed number of observations, decreasing the proportion of treated observations below 0.5 will decrease precision and power. 

The simple formula of the standard error of the difference of the averages of the outcome variable in the treated and control group illustrates this. Of course this does not represent the actual standard error of the DiD estimate but it represents something similar and can be useful to get an intuition for this trade-off. The formula is the following:

$$se_{\bar{y_T} - \bar{y_c}} = \sqrt{\dfrac{\sigma_T^2}{n_T} + \dfrac{\sigma_C^2}{n_C}}$$
where $n_T$ and $n_C$ are the number of observation in the treated group and the control group respectively and $\sigma_T$ and $\sigma_C$ the standard deviations of the outcome in the treated group and the control group respectively. In many cases, we can assume that $\sigma_T = \sigma_C = \sigma$. Under this assumption we have: 

$$se_{\bar{y_T} - \bar{y_c}} = \dfrac{\sigma}{\sqrt{n}} \times \sqrt{\dfrac{1}{p_T(1-p_T)}}$$
where $n$ is the total number of observations and $p_T$ the proportion of treated observations. 

From this simple formula it is obvious that the standard error of interest increases when $n$ decreases and that, for $n$ constant, it is minimized when the proportion of treated is 0.5. If there are less treated than control, one may think of decreasing the number of observations in the control group to get to $p_T = 0.5$. Yet, this will also reduce $n$ and the first equation makes clear that only reducing $n_C$ will increase the standard error of interest. 
 
The unbalance between the number of treated and controls is more general than only event studies and DiD but is particularly salient in this case.

## An illustrative example

For readability and to illustrate this loss in power, we consider an example setting. For this illustration we could use a large variety of Data Genereting Processes (DGP), both in terms of distribution of the variables and of relations between them. We narrow this down to an example setting, considering an analysis of health impacts of air pollution. More precisely, we simulate and analyze the impacts of air pollution reduction on birthweights. Air pollution might vary with other variables that may also affect birthweight (for instance economic activity). Some of these variables might be unobserved and bias estimates of a simple regression of birthweight on pollution levels. A strategy to avoid such issues is to consider exogenous shocks to air pollution such as plant closures, plant openings, creation of a low emission zone or an urban toll, strikes, etc.

Even if we consider an example setting for clarity, the unconfoundedness / exaggeration trade-off mediated by the number of observations treated should also arise in other settings.

### Modeling choices

To simplify, we consider the assumptions described below. Of course these assumptions are arbitrary and we invite you to play with them. 
<!-- Note that, fixed effects and the covariate are not necessary to the analysis. I only add them to make the analysis more realistic if necessary but I set their baseline values to 0. -->

As many studies in the literature, for instance [Currie et al. (2015)](https://www.aeaweb.org/articles?id=10.1257/aer.20121656) and [Lavaine and Neidell (2017)](https://www.journals.uchicago.edu/doi/full/10.1086/691554), to build a panel, we aggregate observations. We look at the evolution of birthweights in zip codes in time, for instance months. 

For clarity in the explanations, let's assume that the exogenous shock considered is a permanent plant closure and that this reduces air pollution level. If the reader prefers, they can think of it as any permanent exogenous change in air pollution levels. For now, we will only estimate a reduced form. We are therefore not interested in modeling the effect of the plant closure on pollution levels. We consider that the plant closure leads to some air pollution reduction and want to estimate the effect of this closure on birthweight. We plan to add pollution in the future in order to compare the performance of the reduced form and a straight regression of birthweight on pollution. Yet, generating pollution is rather complex and we therefore only consider the reduced form for now.

For each time period, a zip code is either treated (plant closed) or not treated. Over the whole period, some zip codes experience a plant closure, others do not either because they do not have a plant that affect their air pollution levels or because their plant did not close. 

We consider that the average birthweight in zip code $z$ at time period $t$, $w_{zt}$, depends on a zip code fixed effect $\zeta_z$, a time fixed effect $\tau_t$ and the treatment status $T_i$, *ie* whether a plant closed in this period or not. For now, we do not simulate omitted variable biases as we consider that the shocks are truly exogenous. Thus, birthweight is defined as follows:

$$w_{z,t} = \alpha + \beta T_{z, t} + \zeta_z + \tau_t + \epsilon_{z,t}$$
<!-- 
is correlated with the average birthweight in this zip code in other periods and in nearby zip codes and also depends the treatment status $T_i$, *ie* whether a plant closed in this period or not. For now, we do not simulate omitted variable biases as we consider that the shocks are truly exogenous.

We consider an AR(1) process along each dimension. Thus, birthweight is defined as follows: -->

<!-- $$Birthweight_{z,t} = \alpha + \beta T_{z, t} + \tau Birthweight_{z, (t-1)} + \zeta Birthweight_{(z-1), t} + \epsilon_{z,t}$$ -->

<!-- The DGP can be represented using the following Directed Acyclic Graph (DAG):  -->

<!-- ```{r DAG_RDD, echo=FALSE, out.width='60%'} -->
<!-- include_graphics(here("images/DAGs/DAGs.004.png")) -->
<!-- ``` -->


To simplify, we consider the following additional assumptions:

- The treatment is constant in time and homogeneous across zip codes. In this case, the two ways fixed effect estimation should yield a correct estimate of the ATET (as discussed in [de Chaisemartin and d'Haultfoeuille (2022)](https://www.nber.org/papers/w29691) for instance)
- A proportion $p_{treat}$ of zip codes are ever treated over the period. Hence, a proportion of $1-p_{treat}$ zip codes are never treated over the period. We draw these zip codes at random. Note that drawing at random is not necessary here. Without loss of generality, we could assume that the non-treated zip codes are those with the larger zip codes identifiers for instance,
- We assume that, among treated zip codes, on average half of the observations are treated. This choice is arbitrary but we choose that such that the treatment happens on average in middle of the of the time period,
- The implementation of the treatment can be staggered or not. If it is not staggered, the treatment date is set to be in the middle of the period. For now we only analyze the non staggered version.

More precisely, we set: 

- $N_z$ the number of zip codes,
- $N_t$ the number of periods (months),
- $\zeta_z \sim \mathcal{N}(\mu_{\zeta}, \sigma_{\zeta}^{2})$ the fixed effect for zip code $z$,
- $\tau_t \sim \mathcal{N}(\mu_{\tau}, \sigma_{\tau}^{2})$ the fixed effect for time period $t$,
- $\epsilon_{zt} \sim \mathcal{N}(0, \sigma_{\epsilon}^{2})$ some noise,
- $T_{zt}$ represent the treatment allocation, it is equal to 1 if zip code $z$ is treated at time $t$ and 0 otherwise,
- $w_{z,t} = \alpha + \beta T_{z, t} + \zeta_z + \tau_t + \epsilon_{z,t}$ where $\alpha$ is a constant,
- $\beta$ is represents the magnitude of the treatment,
- We define `staggered` as a logical variable.

We also create a bunch of variables that can be useful:

- $InTreatment_z$ equal to 1 if zip code $z$ ever gets treated,
- $t^{event}_z$ equal to the date at which zip code $z$ gets treated, especially useful in the staggered setting,
- $t^{centered}_z$ representing the distance in terms of periods to the beginning of the treatment for zip code $z$,
- $Post_{zt}$ equal to 1 if the period $t$ is after the treatment has begun for zip code $z$. This variable is only useful for non-staggered treatment allocation case.

### Data generation

#### Generating function

We write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis. 

```{r DGP_DID}
generate_data_DID <- function(N_z,
                              N_t,
                              sigma_e,
                              p_treat,
                              staggered,
                              alpha,
                              beta,
                              mu_zip_fe, 
                              sigma_zip_fe,
                              mu_time_fe, 
                              sigma_time_fe
                             ) {
  
  if (!is.logical(staggered)) {stop("staggered must be logical")} 
  
  data <- tibble(zip = 1:N_z) %>%
    mutate(in_treatment = (zip %in% sample(1:N_z, floor(N_z*p_treat)))) %>% 
    crossing(t = 1:N_t) %>%
    group_by(zip) %>%
    mutate(
      zip_fe = rnorm(1, mu_zip_fe, sigma_zip_fe),
      # x = rnorm(1, 0, 350),
      t_event = ifelse(staggered, sample(2:(N_t - 1), 1), floor(N_t/2)), 
        #We use 2:(N_t-1) to aalways have a pre and post period
      t_event = ifelse(!in_treatment & staggered, NA, t_event)
    ) %>%
    ungroup() %>%
    group_by(t) %>%
    mutate(time_fe = rnorm(1, mu_time_fe, sigma_time_fe)) %>%
    ungroup() %>%
    mutate(
      post = (t > t_event),
      treated = in_treatment & post, 
      t_centered = t - t_event,
      e = rnorm(nrow(.), 0, sigma_e),
      birthweight0 = alpha + zip_fe + time_fe + e, #+ 1*x
      birthweight1 = birthweight0 + beta,
      birthweight = treated*birthweight1 + (1 - treated)*birthweight0
    )
  
  return(data)
}
```

#### Baseline parameters' values

We set baseline values for the parameters to emulate a somehow realistic observational study`.

We get "inspiration" for the values of parameters from [Lavaine and Neidell (2017)](https://www.journals.uchicago.edu/doi/full/10.1086/691554).

We consider that:
- We consider a large number of zip codes (1000 zip codes) and time periods (24 months),
- Birthweight is expressed in grams. In Lavaine and Neidell's sample made of babies born in France, the average birthweight is 3228g (sd = 353). We choose `alpha` and `sigma_e` to yield a similar distribution. These values of course depend on the values of the other parameters
- A usual treatment effect size in published studies is a change of about 1 to 3% in birthweight. We consider a 2% effect size. Thus, we set $\beta = 3228 \times 0.02 \simeq 65$
- We set time and individual fixed effects to be of half of the order of magnitude of the treatment effect and with a standard deviation roughly equal to their mean (somehow arbitrary choice),
- In these type of analyses, plant closures do not happen often and therefore the proportion of treated observations is limited. As a baseline, we can assume that 5% of the plants close over the period. Translating it in terms of closures, in the two years of the study (24 months), out of the 1000 plants, 50 closed. This does not seem like a particularly large number as such closures are rare. 

```{r baseline_param_DID, echo=FALSE}
baseline_param_DID <- tibble(
  N_z = 5000,
  N_t = 24,
  sigma_e = 350, #65,
  p_treat = 0.05,
  staggered = FALSE,
  alpha = 3163,
  beta = 65,
  mu_zip_fe = 33, 
  sigma_zip_fe = 33,
  mu_time_fe = 33, 
  sigma_time_fe = 33
)

baseline_param_DID %>% kable()
```

Here is an example of data created with the data generating process and baseline parameter values, for 2 zip codes and 8 time periods and not displaying `t_event`, `ìn_treatment`, `post` and `t_centered`:

```{r example_data_DID, echo=FALSE}
baseline_param_DID %>% 
  mutate(N_z = 2, N_t = 8, p_treat = 0.5) %>%
  pmap_dfr(generate_data_DID) %>% #use pmap to pass the set of parameters
  select(zip, t, treated, starts_with("birthweight"), e, ends_with("fe")) %>% 
  kable()
```

We check the standard deviation and means of the parameters:

```{r check_sd_mean_DID, echo=FALSE}
ex_data <- baseline_param_DID %>% 
  pmap_dfr(generate_data_DID) 

ex_data_mean <- ex_data %>% 
  summarise(across(.cols = c(birthweight0), mean)) %>% 
  mutate(Statistic = "Mean") %>% 
  select(Statistic, everything())

ex_data_sd <- ex_data %>% 
  summarise(across(.cols = c(birthweight0), sd)) %>% 
  mutate(Statistic = "Standard Deviation") %>% 
  select(Statistic, everything())

ex_data_mean %>% 
  rbind(ex_data_sd) %>% 
  kable()

# ex_data %>% 
#   count(treated) %>% 
#   kable()
```

Treatment allocations in the staggered and non staggered case, when the proportion of treated is 30%, are as follows:

```{r treatment_allocation_DID, echo=FALSE}
labs_graph_staggered <- labs(
    title = "Treatment assignment across time and zip codes",
    x = "Time index", 
    y = "Zip code id", 
    fill = "Treatment status"
  )

baseline_param_DID %>% 
  mutate(N_z = 20, N_t = 50, p_treat = 0.3) %>%
  pmap_dfr(generate_data_DID) %>% 
  mutate(treated = ifelse(treated, "Treated", "Not treated")) %>% 
  ggplot(aes(x = t, y = factor(zip), fill = fct_rev(treated))) + 
  geom_tile(color = "white", lwd = 0.3, linetype = 1) +
  coord_fixed() +
  labs_graph_staggered + 
  labs(subtitle = "Non staggered")

baseline_param_DID %>%
  mutate(N_z = 20, N_t = 50, p_treat = 0.3) %>%
  mutate(staggered = TRUE) %>%
  pmap_dfr(generate_data_DID) %>% 
  mutate(treated = ifelse(treated, "Treated", "Not treated")) %>% 
  ggplot(aes(x = t, y = factor(zip), fill = fct_rev(treated))) +
  geom_tile(color = "white", lwd = 0.3, linetype = 1) +
  coord_fixed() +
  labs_graph_staggered +
  labs(subtitle = "Staggered")
```

#### Quick data exploration

We quickly explore a data set generated with our function. First, we look at the distribution of potential outcomes.

```{r eda_distrib_outcome,echo=FALSE}
ex_data %>% 
  pivot_longer(
    cols = c(birthweight0, birthweight1),
    names_to = "potential_outcome",
    values_to = "potential_birthweight"
  ) %>% 
  mutate(potential_outcome = factor(str_remove(potential_outcome, "birthweight"))) %>% 
  ggplot(aes(x = potential_birthweight, fill = potential_outcome, color = potential_outcome)) +
  geom_density() +
  labs(
    x = "Birthweight (in g)",
    y = "Density",
    color = "Potential Outcome",
    fill = "Potential Outcome",
    title = "Distribution of potential birthweight"
  )
```

Then, we compare the average birthweight before and after the treatment, in the control and treatment group.

```{r eda_comparison_treatment,echo=FALSE}
ex_data %>%
  mutate(
    before_after = ifelse(post, "After", "Before"),
    in_treatment = ifelse(in_treatment, "Treatment", "Control")
  ) %>% 
  ggplot(aes(x = fct_rev(before_after), color = in_treatment, y = birthweight)) +
  stat_summary(geom = "pointrange", fun.data = "mean_se") +
  labs(
    x = "Before or after the treatment",
    y = "Average birthweight (in g)",
    color = "Treatment group",
    title = "Comparison of average birthweight",
    subtitle = "Before and after the treatment, depending on treatement status"
  )
```

<!-- ```{r eda_evolution_outcome,echo=FALSE} -->
<!-- ex_data %>% -->
<!--   group_by(in_treatment, t) %>%  -->
<!--   summarize( -->
<!--     mean_birthweight = mean(birthweight), -->
<!--     se_birthweight = sd(birthweight) / sqrt(n()), -->
<!--     CI_up = mean_birthweight + (1.96 * se_birthweight), -->
<!--     CI_low = mean_birthweight + (-1.96 * se_birthweight), -->
<!--     .groups = "drop" -->
<!--   ) %>%  -->
<!--   ggplot(aes(x = t, y = mean_birthweight, color = in_treatment)) + -->
<!--   geom_ribbon( -->
<!--     aes(ymin = CI_low, ymax = CI_up, fill = in_treatment),  -->
<!--     alpha = 0.2,  -->
<!--     color = FALSE -->
<!--   ) + -->
<!--   geom_line() + -->
<!--   ylim(c(2000, 4000))  -->
<!-- ``` -->

### Estimation

After generating the data, we can run an estimation.

```{r estimate_DID}
estimate_DID <- function(data) {
  reg <- data %>% 
    mutate(
      zip = as.factor(zip),
      t = as.factor(t),
      treated = as.numeric(treated),
      in_treatment = as.numeric(in_treatment),
      t_centered = as.factor(t_centered)
    ) %>% 
    feols(
      data = ., 
      fml = birthweight ~ treated | zip + t
    ) %>% 
    broom::tidy() %>% 
    rename(p_value = p.value, se = std.error) %>% 
    select(-statistic) 
    # suppressMessages() #Warning saying that NA values dropped and 
    # #that one or two factors are removed due to colinearity
  
  return(reg)
}
```

```{r one_estimation_DID}
baseline_param_DID %>% 
  pmap_dfr(generate_data_DID) %>%
  estimate_DID() %>% 
  slice(1:15) %>% 
  kable()
```

### One simulation

Note that to run power calculations, we need to have access to the true effects. Therefore, before running the estimation, we write a short function to compute the average treatment effect on the treated (ATET). We will add this information to the estimation results. 

```{r compute_true_effect_DID}
compute_true_effect_DID <- function(data) {
  data %>% 
    filter(treated) %>% 
    summarise(true_effect = mean(birthweight1 - birthweight0)) %>% 
    .$true_effect
}  
```

We can now run a simulation, combining `generate_data_DID` and `estimate_DID`. To do so we create the function `compute_sim_DID`. This simple function takes as input the various parameters. It returns a table with the estimate of the treatment, its p-value and standard error, the true effect, the proportion of treated units and whether the treatment was staggered or not. Note that for now, we do not store the values of the other parameters for simplicity because we consider them fixed over the study.

```{r compute_sim_DID}
compute_sim_DID <- function(N_z,
                            N_t,
                            sigma_e,
                            p_treat,
                            staggered,
                            alpha,
                            beta,
                            mu_zip_fe = 0,
                            sigma_zip_fe = 0,
                            mu_time_fe = 0,
                            sigma_time_fe = 0) {
  data <- generate_data_DID(
    N_z = N_z,
    N_t = N_t,
    sigma_e = sigma_e,
    p_treat = p_treat,
    staggered = staggered,
    alpha = alpha,
    beta = beta,
    mu_zip_fe = mu_zip_fe,
    sigma_zip_fe = sigma_zip_fe,
    mu_time_fe = mu_time_fe,
    sigma_time_fe = sigma_time_fe
  ) 
  
  data %>%
    estimate_DID() %>% 
    mutate(
      N_z = N_z,
      N_t = N_t,
      p_treat = p_treat,
      true_effect = compute_true_effect_DID(data)
    )
} 
```

Here is an example of an output of this function.

```{r example_output_sim_RDD, echo=FALSE}
baseline_param_DID %>%
  pmap_dfr(compute_sim_DID) %>% 
  kable()
```

### All simulations

We will run the simulations for different sets of parameters by mapping our `compute_sim_DID` function on each set of parameters. We thus create a table with all the values of the parameters we want to test, `param_DID`. Note that in this table each set of parameters appears `N_iter` times as we want to run the analysis $n_{iter}$ times for each set of parameters.

```{r set_param_DID, echo=FALSE}
vect_p_treat <- c(0.001, seq(0.002, 0.01, 0.002), c(0.01, 0.02, 0.03))
N_iter <- 100

param_DID <- baseline_param_DID %>% 
  select(-p_treat) %>% 
  crossing(vect_p_treat) %>% 
  rename(p_treat = vect_p_treat) %>% 
  crossing(rep_id = 1:N_iter) %>% 
  select(-rep_id)
```

We then run the simulations by mapping our `compute_sim_IV` function on `param_IV`.

```{r run_sim_DID, eval=FALSE, echo=FALSE}
tic()
sim_DID <- pmap_dfr(param_DID, compute_sim_DID)
beep()
toc()

# saveRDS(sim_DID, here("Outputs/sim_DID.RDS"))
```

## Analysis of the results

### Quick exploration

First, we quickly explore the results.

```{r exploration_results_DID, echo=FALSE, fig.asp=0.7}
sim_DID <- readRDS(here("Outputs/sim_DID.RDS"))

sim_DID %>% 
  filter(p_treat %in% sample(vect_p_treat, 4)) %>%  
  mutate(
    n_treat = p_treat*N_z*N_t,
    # n_treat_name = fct_order(paste("Nb treated:", n_treat),
    N_z = paste("Number zip codes: ", str_pad(N_z, 2)),
    N_t = paste("Number periods: ", str_pad(N_t, 2))
  ) %>% 
  ggplot(aes(x = estimate)) +
  geom_vline(xintercept = unique(sim_DID$true_effect)) +
  geom_density() +
  facet_grid(~ n_treat) +
  labs(
    title = "Distribution of the estimates of the treatment effect",
    subtitle = "For different number of treated observations",
    x = "Estimate of the treatment effect",
    y = "Density",
    caption = "The vertical line represents the true effect"
  )
```

### Computing bias and exaaggeration ratio

We want to compare $\mathbb{E}[\beta_0/\widehat{\beta}]$ and $\mathbb{E}[\beta_0/ \widehat{\beta}|signif]$. The first term represents the bias and the second term represents the 
exaggeration ratio. These terms depend on the true effect size.

```{r summarise_IV}
summarise_sim_DID <- function(data) {
  data %>%
    mutate(significant = (p_value <= 0.05)) %>% 
    group_by(p_treat, N_z, N_t) %>%
    summarise(
      power = mean(significant, na.rm = TRUE)*100, 
      exag_ratio = mean(ifelse(significant, abs(estimate/true_effect), NA), na.rm = TRUE),
      bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),
      bias_all = mean(estimate/true_effect, na.rm = TRUE),
      bias_all_median = median(estimate/true_effect, na.rm = TRUE),
      .groups	= "drop"
    ) %>% 
    ungroup() %>% 
    mutate(n_treated = p_treat*N_z*N_t)
} 

summary_sim_DID <- summarise_sim_DID(sim_DID)
# saveRDS(summary_sim_DID, here("Outputs/summary_sim_DID.RDS"))
```

### Graph

To analyze our results, we build a unique and simple graph:

```{r main_graph_DID, echo=FALSE, fig.asp=0.7}
summary_sim_DID %>% 
  filter(n_treated < 3000) %>% 
  ggplot(aes(x = n_treated, y = bias_signif)) + 
  # geom_point() +
  geom_line(size = 0.8) +
  labs(
    x = "Number of treated observations", 
    y = expression(paste("Average  ", frac("Estimate", "True Effect"))),
    title = "Evolution of bias with the number of treated observations",
    subtitle = "For statistically significant estimates",
    caption = paste("Fixed sample size:",
                    unique(summary_sim_DID$N_z)*unique(summary_sim_DID$N_t),
                    "observations \n")
  ) 
```

```{r main_graph_DID_paper, dpi=600, include=FALSE}
summary_sim_DID %>% 
  filter(n_treated < 3000) %>% 
  ggplot(aes(x = n_treated, y = bias_signif)) + 
  # geom_point() +
  geom_line(size = 0.8) +
  labs(
    x = "Number of treated observations", 
    y = expression(paste("Average  ", frac("Estimate", "True Effect"))),
    caption = paste("Fixed sample size:",
                    unique(summary_sim_DID$N_z)*unique(summary_sim_DID$N_t),
                    "observations \n")
  ) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +
  theme_mediocre(base_family = "Lora") 

ggsave("main_graph_DID_paper.pdf", path = "images", width = 7.4, height = 4.4)
```


<!-- ```{r graph_results_DID, echo=FALSE, fig.asp=0.7} -->
<!-- summary_sim_DID %>%  -->
<!--   mutate( -->
<!--     N_z = as.factor(N_z), -->
<!--     N_t = as.factor(N_t) -->
<!--   ) %>%  -->
<!--   ggplot(aes(x = N_z, y = N_t, fill = exag_ratio)) + -->
<!--   geom_tile(color = "white", lwd = 1, linetype = 1) + -->
<!--   coord_fixed() + -->
<!--   labs( -->
<!--     # title = "Type M error for different number of periods and observation", -->
<!--     title = "The 'balls of yarn' graph", -->
<!--     x = "Number of zip codes", -->
<!--     y = "Number of time periods", -->
<!--     fill = "Exaggeration ratio" -->
<!--   )  -->
<!-- ``` -->


