{
  "articles": [
    {
      "path": "DID.html",
      "title": "Simulations Event study/DID",
      "description": "In this document, we run a simulation exercise to illustrate the loss in power and resulting type M error when the number of events in a Difference In Differences design decreases.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "LÃ©o Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSummary and intuition\nAn illustrative exampleModelisation choices\nData generation\n\n\n\nbody {\ntext-align: justify}\nSummary and intuition\nIn the case of Event studies and DiD, the OVB/type M trade-off is mediated by the number of events.\nAn illustrative example\nFor readability and to illustrate this loss in power, we consider an example setting. For this illustration we could use a large variety of Data Genereting Processes (DGP), both in terms of distribution of the variables and of relations between them. We narrow this down to an example setting, considering an analysis of health impacts of air pollution. Our point should stand in more general settings.\nA threat of confounders often arises when analyzing the health effects of air pollution. To estimate such an effect causally, one can consider exogeneous shocks to air pollution. In the present analysis, we consider the example of plant closures as exogeneous shocks.\nModelisation choices\nIn the present analysis, we build our simulations to replicate an analysis of the causal health effects of air pollution, using plant closures as an exogeneous shifter in air pollution levels. In such analyses, the data is often at the city-daily level. Hospital admissions are usual health outcomes considered in such analyses.\nThe DGP can be represented using the following Directed Acyclic Graph (DAG):\n\n\n\nThis DAG makes it clear that in substance, we are instrumenting air pollution level by plant closure.\nThe DGP for the number of admissions at the hospital in city \\(c\\) at time \\(t\\) is as follows:\n\\[Admissions_{ct} = \\xi + \\gamma Poll_{ct} + \\delta U_{ct} + e_{ct}\\] Where \\(\\xi\\) is a constant, \\(U\\) represents an unobserved variable and \\(e \\sim \\mathcal{N}(0, \\sigma_{e)\\) noise. The DGP for the pollution data is as follows:\n\\[Poll_{ct} = \\mu + \\lambda T_{ct} + \\eta U_{ct} + \\tilde{e}_{ct}\\] Where \\(\\mu\\) is a constant,\\(T_{ct}\\) is the treatment, equal to 1 if there is a plant closure in city \\(c\\) at time \\(t\\) and zero otherwise and \\(\\tilde{e} \\sim \\mathcal{N}(0, \\sigma_{\\tilde{e})\\) noise.\nThe effect of plant closures, the treatment, on health is often estimated using a reduced form approach, regressing health in city \\(c\\) at time \\(t\\) on the treatment. In our case, that yields to estimating the following equation: m \\[Admissions_{ct} = \\alpha + \\beta T_{ct} + \\epsilon_{ct}\\] To simplify, we consider the following assumptions:\nPollution and hospital admissions are not correlated across cities nor time. This is very simplistic but if anything should make it easier to identify the effect of interest,\nThe unobserved variable \\(U\\) is drawn from a normal distribution,\nIn a first step, we consider homogeneous treatment effects\nA proportion \\(p_{treat}\\) of individuals are ever treated over the period. Hence, a proportion of \\(1-p_{treat}\\) individuals are never treated over the period. I draw these individual at random. Note that the value of the individual identifiers do not matter here. So I could assume that the non-treated individuals are those with the larger individual ids for instance,\nThe implementation of the treatment can be staggered or not. If it is not staggered, the treatment date is set to be in the middle of the period\nThe treatment can vary along two dimensions, time and individual. Details are given below.\nMore precisely, I set:\n\\(N_C\\) the number of cities\n\\(N_T\\) the number of periods\n\\(U_{ct} \\sim \\mathcal{N}(\\mu_{u}, \\sigma_{u}^{2})\\)\n\\(e_{it} \\sim \\mathcal{N}(0, \\sigma_{e}^{2})\\), \\(\\tilde{e}_{it} \\sim \\mathcal{N}(0, \\sigma_{\\tilde{e}}^{2})\\) noises\n\\(T_{ct}\\) represent the treatment allocation, it is equal to one if a plant closes in city \\(c\\) at time \\(t\\) and 0 otherwise,\n\\(Poll\\) and \\(Amissions\\) are created as described above\n\\(\\beta_{it}\\) is represents the magnitude of the treatment effect and is linked to the input parameter beta.\nAcross individuals, the treatment can either be:\nhomogeneous: het_indiv == homogeneous, for each individual, the treatment is equal to beta,\nrandom: het_indiv == random, for each individual, the treatment is drawn from \\(\\mathcal{U}(0.5\\beta, 1.5\\beta)\\),\nlarger for those that are treated first: het_indiv == large_first, for each individual, the treatment is equal to \\(N_T - \\beta\\).\n\nAcross time, the effect of the treatment can either be\nconstant: het_time == constant,\nincreasing linearly in time: het_time == linear.\n\n\nI also create a bunch of variables that can be useful:\n\\(InTreatment_i\\) equal to 1 if individual \\(i\\) ever gets treated,\n\\(t^{event}_i\\) equal to the date at which individual \\(i\\) gets treated,\n\\(t^{centered}_i\\) representing the distance in terms of period to the beginning of the treatment for individual \\(i\\),\n\\(Post_{it}\\) equal to 1 if the period \\(t\\) is after the treatment has begun for individual \\(i\\). This variable is only useful for non-staggered treatment allocation,\nData generation\nI write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis.\n\n\ngenerate_data_TWFE <- function(N_C,\n                               N_T,\n                               sigma_e,\n                               p_treat,\n                               staggered,\n                               het_indiv,\n                               het_time,\n                               alpha,\n                               beta,\n                               mu_indiv_fe = 0, \n                               sigma_indiv_fe = 0,\n                               mu_time_fe = 0, \n                               sigma_time_fe = 0,\n                               mu_x = 0, \n                               sigma_x = 0,\n                               gamma = 0\n                             ) {\n\n  if (!is.logical(staggered)) {stop(\"staggered must be logical\")} \n  if (!(het_indiv %in% c(\"large_first\", \"random\", \"homogeneous\"))) {\n    stop('het_indiv must be either \"large_first\", \"random\" or \"homogeneous\"')\n  } \n  if (!(het_time %in% c(\"constant\", \"linear\"))) {\n    stop('het_time must be either \"constant\" or \"linear\"')\n  } \n  \n  data <- tibble(indiv = 1:N_C) %>%\n    mutate(InTreatment = (indiv %in% sample(1:N_C, floor(N_C*p_treat)))) %>% \n    crossing(t = 1:N_T) %>%\n    group_by(indiv) %>%\n    mutate(\n      indiv_fe = rnorm(1, mu_indiv_fe, sigma_indiv_fe),\n      t_event = ifelse(staggered, sample(2:(N_T - 1), 1), floor(N_T/2)), \n        #I use 2:(N_T-1) to have a pre and post period\n      t_event = ifelse(InTreatment, t_event, NA),\n      beta_i = case_when(\n        het_indiv == \"large_first\" ~ N_T-t_event,\n        het_indiv == \"random\" ~ runif(1, beta*0.5, beta*1.5), \n        het_indiv == \"homogeneous\" ~ beta\n      ),\n      beta_i = ifelse(is.na(t_event), 0, beta_i)\n    ) %>%\n    ungroup() %>%\n    group_by(t) %>%\n    mutate(time_fe = rnorm(1, mu_time_fe, sigma_time_fe)) %>%\n    ungroup() %>%\n    mutate(\n      post = (t > t_event),\n      treated = InTreatment & post, \n      beta_i = ifelse(\n        het_time == \"linear\" & post & !is.na(t_event),\n        beta_i*(t - t_event), \n        beta_i\n      ),\n      t_centered = t - t_event,\n      x = rnorm(nrow(.), mu_x, sigma_x),\n      e = rnorm(nrow(.), 0, sigma_e),\n      y0 = alpha + gamma * x + indiv_fe + time_fe + e,\n      y1 = y0 + beta_i,\n      y = treated*y1 + (1 - treated)*y0\n    )\n  \n  return(data)\n}\n\n\n\nI set baseline values for the parameters as very standard. These values are arbitrary.\n\n\nbaseline_parameters_TWFE <- tibble(\n  N_C = 20,\n  N_T = 50,\n  sigma_e = 1,\n  p_treat = 0.8,\n  staggered = TRUE,\n  het_indiv = \"homogeneous\",\n  het_time = \"constant\",\n  alpha = 1,\n  beta = 1\n)\n\n\n\nHere is an example of data created with the data generating process and baseline parameter values, for 2 individuals and 8 time periods:\n\nindiv\nt\ny\nInTreatment\npost\ntreated\nt_centered\ne\n1\n1\n1.2140277\nTRUE\nFALSE\nFALSE\n-5\n0.2140277\n1\n2\n1.3701889\nTRUE\nFALSE\nFALSE\n-4\n0.3701889\n1\n3\n0.8138435\nTRUE\nFALSE\nFALSE\n-3\n-0.1861565\n1\n4\n0.8819648\nTRUE\nFALSE\nFALSE\n-2\n-0.1180352\n1\n5\n0.7806692\nTRUE\nFALSE\nFALSE\n-1\n-0.2193308\n1\n6\n1.5021386\nTRUE\nFALSE\nFALSE\n0\n0.5021386\n1\n7\n2.3844128\nTRUE\nTRUE\nTRUE\n1\n0.3844128\n1\n8\n3.4736383\nTRUE\nTRUE\nTRUE\n2\n1.4736383\n2\n1\n3.3435905\nFALSE\nNA\nFALSE\nNA\n2.3435905\n2\n2\n2.3471761\nFALSE\nNA\nFALSE\nNA\n1.3471761\n2\n3\n1.7639009\nFALSE\nNA\nFALSE\nNA\n0.7639009\n2\n4\n0.5621555\nFALSE\nNA\nFALSE\nNA\n-0.4378445\n2\n5\n1.5164345\nFALSE\nNA\nFALSE\nNA\n0.5164345\n2\n6\n0.5997095\nFALSE\nNA\nFALSE\nNA\n-0.4002905\n2\n7\n-1.0094664\nFALSE\nNA\nFALSE\nNA\n-2.0094664\n2\n8\n1.2326390\nFALSE\nNA\nFALSE\nNA\n0.2326390\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2021-12-09T15:17:13-05:00"
    },
    {
      "path": "experiments.html",
      "title": "Analyzing Experimental Studies for Intuition",
      "description": "In this document, we analyze replication of experimental studies to illustrate the concept of type M error.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "LÃ©o Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLaboratory experimentsAnalyzing all studies\nFocus on one particular study\n\nRandomized Control Trials\n\n\nbody {\ntext-align: justify}\nLaboratory experiments\nFirst, we consider the paper Camerer et al (2016). The authors of this paper replicated laboratory experiments in economics. We analyze their results through the prism of statistical power.\nThey report their replication results, alongside the original results, in table S1 Note that some p-values are strictly smaller than 0.001. As we do not have more information, we set them to 0.001. We also back out the standard errors from the p-values as they will be useful for our analysis.\nWe compute the power of the initial analysis if the true effect is in fact equal to the replicationâs. We store the results in retro_camerer.\n\n\nrep_camerer <- read_excel(here(\"Misc\", \"rep_camerer.xlsx\")) %>% \n  mutate(\n    se_original = effect_original/qnorm(1 - pvalue_original), #incorrect\n    se_rep = effect_rep/qnorm(1 - pvalue_rep) #incorrect\n  ) \n\nretro_camerer <- rep_camerer %>% \n  mutate(\n    se_original = effect_original/qnorm(1 - pvalue_original), #incorrect\n    se_rep = effect_rep/qnorm(1 - pvalue_rep) #incorrect\n  ) %>% \n  select(A = effect_rep, s = se_original) %>% \n  # select(A, s) %>% \n  pmap_dfr(retrodesign) %>% \n  cbind(rep_camerer) %>% \n  as_tibble()\n\n\n\nAnalyzing all studies\nWe quickly plot and analyze the results obtained, ie the distribution of the exaggeration ratio and power.\n\n\n\nThe median power would be 0.38%. The median replicated estimates is equal to 0.62 times the original estimate.\nWe then compute the number and proportion of original studies that were statistically significant.\n\nOriginal estimate statistically significant\nNumber\nProportion\nNo\n2\n0.11\nYes\n16\n0.89\n\nWe then do the same thing for the replication studies.\n\nReplication estimate statistically significant\nNumber\nProportion\nNo\n7\n0.39\nYes\n11\n0.61\n\nWe then compute the proportion of original studies that would have adequate power as defined by the customary and arbitrary 80% threshold, still assuming that the true effect is equal to the replication one.\n\nAdequate power\nNumber\nProportion\nNo\n14\n0.78\nYes\n4\n0.22\n\nFocus on one particular study\nHere, we focus on one particular study in order to illustrate in more details the problem at play. We want to simulate what could have yielded replication of the initial study if the true effect was equal to the replication estimate.\nWe select one of the studies and draw the graph of interest.\n\n\n\nIn red is the estimate from the original study and its 95% confidence interval\nThe estimate is significant and has been published. Yet, it is pretty noisy.\nIn blue is the estimate from the replicated study and its 95% confidence interval\nWe notice that this second estimate is both more precise and smaller than the initial one. It still remains noisy\nLetâs assume that the true effect is actually equal to this second estimate (note that this is unlikely)\nWould the design of the initial study be good enough to detect this true effect? ie if we replicated the initial study, could we reject the null of no effect (knowing that the true effect is equal to the replicated estimate)\nIn gray is the estimate form the replicated study but with a standard error equal to the initial studyâs (approximately the standard errors that would have been obtained with the design of the initial study)\nThis estimate is non significant. In this instance, we would not have been able to reject the null of no effect\nNow, if we replicate this study 500 times, running 500 lab experiments, in some cases we would get statisitcally significant estimates (the beige dots) and in some others non statistically significant ones (the green dots)\nIf we would have been a bit more lucky, we could have gotten a sample of individuals that would have yielded one of the beige estimates\nNow, we notice that, on average, statistically significant estimates overestimate the true effect by a factor 1.7 (average of 0.53 while the true effect is 0.31). Gelman and Carlin call this inflation factor type M error.\nIn this case, the power is basically the proportion of statistically significant estimates\nIf the study had more power, the sd would be smaller and most estimates would be statistically significative (because there is indeed a non null effect)\nBut since the power is low (33%), if by chance the sample of individuals we get yields a statistically significant estimate, this estimate will overestimate the true effect\nRandomized Control Trials\nWe want to look at replications of RCTs in Development Economics. To do so, we use the list of replication papers put together by Sandip Sukhtankar.\nWe gather the list of RCTs that have been replicated in Development Economics.\n\n\nrep_dvpt <- read_dta(here(\"Misc\", \"replication_data_final.dta\"))\n\n# rep_dvpt %>% \n#   filter((RCT == \"Yes\") & (Replicated == \"Replicated\")) %>% \n#   .$ReplicationPaperTitle\n\n\n\n\n\n\n",
      "last_modified": "2021-12-09T15:17:22-05:00"
    },
    {
      "path": "index.html",
      "title": "Unbiased but Inflated Causal Effects",
      "author": [],
      "contents": "\n\n          \n      \n      Unbiased but Inflated Causal Effects\n      \n      \n      Home\n      Intuition\n      \n      \n      Simulations\n       \n      â¾\n      \n      \n      RDD\n      IV\n      Matching\n      DiD / Event study\n      \n      \n      \n      \n      \n      â°\n      \n      \n      \n        \n          \n            \n              \n            \n              Unbiased but Inflated Causal Effects\n            \n            \n              \n                \n                    \n                      \n                         GitHub\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            Hi and welcome!\n            This website gathers code and additional material for the paper âUnbiased but Inflated Causal Effectsâ by Vincent Bagilet and LÃ©o Zabrocki.\n            The website is under construction and the analysis is still at a preliminary stage.\n          \n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Unbiased but Inflated Causal Effects\n            \n            \n              \n                \n                                    \n                    \n                       GitHub\n                    \n                  \n                                  \n              \n            \n            \n              Hi and welcome!\n              This website gathers code and additional material for the paper âUnbiased but Inflated Causal Effectsâ by Vincent Bagilet and LÃ©o Zabrocki.\n              The website is under construction and the analysis is still at a preliminary stage.\n            \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2021-12-09T16:43:14-05:00"
    },
    {
      "path": "IV.html",
      "title": "Simulations IV",
      "description": "In this document, we run a simulation exercise to illustrate the existence of a trade-off between Omitted Variable Bias (OVB) and type M error in the context of an Instrumental Variable (IV) strategy.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "LÃ©o Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSummary and intuition\nAn illustrative exampleModelisation choices\nData generation\nEstimation\nOne simulation\nAll simulations\n\nAnalysis of the resultsQuick exploration\nComputing bias and type M\nGraph\nF-statistic analysis\n\n\n\nbody {\ntext-align: justify}\nSummary and intuition\nIn the case of the IV, the OVB/type M trade-off is mediated by the âstrengthâ of the instrument considered.\nAn illustrative example\nFor readability and to illustrate this loss in power, we consider an example setting. For this illustration we could use a large variety of Data Genereting Processes (DGP), both in terms of distribution of the variables and of relations between them. We narrow this down to an example setting, considering an analysis of health impacts of air pollution. Our point should stand in more general settings.\nA threat of confounders often arises when analyzing the health effects of air pollution. To estimate such an effect causally, one can consider exogeneous shocks to air pollution. In the present analysis, we consider the example of plant closures as exogeneous shocks.\nModelisation choices\nIn the present analysis, we build our simulations to replicate an analysis of the causal health effects of air pollution. In such analyses, in order to avoid potential confounders, researchers often instrument air pollution with exogeneous shocks such as plant closure or thermal inversions for instance. For simplicity we abstract from the panel dimension in this analysis. One can consider that this is an analysis of the impact of life-long exposure to air pollution on health. Again, this illustration is very simplistic and is mostly consider to simplify the understanding of the interactions between the different variables.\nThe DGP can be represented using the following Directed Acyclic Graph (DAG):\n\n\n\nThe DGP for the health status of person \\(i\\) is defined as follows:\n\\[Health_{i} = \\alpha + \\beta Poll_{i} + \\delta u_{i} + e^{(h)}_{i}\\]\nWhere \\(\\alpha\\) is a constant, \\(u\\) represents an unobserved variable and \\(e \\sim \\mathcal{N}(0, \\sigma_{e})\\) noise. \\(\\beta\\) is the parameter of interest.\nThe DGP for the pollution data is as follows:\n\\[Poll_{i} = \\gamma + \\lambda z_{i} + \\eta u_{i} + e^{(p)}_{i}\\] Where \\(\\mu\\) is a constant, \\(z\\) is the instrument for air pollution and \\(\\tilde{e} \\sim \\mathcal{N}(0, \\sigma_{\\tilde{e}})\\) noise. We refer to \\(\\lambda\\) as âIV strengthâ.\nThe effect of air pollution on health is estimated using 2 Stages Least Squares.\n\n\nMore precisely, we set:\n\\(N\\) the number of observations\n\\(z \\sim \\mathcal{N}(0, \\sigma_{z}^{2})\\) or \\(z \\sim \\text{Bernoulli}(p_z)\\) the instrument\n\\(u \\sim \\mathcal{N}(0, \\sigma_{u}^{2})\\) the unobserved variable\n\\(e^{(h)} \\sim \\mathcal{N}(0, \\sigma_{e_h}^{2})\\)\n\\(e^{(p)} \\sim \\mathcal{N}(0, \\sigma_{e_p}^{2})\\)\nData generation\nWe write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis.\nNote that the parameter type_z describes whether z is a random sample from a normal or bernoulli distribution. It can take the values normal or bernoulli. param_z represent either \\(\\sigma_z\\) if \\(z\\) is normal or \\(p_z\\) if it is Bernoulli.\n\n\ngenerate_data_IV <- function(N,\n                             type_z, #\"normal\" or \"bernoulli\"\n                             param_z,\n                             sigma_u,\n                             sigma_eh,\n                             sigma_ep,\n                             alpha_y,\n                             alpha_x,\n                             treatment_effect,\n                             iv_strength,\n                             ovb_intensity\n                             ) {\n  \n  if (type_z == \"bernoulli\") {\n    z_gen <- rbernoulli(N, param_z)\n  } else if (type_z == \"normal\") {\n    z_gen <- rnorm(N, 0, param_z)\n  } else {\n    stop(\"type_z must be either 'bernoulli' or 'normal'\")\n  } \n  \n  data <- tibble(id = 1:N) %>% \n    mutate(\n      z = z_gen,\n      u = rnorm(nrow(.), 0, sigma_u),\n      e_h = rnorm(nrow(.), 0, sigma_eh),\n      e_p = rnorm(nrow(.), 0, sigma_ep),\n      x = alpha_x + iv_strength*z + ovb_intensity*u + e_p,\n      y = alpha_y + treatment_effect*x + ovb_intensity*u + e_h\n    )\n  \n  return(data)\n}\n\n\n\nWe set baseline values for the parameters to emulate a somehow realistic observational study in this field. We add the parameter value for delta separately as we will vary the value later and will reuse the vector baseline_parameters_IV.\n\n\nsimple_parameters_IV <- tibble(\n  N = 500,\n  type_z = \"normal\",\n  param_z = 1,\n  sigma_u = 1,\n  sigma_eh = 1,\n  sigma_ep = 1,\n  alpha_y = 0,\n  alpha_x = 0,\n  treatment_effect = 1\n)\n\n\n\nHere is an example of data created with our data generating process:\n\nid\nz\nu\ne_h\ne_p\nx\ny\n1\n0.3359355\n-0.2595300\n0.1898782\n-0.2709608\n-0.3075857\n-0.2215195\n2\n0.6847179\n0.1951857\n0.2802251\n0.6201045\n0.8351223\n1.1934217\n3\n-0.6778562\n-0.9440614\n1.0060309\n-0.8740092\n-1.3872050\n-0.7587987\n4\n0.2458704\n-0.3813853\n0.2982767\n-0.1176694\n-0.2210494\n-0.0753268\n5\n-2.2438366\n0.0883030\n-0.2943246\n-0.8299922\n-1.2434383\n-1.5024417\n6\n-1.5132234\n1.8949145\n-0.2279403\n-0.4962166\n-0.0408955\n0.4891300\n7\n0.2300917\n0.9501981\n0.6045598\n1.4791693\n1.9052668\n2.8899059\n8\n-0.3780119\n1.3683312\n0.5835288\n0.3572319\n0.8289620\n1.9598233\n9\n0.2912772\n-0.4295165\n0.4466483\n-0.5105156\n-0.6240668\n-0.3492251\n10\n0.7480258\n-0.1659617\n-1.4783329\n1.9211000\n2.0043205\n0.4596029\n\n\n\n\n\n\n\n\n\n\nEstimation\nAfter generating the data, we can run an estimation. We want to compare the IV and the OLS for different IV strength values. Hence, we need to estimate both an IV and an OLS and return both set of outcomes of interest.\n\n\nestimate_IV <- function(data) {\n  reg_IV <- ivreg(\n    data = data, \n    formula = y ~ x | z\n    ) \n  \n  fstat_IV <- summary(\n    reg_IV, \n    diagnostics = TRUE\n  )$diagnostics[\"Weak instruments\", \"statistic\"]\n  \n  reg_IV <- reg_IV %>% \n    broom::tidy() %>%\n    mutate(\n      model = \"IV\",\n      fstat = fstat_IV\n    )\n  \n  reg_OLS <- lm(\n    data = data, \n    formula = y ~ x\n    ) %>% \n    broom::tidy() %>%\n    mutate(\n      model = \"OLS\",\n      fstat = NA\n    )\n  \n  reg_OLS_unbiased <- lm(\n    data = data, \n    formula = y ~ x + u\n    ) %>% \n    broom::tidy() %>%\n    mutate(\n      model = \"OLS unbiased\",\n      fstat = NA\n    )\n  \n  reg <- reg_IV %>% \n    rbind(reg_OLS) %>% \n    rbind(reg_OLS_unbiased) %>% \n    filter(term == \"x\") %>%\n    rename(p_value = p.value, se = std.error) %>%\n    select(estimate, p_value, se, fstat, model) %>% \n  \n  return(reg)\n}\n\n\n\nOne simulation\nWe can now run a simulation, combining generate_data_IV and estimate_IV. To do so we create the function compute_sim_IV. This simple function takes as input the various parameters. It returns a table with the estimate of the treatment, its p-value and standard error, the F-statistic for the IV, the true effect, the IV strength and the intensity of the OVB considered (ovb_intensity). Note for now, that we do not store the values of the other parameters for simplicity because we consider them fixed over the study.\n\n\ncompute_sim_IV <- function(N,\n                           type_z,\n                           param_z,\n                           sigma_u,\n                           sigma_eh,\n                           sigma_ep,\n                           alpha_y,\n                           alpha_x,\n                           treatment_effect,\n                           iv_strength,\n                           ovb_intensity) {\n  generate_data_IV(\n    N = N,\n    type_z = type_z,\n    sigma_u = sigma_u,\n    param_z = param_z,\n    sigma_eh = sigma_eh,\n    sigma_ep = sigma_ep,\n    alpha_y = alpha_y,\n    alpha_x = alpha_x,\n    treatment_effect = treatment_effect,\n    iv_strength = iv_strength,\n    ovb_intensity = ovb_intensity\n  ) %>%\n    estimate_IV() %>%\n    mutate(\n      iv_strength = iv_strength,\n      ovb_intensity = ovb_intensity,\n      true_effect = treatment_effect\n    )\n} \n\n\n\nAll simulations\nWe will run the simulations for different sets of parameters by mapping our compute_sim_IV function on each set of parameters. We thus create a table with all the values of the parameters we want to test param_IV. Note that in this table each set of parameters appears n_iter times as we want to run the analysis \\(n_{iter}\\) times for each set of parameters.\n\n\nbaseline_parameters <- tibble(\n  N = 500,\n  type_z = \"normal\",\n  param_z = 1,\n  sigma_u = 1,\n  sigma_eh = 1,\n  sigma_ep = 1,\n  alpha_y = 0,\n  alpha_x = 0,\n  treatment_effect = 1\n)\n\nfixed_parameters <- baseline_parameters #%>% rbind(...)\nvect_iv_strength <- c(seq(0.05, 0.4, 0.05), seq(0.4, 0.6, 0.1))\n# vect_iv_strength <- c(0.1)\nvect_ovb_intensity <- c(0.4)\nn_iter <- 1\n\nparam_IV <- fixed_parameters %>% \n  crossing(vect_iv_strength, vect_ovb_intensity) %>% \n  rename(iv_strength = vect_iv_strength, ovb_intensity = vect_ovb_intensity) %>% \n  crossing(rep_id = 1:n_iter) %>% \n  select(-rep_id)\n\n\n\nWe then run the simulations by mapping our compute_sim_IV function on param_IV.\n\n\ntic()\nsimulations_IV <- pmap_dfr(param_IV, compute_sim_IV)\nbeep()\ntoc()\n\n# saveRDS(simulations_IV, here(\"Outputs/simulations_IV.RDS\"))\n\n\n\nAnalysis of the results\nQuick exploration\nFirst, we quickly explore the results.\n\n\n\nWe notice that the OLS is always biased and that the IV is never biased. However, for limited IV strengths, the distribution of the estimates flattens. The smaller the IV strength, the most like it is to get an estimate away from the true value, even though the expected value remains equal to the true effect size. \nComputing bias and type M\nWe want to compare \\(\\mathbb{E}[\\beta_0 - \\widehat{\\beta_{i}}]\\) and \\(\\mathbb{E}[|\\beta_0 - \\widehat{\\beta_{IV}}||signif]\\). The first term represents the bias and the second term represents the type M error. This terms depend on the effect size. To enable comparison across simulation and getting terms independent of effect sizes, we also compute the average of the ratios between the estimate and the true effect, conditional on significance.\n\n\nsummarise_simulations <- function(data) {\n  data %>%\n    mutate(significant = (p_value <= 0.05)) %>% \n    group_by(ovb_intensity, iv_strength, model) %>%\n    summarise(\n      power = mean(significant, na.rm = TRUE)*100, \n      type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE),\n      bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      bias_all_median = median(estimate/true_effect, na.rm = TRUE),\n      median_fstat = mean(fstat, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup()\n} \n\nsummary_simulations_IV <- summarise_simulations(simulations_IV)\n# saveRDS(summary_simulations_IV, here(\"Outputs/summary_simulations_IV.RDS\"))\n\n\n\nGraph\nTo analyze our results, we build a unique and simple graph:\n\n\n\nOf course, if one considers all estimates, as the IV is unbiased, this issue does not arise. For now, we consider the median because for very low IV strength, we get very extreme values. We need to investigate this further.\n\n\n\nF-statistic analysis\n\n\n\n\n\nsimulations_IV %>% \n  mutate(significant = (p_value <= 0.05)) %>% \n  ggplot(aes(x = iv_strength, y = fstat, color = significant)) +\n  geom_point() +\n  geom_jitter() +\n  ylim(c(0, 40))\n\n\n\nlm(data = simulations_IV, fstat ~ iv_strength) %>% \n  summary() %>% \n  .$adj.r.squared\n\n\n[1] 0.8486067\n\nlibrary(ggridges)\n\nsimulations_IV %>% \n  mutate(significant = (p_value <= 0.05)) %>% \n  filter(model == \"IV\") %>% \n  ggplot() +\n  geom_density_ridges(aes(x = fstat, y = factor(iv_strength), fill = significant, color = significant), alpha = 0.6)+\n  coord_flip()+\n  xlim(c(0, 50))\n\n\n\n\n\n\nsimulations_IV %>% \n  filter(model == \"IV\") %>%\n  mutate(\n    significant = (p_value <= 0.05),\n    bin_fstat = cut_number(fstat, n = 10) %>% \n      paste() %>% \n      str_extract(\"(?<=,)(\\\\d|\\\\.)+\") %>% \n      as.numeric()\n  ) %>% \n  group_by(ovb_intensity, bin_fstat) %>%\n  summarise(\n    power = mean(significant, na.rm = TRUE)*100, \n    type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE),\n    bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n    bias_all = mean(estimate/true_effect, na.rm = TRUE),\n    bias_all_median = median(estimate/true_effect, na.rm = TRUE),\n    median_fstat = mean(fstat, na.rm = TRUE),\n    .groups  = \"drop\"\n  ) %>% \n  ungroup() %>% \n  ggplot(aes(x = bin_fstat, y = bias_signif)) +\n  geom_line() +\n  geom_vline(xintercept = 10) +\n  xlim(c(0, 100))\n\n\n\n\n\n\n\n",
      "last_modified": "2021-12-10T15:23:23-05:00"
    },
    {
      "path": "Matching.html",
      "title": "Matching Simulations",
      "description": "\"In this document, we run a simulation exercise to illustrate the existence of a trade-off between Omitted Variable Bias (OVB) and type M error in the context of a matching procedure.\"\n",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "LÃ©o Zabrocki",
          "url": "https://lzabrocki.github.io/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPackages Loading\nData Generating ProcedureGeneral Approach\nFunction to Generate the Data\nEDA for One Dataset\n\nOutcome Regression Analysis\nMatching ProcedureProposensity Score Function\nSimulations\n\n\n\nbody {\ntext-align: justify}\nIn this document, we show through simulations the Type M error - omitted variable bias trade-off for observational studies relying on matching methods. We create fake-data similar to those used for analyzing non-randomized labor training program. Should you have any questions or find coding errors, please do not hesitate to reach us at vincent.bagilet@columbia.edu and leo.zabrocki@psemail.eu.\nPackages Loading\nWe first load the required packages to set-up the simulations:\n\n\n# load required packages\nlibrary(knitr) # for creating the R Markdown document\nlibrary(tidyverse) # for data manipulation and visualization\nlibrary(MatchIt) # for matching analysis\nlibrary(lmtest) # for modifying regression standard errors\nlibrary(sandwich) # for robust and cluster robust standard errors\nlibrary(DT) # for displaying the data as tables\nlibrary(mediocrethemes) # vincent's custom ggplot2 theme\nlibrary(tictoc) # for measuring running time\nlibrary(beepr) # for making a sound when the code is done\nlibrary(here)\n\n# set ggplot theme\nset_mediocre_all(pal = \"coty\") #, background = TRUE) #for presentations\n\n\n\nData Generating Procedure\nGeneral Approach\nTo illustrate the the Type M error - OVB trade-off, we simulate fake-data from a non-randomized labor training program targeting young individuals:\nWe first create the units identifiers (id).\nWe then simulate 4 correlated binary covariates:\nThe true propensity score variable true_ps is drawn from \\(N(0.3, 0.1)\\) for control units and from \\(N(0.5, 0.12)\\) for treated units.\nOnce the the true propensity scores are created, we define the potential outcomes of each individual. Here, potential outcomes represent the income (in euros) of the individuals if they undertake the training program or not. The potential outcome without treatment adoption, Y(0), is simulated using the following equation:\ny_0 = 2000 * true_ps + rnorm(n(), mean = 300, sd = 200)\nWe finally simulate the potential outcomes when individuals benefit from the training program. The average treatment effect on the treated (ATT) was set to 100. The average treatment effect on the control (ATC) was set to 50.\nFunction to Generate the Data\nWe display below the code for the function generate_data_matching() which creates the dataset. Its single argument takes the desired sample size.\n\n\ngenerate_data_matching  <- function(sample_size) {\n  data <- tibble(id = 1:sample_size) %>%\n    mutate(\n      treatment = rbinom(n = sample_size, size = 1, prob = 0.25),\n      true_ps = ifelse(\n        treatment == 0,\n        rnorm(n(), mean = 0.3, sd = 0.1),\n        rnorm(n(), mean = 0.5, sd = 0.12)\n      ),\n      true_ps = case_when(true_ps > 1 ~ 1,\n                          true_ps < 0 ~ 0,\n                          true_ps >= 0 & true_ps <= 1 ~ true_ps),\n      # generate the potential outcomes\n      y_0 = 2000 * true_ps + rnorm(n(), mean = 300, sd = 200),\n      y_0 = y_0 %>% round(., 0),\n      y_1 = ifelse(treatment == 1,\n                   y_0 + 100,\n                   y_0 + 50),\n      # generate observed outcomes\n      y_obs = ifelse(treatment == 1, y_1, y_0) %>% round(., 0)\n    )\n  return(data)\n}\n\n\n\nEDA for One Dataset\nWe run one iteration of the function generate_data_matching() to explore the resulting data with 500 units:\n\n\n# run the function for a sample of 500 units\ndata <- generate_data_matching(500)\n\n# display the table\ndatatable(data)\n\n\n\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\",\"201\",\"202\",\"203\",\"204\",\"205\",\"206\",\"207\",\"208\",\"209\",\"210\",\"211\",\"212\",\"213\",\"214\",\"215\",\"216\",\"217\",\"218\",\"219\",\"220\",\"221\",\"222\",\"223\",\"224\",\"225\",\"226\",\"227\",\"228\",\"229\",\"230\",\"231\",\"232\",\"233\",\"234\",\"235\",\"236\",\"237\",\"238\",\"239\",\"240\",\"241\",\"242\",\"243\",\"244\",\"245\",\"246\",\"247\",\"248\",\"249\",\"250\",\"251\",\"252\",\"253\",\"254\",\"255\",\"256\",\"257\",\"258\",\"259\",\"260\",\"261\",\"262\",\"263\",\"264\",\"265\",\"266\",\"267\",\"268\",\"269\",\"270\",\"271\",\"272\",\"273\",\"274\",\"275\",\"276\",\"277\",\"278\",\"279\",\"280\",\"281\",\"282\",\"283\",\"284\",\"285\",\"286\",\"287\",\"288\",\"289\",\"290\",\"291\",\"292\",\"293\",\"294\",\"295\",\"296\",\"297\",\"298\",\"299\",\"300\",\"301\",\"302\",\"303\",\"304\",\"305\",\"306\",\"307\",\"308\",\"309\",\"310\",\"311\",\"312\",\"313\",\"314\",\"315\",\"316\",\"317\",\"318\",\"319\",\"320\",\"321\",\"322\",\"323\",\"324\",\"325\",\"326\",\"327\",\"328\",\"329\",\"330\",\"331\",\"332\",\"333\",\"334\",\"335\",\"336\",\"337\",\"338\",\"339\",\"340\",\"341\",\"342\",\"343\",\"344\",\"345\",\"346\",\"347\",\"348\",\"349\",\"350\",\"351\",\"352\",\"353\",\"354\",\"355\",\"356\",\"357\",\"358\",\"359\",\"360\",\"361\",\"362\",\"363\",\"364\",\"365\",\"366\",\"367\",\"368\",\"369\",\"370\",\"371\",\"372\",\"373\",\"374\",\"375\",\"376\",\"377\",\"378\",\"379\",\"380\",\"381\",\"382\",\"383\",\"384\",\"385\",\"386\",\"387\",\"388\",\"389\",\"390\",\"391\",\"392\",\"393\",\"394\",\"395\",\"396\",\"397\",\"398\",\"399\",\"400\",\"401\",\"402\",\"403\",\"404\",\"405\",\"406\",\"407\",\"408\",\"409\",\"410\",\"411\",\"412\",\"413\",\"414\",\"415\",\"416\",\"417\",\"418\",\"419\",\"420\",\"421\",\"422\",\"423\",\"424\",\"425\",\"426\",\"427\",\"428\",\"429\",\"430\",\"431\",\"432\",\"433\",\"434\",\"435\",\"436\",\"437\",\"438\",\"439\",\"440\",\"441\",\"442\",\"443\",\"444\",\"445\",\"446\",\"447\",\"448\",\"449\",\"450\",\"451\",\"452\",\"453\",\"454\",\"455\",\"456\",\"457\",\"458\",\"459\",\"460\",\"461\",\"462\",\"463\",\"464\",\"465\",\"466\",\"467\",\"468\",\"469\",\"470\",\"471\",\"472\",\"473\",\"474\",\"475\",\"476\",\"477\",\"478\",\"479\",\"480\",\"481\",\"482\",\"483\",\"484\",\"485\",\"486\",\"487\",\"488\",\"489\",\"490\",\"491\",\"492\",\"493\",\"494\",\"495\",\"496\",\"497\",\"498\",\"499\",\"500\"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],[1,1,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,1,1,1,0,0,0,0,0,1,1,0,0,1,0,1,0,1,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,1,0,0,1,1,0,0,1,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,1,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,0,0,0,0],[0.29231738653718,0.294186457573529,0.407626724381555,0.521435949028332,0.561115663820972,0.211626927626907,0.401349519992493,0.471773512229304,0.327186612815485,0.268538188299065,0.205583460778497,0.551421647856606,0.344423125086068,0.461108823510189,0.382609308201497,0.435981792249324,0.149897690388443,0.719400485788951,0.452576908541578,0.417109922523804,0.209099241592774,0.319274099019624,0.125018186464771,0.191293579514546,0.498867467902386,0.367237575994931,0.376695239525238,0.239183860248456,0.369761768851908,0.439775566100925,0.42575067279419,0.304707234617916,0.271063960701782,0.374355372186942,0.451159780410127,0.333025155547924,0.49582783919594,0.407782847480136,0.245492988210575,0.442833808446154,0.307530701943365,0.204799079233294,0.317734413979764,0.30631224948484,0.338039221702224,0.461103563895984,0.395345228374242,0.510494331470082,0.200455743012333,0.407910957616659,0.486931854879905,0.396986872866068,0.29901384715299,0.312195265380099,0.282305888791124,0.385656466117635,0.286016586732253,0.358403568315656,0.712381763480122,0.574213485493768,0.462442456802656,0.486638343828282,0.0816855366149379,0.130296107722194,0.186258888410119,0.12716910338289,0.300638787959209,0.430041741897749,0.520488500056494,0.285855156226489,0.272898943768251,0.437522950549583,0.166686110535623,0.48972755482618,0.35730806708751,0.484727437205537,0.332580380518898,0.397593469086722,0.406114664902668,0.506992945634796,0.379900908081422,0.252846274253537,0.597754258079764,0.350772885010089,0.542439164812382,0.328735773145425,0.356931621836873,0.234435084599661,0.397416427047166,0.314300794945393,0.320362222981322,0.392567959135591,0.187638257411014,0.404563860756933,0.288733238765241,0.436925749564402,0.22959984050921,0.376142141823229,0.574351921978698,0.33050307167323,0.259870617007112,0.181521134249655,0.241489611640095,0.0900045745482627,0.683712378097084,0.185141186758191,0.0956910030482001,0.207398630849497,0.456816811268742,0.317305519740509,0.338762966302919,0.593624238589333,0.396990443080945,0.63231463469788,0.323412361038832,0.374987076999466,0.356960808043597,0.327553591869418,0.273726805632706,0.388929318096242,0.189521197535456,0.425891158944394,0.268091779608806,0.284935901010229,0.279303349069137,0.351982328583962,0.263675037934495,0.156966997628686,0.385481484525194,0.381621026074858,0.225015584630141,0.535049276957557,0.647151571374471,0.605103492003968,0.501800275382648,0.272558524235278,0.455300571700209,0.422420226133955,0.308548464537926,0.213851604622345,0.565731458471831,0.285301399398254,0.488149494118319,0.667384359751801,0.435122804343354,0.348897807075834,0.315876691849968,0.345709570044673,0.374701014573315,0.249777623123437,0.558844902693736,0.401368521749921,0.330557381140564,0.137967876983576,0.422477307098618,0.413769822720959,0.398464951934686,0.338280547137476,0.32122994296945,0.247350986108636,0.1722812087213,0.369336817408539,0.591630392961183,0.294520188148885,0.305547884647518,0.132875793064716,0.185960248414935,0.180145825225243,0.584682858215901,0.4407430129465,0.324345004962799,0.414588882651399,0.348529258548037,0.295069599972799,0.312744974259886,0.328263719265476,0.395854540109495,0.185077847522096,0.651723369587132,0.675837651960901,0.125173726477884,0.23357900848189,0.290933436263512,0.272210313521721,0.282525778689916,0.205825795161959,0.439956640115709,0.113389209837154,0.232772481401332,0.335041225359317,0.514074718919145,0.49028050379689,0.28973359454338,0.263365446873175,0.435529826113203,0.173213972114656,0.188555560486249,0.362970350124686,0.521524757728414,0.3654087771273,0.334926113585899,0.487690255971676,0.162579746630966,0.61001576508735,0.339602412160753,0.114736571953062,0.243551586494763,0.144412954632876,0.263462071177303,0.286460037956825,0.311033237126495,0.211324756773707,0.382595015604748,0.202672840572603,0.142569660034665,0.264410809580056,0.422933093160502,0.489082070652743,0.0827872300647128,0.131355074061778,0.312899946292175,0.350382126165405,0.429745496234132,0.481822200140466,0.185709661485936,0.384192867086943,0.556083950720823,0.438027846522275,0.44892867287648,0.309386850904631,0.684478494157691,0.689769916225087,0.292588319213089,0.197172390295545,0.402587135987834,0.197071279178486,0.355749442178499,0.574630808007834,0.384251836096642,0.441583191539614,0.454852083949714,0.58502072902986,0.120801844253823,0.329521171883782,0.365038954735954,0.423368983167843,0.374376764977709,0.209400231537095,0.302052125930393,0.222133147911903,0.39077092673038,0.40531144645608,0.255624624933238,0.229843906178035,0.386715017289799,0.407375765285646,0.332851068925239,0.645536116480217,0.353506387450338,0.367739722953237,0.302895967001883,0.262582300914563,0.422430531196933,0.328846573481043,0.420152623260791,0.196802143384789,0.325434150150079,0.634579785684397,0.496867605381641,0.0717310778015424,0.248246895086325,0.32168126548815,0.26423193417881,0.479611672299402,0.214965134623533,0.273646267986949,0.269574960164532,0.386477231261313,0.314081465096535,0.54002434951146,0.276555888969724,0.280381862646005,0.437020439235789,0.267593107795633,0.264438400757406,0.461276064237165,0.725628175547971,0.30646145823765,0.313459520033311,0.3405156554546,0.292632861213179,0.562228663878716,0.621290755210621,0.291209354890398,0.366346566319507,0.22892516800731,0.357479494111571,0.289381629746988,0.283322301961949,0.388218574079565,0.271199983808338,0.312592276541985,0.321477785157499,0.570431479319419,0.540498123110513,0.485710675639581,0.56165218049796,0.158871676062892,0.170070894267033,0.305652916062282,0.315225150654429,0.557307285413817,0.394419249427392,0.170923070104525,0.40753997384298,0.164090774148793,0.388546353197919,0.273749492470282,0.278045816507844,0.37359677494567,0.402670168788253,0.318515272241684,0.16812685607106,0.284501939448274,0.259022598037743,0.40622717078526,0.272755899636966,0.51509572415886,0.576227459874523,0.299071899847968,0.416256225450592,0.467900697724546,0.406110133463522,0.634943930224428,0.281092875025124,0.481250768566814,0.515562988495392,0.208327535575283,0.199402830289962,0.523119144694015,0.299446855319203,0.54575475836952,0.276067379155362,0.246178294769652,0.233216180483152,0.356457682835526,0.260911680348564,0.646153212242705,0.419808202835156,0.527102350092398,0.309639516107708,0.59512388504637,0.249954489085168,0.23282305046358,0.292555915568348,0.483691361600738,0.368799720280349,0.340201754035338,0.15320338729403,0.246325936312748,0.292211374300631,0.513972539452959,0.429914350165144,0.413364166445866,0.395460468872391,0.328401627907472,0.276431428090002,0.28506000314374,0.627927500398007,0.365236956571935,0.321039300414674,0.543539757762676,0.188593428349517,0.291066945532387,0.148363944712482,0.483755355172343,0.36012688940463,0.288917222663755,0.568885497100762,0.238092266610064,0.410268881959457,0.395762518489273,0.306326206072389,0.293871830479615,0.343628617202915,0.464218263377483,0.125496286685951,0.490876619799145,0.274343154843409,0.264233718991513,0.637657175687134,0.38541368963352,0.242180409011912,0.379054162723455,0.286185240487428,0.279702335030563,0.424978826598662,0.285209993348181,0.52233929563915,0.402737212361698,0.336858825344575,0.422745229675073,0.369673882844977,0.386850848792018,0.311086604636588,0.27936114889694,0.387235154006669,0.286185436420093,0.353260710099675,0.267162122075322,0.17784852939037,0.281066120266864,0.405849039761126,0.341367035191422,0.42569147716285,0.384254018172895,0.278269388457872,0.208300747312419,0.247465846285415,0.412883402786522,0.518499822382156,0.125450409229761,0.37697126282062,0.24055713824081,0.276732934134997,0.335864521988298,0.310799077167282,0.259209776166474,0.444309667466435,0.461459988395143,0.357380439399749,0.272474250343763,0.279608612487603,0.121376509548082,0.474824115513847,0.565546347664718,0.308577612618959,0.338639451165293,0.116768871615908,0.312914547276538,0.461024340028727,0.566794712360978,0.145165080427103,0.238582281382039,0.575210201735796,0.418851689129883,0.411439340406019,0.252608155217913,0.0733591531517768,0.58725419057955,0.31497086501905,0.295626664728485,0.268755370347527,0.372273423316157,0.255407798547894,0.310570333358699,0.045352274486438,0.331248416131221,0.222821682541168,0.423870441866952,0.328408357379906,0.530981398715524,0.253112500326753,0.350010925780456,0.487544793367574,0.325018085431733,0.721580487566645,0.247985607584585,0.542350497253242,0.54096023264274,0.262741150409406,0.295993263696895,0.316962140416479,0.424759088246271,0.361149148706713,0.384610395495092,0.482732006307162,0.369790813209474,0.348418071857861,0.310385249878162,0.144008134097777,0.433458002304781,0.26864138637069,0.30773537335542,0.186437927580884,0.316026085097644,0.412509929358773,0.382254773111844,0.341684479538118,0.423155202747494,0.291232276751626,0.22183372021675,0.533483255173512,0.318269031239883,0.362708825991656,0.457874018523303,0.300546614617045,0.483677494994483,0.200440334622785,0.451958766756104],[837,614,1257,1584,1265,761,1251,1601,667,1050,394,1501,1027,1529,1006,1338,627,1836,1304,1301,676,577,501,736,1206,1098,1154,895,1120,686,1106,791,773,1125,905,1136,1463,764,808,1236,773,280,1171,766,950,983,1132,1070,514,1274,1396,820,1261,1045,675,1111,719,722,1548,1292,1190,1225,219,655,894,725,1084,1322,1176,930,857,1323,742,1354,978,1389,1330,834,1343,1662,1111,636,1454,1114,1400,642,1097,907,732,746,1139,1104,893,1115,1273,1418,476,846,1447,1115,555,952,691,191,1236,512,719,541,1031,502,1351,1577,1326,2138,1049,1133,1034,1056,846,1299,612,721,815,1085,709,1121,602,720,1028,891,802,1148,1494,1552,1411,629,1336,1219,388,810,1089,1317,1059,1527,1046,1220,996,1238,877,1003,1494,1154,1251,1030,997,1341,1275,919,907,875,722,947,1282,971,1028,254,685,343,1421,1222,657,1167,1185,830,972,1080,1310,679,1652,1580,25,453,1118,766,826,561,1192,550,521,876,1470,1285,666,933,752,643,776,1205,1459,1177,1192,1523,504,1424,1133,376,1188,569,1016,649,527,704,1295,749,612,969,1396,1280,353,420,1074,941,943,686,736,1043,1197,1501,1289,787,1668,1624,1072,823,1127,731,915,1366,1146,957,1355,1425,743,690,838,1283,1312,1033,1148,942,1064,925,725,504,981,1036,930,1399,1065,945,753,811,1021,759,767,725,856,1593,1163,227,546,937,555,1190,786,814,993,1277,717,1030,733,922,1106,363,987,1226,1544,1256,701,1517,900,1533,1445,638,1125,1057,1163,754,1067,1088,934,729,1123,1192,1537,712,1294,696,861,926,673,1545,973,343,887,408,1012,988,657,1237,1433,1168,879,1098,756,1138,952,1464,1488,542,1305,1420,1200,1642,824,989,1070,916,1026,1358,983,1566,886,375,846,1072,992,1517,1019,1434,873,1477,311,825,1325,1214,905,1063,528,446,935,1555,1091,887,920,959,1330,1339,1696,600,791,1613,587,1072,284,1044,914,1045,1467,780,1142,1123,893,1067,1267,1221,342,1335,313,754,1846,1052,959,1138,921,933,966,976,1078,1268,1052,1072,625,1065,863,767,964,971,810,460,636,1007,1219,725,1114,1323,765,987,1077,920,1291,770,826,370,623,1422,1104,759,1022,1236,752,812,1161,555,1379,1234,777,1525,1074,900,1225,1398,743,841,1116,968,1032,609,416,1593,661,957,322,783,619,615,379,839,691,1321,1014,959,786,980,1290,735,1667,520,1061,1406,1017,983,683,1450,1213,755,1026,1099,1116,824,512,1283,632,1211,694,702,1298,811,850,1276,711,738,1382,836,662,1256,1182,947,340,587],[937,714,1357,1684,1365,811,1301,1651,717,1100,444,1601,1077,1579,1056,1388,677,1936,1354,1351,726,627,551,786,1306,1198,1204,945,1170,786,1156,841,823,1175,955,1236,1563,864,858,1286,823,330,1221,816,1000,1033,1232,1120,564,1324,1496,870,1361,1095,725,1161,769,772,1648,1392,1290,1325,269,705,944,775,1134,1422,1276,980,907,1423,792,1454,1028,1489,1380,884,1393,1762,1211,686,1504,1164,1500,692,1147,957,782,796,1189,1154,943,1165,1323,1468,526,896,1547,1165,605,1002,741,241,1336,562,769,591,1131,552,1401,1677,1376,2238,1099,1183,1084,1106,896,1349,662,821,865,1135,759,1171,652,770,1078,941,852,1248,1594,1602,1511,679,1436,1269,438,910,1189,1367,1109,1627,1146,1270,1046,1288,977,1053,1594,1204,1301,1080,1097,1391,1375,969,957,925,772,1047,1332,1021,1078,304,735,393,1521,1272,707,1267,1235,880,1072,1130,1360,729,1752,1680,75,503,1168,816,876,611,1292,600,571,926,1570,1385,716,983,852,693,826,1255,1559,1227,1242,1573,554,1524,1183,426,1238,619,1066,699,577,754,1345,799,662,1019,1446,1330,403,470,1124,991,993,736,786,1093,1247,1601,1339,837,1768,1724,1122,873,1177,781,965,1466,1196,1007,1455,1525,793,740,938,1333,1362,1083,1198,992,1114,975,775,554,1031,1086,1030,1499,1115,995,803,861,1071,809,817,775,906,1693,1213,277,596,987,655,1290,836,864,1043,1327,767,1130,783,1022,1156,413,1037,1276,1644,1306,751,1567,950,1633,1495,688,1175,1107,1213,804,1117,1138,984,779,1173,1292,1587,812,1394,746,911,1026,723,1645,1023,393,937,458,1062,1038,707,1287,1483,1218,929,1148,806,1188,1002,1564,1538,592,1355,1470,1300,1742,874,1089,1170,966,1076,1458,1033,1666,936,425,896,1122,1042,1617,1069,1534,923,1577,361,875,1375,1314,955,1113,578,496,985,1655,1141,937,1020,1009,1380,1439,1796,650,841,1713,687,1122,334,1144,1014,1095,1567,830,1192,1223,943,1117,1317,1271,392,1435,363,804,1946,1102,1059,1188,971,983,1016,1026,1178,1318,1102,1122,675,1165,913,817,1014,1021,910,510,686,1057,1269,775,1214,1373,815,1037,1127,1020,1391,820,926,420,673,1472,1154,809,1072,1286,802,862,1211,605,1479,1334,827,1625,1124,950,1275,1448,793,891,1216,1018,1082,659,466,1693,711,1007,372,883,669,665,429,889,741,1371,1064,1059,836,1030,1340,785,1767,570,1161,1506,1067,1033,733,1500,1263,855,1076,1149,1166,874,562,1333,682,1261,744,752,1398,911,900,1326,761,788,1482,886,712,1356,1232,997,390,637],[937,714,1357,1684,1365,761,1251,1601,667,1050,394,1601,1027,1529,1006,1338,627,1936,1304,1301,676,577,501,736,1306,1198,1154,895,1120,786,1106,791,773,1125,905,1236,1563,864,808,1236,773,280,1171,766,950,983,1232,1070,514,1274,1496,820,1361,1045,675,1111,719,722,1648,1392,1290,1325,219,655,894,725,1084,1422,1276,930,857,1423,742,1454,978,1489,1330,834,1343,1762,1211,636,1454,1114,1500,642,1097,907,732,746,1139,1104,893,1115,1273,1418,476,846,1547,1115,555,952,691,191,1336,512,719,541,1131,502,1351,1677,1326,2238,1049,1133,1034,1056,846,1299,612,821,815,1085,709,1121,602,720,1028,891,802,1248,1594,1552,1511,629,1436,1219,388,910,1189,1317,1059,1627,1146,1220,996,1238,977,1003,1594,1154,1251,1030,1097,1341,1375,919,907,875,722,1047,1282,971,1028,254,685,343,1521,1222,657,1267,1185,830,1072,1080,1310,679,1752,1680,25,453,1118,766,826,561,1292,550,521,876,1570,1385,666,933,852,643,776,1205,1559,1177,1192,1523,504,1524,1133,376,1188,569,1016,649,527,704,1295,749,612,969,1396,1280,353,420,1074,941,943,686,736,1043,1197,1601,1289,787,1768,1724,1072,823,1127,731,915,1466,1146,957,1455,1525,743,690,938,1283,1312,1033,1148,942,1064,925,725,504,981,1036,1030,1499,1065,945,753,811,1021,759,767,725,856,1693,1163,227,546,937,655,1290,786,814,993,1277,717,1130,733,1022,1106,363,987,1226,1644,1256,701,1517,900,1633,1445,638,1125,1057,1163,754,1067,1088,934,729,1123,1292,1537,812,1394,696,861,1026,673,1645,973,343,887,408,1012,988,657,1237,1433,1168,879,1098,756,1138,952,1564,1488,542,1305,1420,1300,1742,824,1089,1170,916,1026,1458,983,1666,886,375,846,1072,992,1617,1019,1534,873,1577,311,825,1325,1314,905,1063,528,446,935,1655,1091,887,1020,959,1330,1439,1796,600,791,1713,687,1072,284,1144,1014,1045,1567,780,1142,1223,893,1067,1267,1221,342,1435,313,754,1946,1052,1059,1138,921,933,966,976,1178,1268,1052,1072,625,1165,863,767,964,971,910,460,636,1007,1219,725,1214,1323,765,987,1077,1020,1391,770,926,370,623,1422,1104,759,1022,1236,752,812,1161,555,1479,1334,777,1625,1074,900,1225,1398,743,841,1216,968,1032,609,416,1693,661,957,322,883,619,615,379,839,691,1321,1014,1059,786,980,1290,735,1767,520,1161,1506,1017,983,683,1450,1213,855,1026,1099,1116,824,512,1283,632,1211,694,702,1398,911,850,1276,711,738,1482,836,662,1356,1182,947,340,587]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>id<\\/th>\\n      <th>treatment<\\/th>\\n      <th>true_ps<\\/th>\\n      <th>y_0<\\/th>\\n      <th>y_1<\\/th>\\n      <th>y_obs<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5,6]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\nAbout 25% of units are treated. We display below the true propensity score distributions by treatment status:\n\n\n\nWe can finally see how the observed revenue is distributed across the two groups:\n\n\n\nAnd we can check whether the ATT and ATC were correctly simulated. The ATT is computed such as:\n\n\n# checking att\nmean(data$y_1[data$treatment==1]) - mean(data$y_0[data$treatment==1])\n\n\n[1] 100\n\nand the ATC:\n\n\n# checking atc\nmean(data$y_1[data$treatment==0]) - mean(data$y_0[data$treatment==0])\n\n\n[1] 50\n\nThe data have been simulated as we wanted.\nOutcome Regression Analysis\nWhat would happen if we analyze our simulated datasets with a simple outcome regression model? Would we recover the true answer?\nWe first create a regression function to run a simple regression model where we simply regress the observed income on the treatment indicator:\n\n\noutcome_regression <- function(data) {\n  data %>%\n    lm(\n      y_obs ~ treatment,\n      data = .\n    ) %>%\n    broom::tidy(., conf.int = TRUE) %>%\n    filter(term == \"treatment\") %>%\n    select(estimate, p.value, conf.low, conf.high)\n}\n\n\n\nWe then simulate 1000 datasets of 500 units and run the regression model:\n\n\n# first simulate simulation id\ndata_simulations <- tibble(sim_id = 1:1000) %>%\n# then simulate data\n  mutate(data = map(sim_id, ~ generate_data_matching(500))) %>%\n# finally run the reg analysis\n  mutate(results = map(data, ~ outcome_regression(.)))\n\n# unnest the results\ndata_simulations <- data_simulations %>%\n  select(-data) %>%\n  unnest(results)\n\n\n\nWe plot the distribution of estimates:\n\n\ndata_simulations %>%\n  ggplot(., aes(x = estimate)) +\n  geom_density(colour = NA) +\n  geom_vline(xintercept = mean(data_simulations$estimate)) +\n  geom_vline(xintercept = 100, colour = \"#EAA95C\") +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  xlab(\"Revenue (in euros)\") + ylab(\"\") +\n  labs(fill = 'Status:') +\n  theme(panel.grid.major.y = element_blank(),\n        axis.text.y = element_blank())\n\n\n\n\nThe average of estimates is equal to 500.\nMatching Procedure\nWe now implement a simple matching where:\nWe implement below a propensity score matching procedure where:\neach treated is matched to its most similar control unit. This is a 1:1 nearest neighbor matching without replacement.\nthe distance metric used for the matching is the propensity score.\nTo see how the bias, statistical power and type M error evolve, we vary the matching distance (the caliper), which is expressed in standard deviation of the propensity score distribution.\nProposensity Score Function\nWe display the below the code for the function ps_function() which runs the matching procedure. It takes to inputs: (i) a dataset and (ii) the value of the caliper.\n\n\n# propensity score analysis function\nps_function <- function(data, caliper_value) {\n  matching_results <- matchit(\n    treatment ~ id,\n    distance = data$true_ps,\n    caliper = caliper_value,\n    data = data\n  )\n  \n  data_matched <- match.data(matching_results)\n  \n  proportion_matched <- sum(data_matched$treatment)/sum(data$treatment)*100\n  \n  true_effect <-\n    mean(data_matched$y_1[data_matched$treatment == 1]) - mean(data_matched$y_0[data_matched$treatment == 1])\n  \n  model_fit <- lm(\n    y_obs ~ treatment,\n    data = data_matched,\n    weights = weights\n  )\n  \n  ps_att <- broom::tidy(coeftest(model_fit, vcov. = vcovCL, cluster = ~ subclass),\n                        conf.int = TRUE) %>%\n    filter(term == \"treatment\") %>%\n    select(term, estimate, p.value, conf.low, conf.high)\n  \n  return(bind_cols(ps_att, proportion_matched = proportion_matched, true_effect = true_effect))\n}\n\n\n\nWe run the function on the data we previously created:\n\n\n# testing the function\nps_function(data, caliper = 0.5)\n\n\n\nThe function returns the estimate for the ATT, the associated \\(p\\)-value and 95% confidence interval, the portion of matched treated unit and the true value of the ATT.\nSimulations\nWe implement Monte-Carlo simulatiuons for a sample size of 300 units and differents values of the caliper:\n\n\ndata_simulations <- tibble(sim_id = 1:300) %>%\n  # then simulate data\n  mutate(data = map(sim_id, ~ generate_data_matching(300))) %>%\n  # generate caliper\n  crossing(caliper = c(seq(from = 1, to = 100, by = 1)/100)) %>%\n  # finally run the matching analysis\n  mutate(results = map2(data, caliper, ~ ps_function(.x, .y)))\n\n# unnest results\nsimulations_matching <- data_simulations %>% \n  select(-data) %>%\n  unnest(results)\n\n# saveRDS(simulations_matching, here(\"Outputs/simulations_matching.RDS\"))\n\n\n\nOnce the simulations have been run, we compute the summary statistics using the summarise_simulations() function:\n\n\nsimulations_matching <- readRDS(here(\"Outputs/simulations_matching.RDS\"))\n\nsummarise_simulations_matching <- function(data) {\n  data %>%\n    mutate(significant = (p.value <= 0.05)) %>% \n    group_by(caliper) %>%\n    summarise(\n      proportion_matched = mean(proportion_matched),\n      power = mean(significant, na.rm = TRUE)*100, \n      bias_sign = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup()\n} \n\n\n\nWe apply the function to data_simulations:\n\n\nsummary_simulations_matching <- summarise_simulations_matching(simulations_matching)\n\n\n\nAnd plot the results:\n\n\n\n\n\n\n",
      "last_modified": "2021-12-09T15:17:56-05:00"
    },
    {
      "path": "RDD.html",
      "title": "Simulations RDD",
      "description": "In this document, we run a simulation exercise to illustrate the existence of a trade-off between Omitted Variable Bias (OVB) and type M error in the context of a Regression Discontinuity Design (RDD).",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "LÃ©o Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSummary and intuition\nAn illustrative exampleModelisation choices\nData generation\nDefining the bandwidth\nEstimation\nOne simulation\nAll simulations\n\nAnalysis of the resultsQuick exploration\nComputing bias and type M\nGraph\n\n\n\nbody {\ntext-align: justify}\nSummary and intuition\nIn the case of the RDD, the OVB/type M trade-off is mediated by the size of the bandwidth considered in the analysis. The underlying idea is that the smaller the bandwidth, the more comparable units are and therefore the smaller the risk of OVB is. Yet, with a smaller bandwidth, sample size and thus power decrease, increasing type M error.\nAn illustrative example\nTo illustrate this trade-off between OVB and type M error, we consider a standard application of the RD design in economics of education where an grant or additional lessons are assigned based on the score obtained by students on a standardized test. Students with test scores below a given threshold receive the treatment while those above do not. Yet, students far above and far below the threshold may differ along unobserved characteristics such as ability. To limit this bias, the effect of the treatment is estimated by comparing the outcomes of students just below and just above this threshold. This enable to limit disparities in terms of unobserved characteristics.\nThistlewaite and Campbell (1960) introduced the concept of RDD using this type of quasi-experiment. In their paper, they take advantage of a sharp discontinuity in the assignment of an award (a Certificate of Merit) based on qualifying scores at a test. This type of analysis is still used today and many papers leveraging similar methodologies have been published since this seminal work. For instance, Jacob and Lefgren (2004) exploit this type of discontinuity to study the impact of summer school and grade retention programs on test scores. Students who score below a given score are required to attend a summer school and to retake the test. Students who do not pass the second have to repeat the grade.\nModelisation choices\nIn the present analysis, we build our simulations to replicate a similar type of quasi-experiment. In our fictional example, all students scoring below a cutoff \\(C\\) in a qualification test are required to take additional lessons. We want to estimate the effect of these additional lessons on scores on a final test taken by all students a year later.\nWe assume that the final score of student \\(i\\), \\(Final_i\\), is correlated with their qualification score \\(Qual_i\\) and their treatment status \\(T_i\\), ie whether student \\(i\\) received additional lessons or not. We further assume that both qualification and final test scores are affected by studentsâ unobserved ability \\(U_i\\) in a non linear way.\nThe DGP can be represented using the following Directed Acyclic Graph (DAG):\n\n\n\nFinal test scores are thus defined as follows:\n\\[Final_{i} = \\alpha + \\beta T_i + \\gamma Qual_{i} +  \\delta f(U_i) + \\epsilon_{i}\\] Where \\(\\alpha\\) is a constant, \\(f\\) a non linear function and \\(e \\sim \\mathcal{N}(0, \\sigma_{e})\\) noise. The parameter of interest is \\(\\beta\\). Translating this into a potential outcomes framework, we have \\(Final_i(0) = \\alpha + \\gamma Qual_{i} + \\delta f(U_i) + \\epsilon_{i}\\) and \\(Final_i(1) = \\alpha + \\gamma Qual_{i} + \\beta + \\delta f(U_i) + \\epsilon_{i}\\)\n\nTo simplify, we consider the following assumptions:\nFull compliance and a sharp treatment allocation such that \\(T_i = \\mathbb{I}[Qual_{i} < C]\\). All students with a qualification score below the threshold are treated and receive additional lessons. None of the students with a qualification score above the threshold are treated.\nThe unobserved ability affects qualification and final test scores in a cubic way. A large ability has a strong positive impact on test scores. Similarly a particularly low ability strongly impacts test scores negatively. An average ability does not have much impact on test scores. Such a functional form seems realistic. Note that ability creates an OVB only if it has a non linear impact on test scores.\nWe assume constant treatment effects. This assumption is not necessary and our results hold if we consider non-constant treatment effects. We thus may drop this assumption in the future.\nWe assume that the unobserved availability affects the qualification and final score in a similar way and therefore with the same intensity \\(\\delta\\).\nMore precisely, we set:\n\\(N\\) the number of students\n\\(U \\sim \\mathcal{N}(0, \\sigma_u^{2})\\) the unobserved ability.\n\\(Qual_i = H_i + \\delta U_i^{3}\\) where \\(H \\sim \\mathcal{N}(\\mu_h, \\sigma_h^{2})\\). We center the qualification scores such that treated units are below 0 and non treated ones above.\n\\(T_i = \\mathbb{I}[Qual_{i} < q_c]\\) where for now and for simplicity, \\(q_c\\) is a fixed grade threshold given as the quantile in the qualification score distribution.\n\\(e \\sim \\mathcal{N}(0, \\sigma_e^2)\\)\n\\(Final_{i} = \\alpha + \\beta T_i + \\gamma Qual_{i} + \\delta U_i^{3} + e_{i}\\)\nData generation\nWe write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis.\nOnce the fake data is generated, to make things more realistic we consider our data as if it was actual data. We do not take advantage of our knowledge of the data generating process in the estimation procedure. However, we observe both potential outcomes and the unobserved ability. Note that, in a real world setting, one would generally know the value of the threshold (and thus of \\(q_c\\)). Based on that and to simplify the computation of the bandwidth, we store \\(q_c\\).\n\n\ngenerate_data_rdd <- function(N, \n                              sigma_u,\n                              mu_h, \n                              sigma_h, \n                              sigma_e, \n                              alpha, \n                              beta,\n                              gamma,\n                              delta,\n                              q_c) {\n  \n  data <- tibble(id = 1:N) %>% \n    mutate(\n      # qual = rnorm(nrow(.), mu_h, sigma_h),\n      # u = rnorm(nrow(.), 0.5, sigma_u) + qual + 0.3*qual^3,\n      u = rnorm(nrow(.), 0, sigma_u),\n      qual = rnorm(nrow(.), mu_h, sigma_h) + delta*u^2,\n      e = rnorm(nrow(.), 0, sigma_e),\n      # qual_c = qual - quantile(qual, q_c),\n      # treated = qual_c < 0,\n      # threshold = quantile(qual, q_c),\n      treated = qual < quantile(qual, q_c),\n      final0 = alpha + gamma*qual + delta*u^2 + e,\n      final1 = final0 + beta,\n      final = final0 + beta*treated,\n      q_c = q_c\n    )\n  \n  return(data)\n}\n\n\n\nWe set baseline values for the parameters to emulate a somehow realistic observational study in this field. The set of parameters may produce test score outside of the range 0-100 in some iterations but that does not affect the analysis. We add the parameter value for delta separately as we will vary the value later and will reuse the vector baseline_parameters_RDD.\n\n\nbaseline_parameters_RDD <- tibble(\n  N = 1000,\n  sigma_u = 0.5,\n  mu_h = 75,\n  sigma_h = 7,\n  sigma_e = 4,\n  alpha = 20,\n  beta = 1,\n  gamma = 0.7,\n  q_c = 0.5\n)\n\n\n\nHere is an example of data created with our data generating process:\n\nid\nu\nqual\ne\ntreated\nfinal0\nfinal1\nfinal\nq_c\n1\n-0.0561379\n77.75372\n3.6872381\nFALSE\n78.11800\n79.11800\n78.11800\n0.5\n2\n0.1936508\n78.39593\n-3.1487619\nFALSE\n71.76589\n72.76589\n71.76589\n0.5\n3\n0.2701340\n67.27245\n0.8407204\nTRUE\n68.00441\n69.00441\n69.00441\n0.5\n4\n-1.0965401\n91.56906\n6.0414575\nFALSE\n91.34220\n92.34220\n91.34220\n0.5\n5\n-0.8345227\n59.84838\n2.2718245\nTRUE\n64.86212\n65.86212\n65.86212\n0.5\n6\n0.7072641\n82.92252\n-1.7820991\nFALSE\n76.76388\n77.76388\n76.76388\n0.5\n7\n0.2517388\n69.98549\n0.3660469\nTRUE\n69.41926\n70.41926\n70.41926\n0.5\n8\n0.6270646\n74.32432\n-5.7997304\nFALSE\n66.62050\n67.62050\n66.62050\n0.5\n9\n0.7438277\n64.87078\n-1.9359102\nTRUE\n64.02692\n65.02692\n65.02692\n0.5\n10\n-0.0868660\n68.05755\n0.9911264\nTRUE\n68.63896\n69.63896\n69.63896\n0.5\n\nDefining the bandwidth\nIn a RDD, the model is estimated only for observations close enough to the threshold, ie in a given bandwidth. We therefore create a function to define this bandwidth by adding a variable to the data set treated_bw that is equal to NA if the observations is outside of the bandwidth, TRUE if the observation falls in the bandwidth and the student is treated and FALSE if the observation falls in the bandwidth and the student is not treated. The bandwidth parameter bw represents the proportion of units that are in the bandwidth. If bw = 0.1, 10% of the students are in the bandwidth for instance.\n\n\ndefine_bw <- function (data, bw) {\n  data <- data %>% \n    mutate(\n      treated_bw = ifelse(\n        dplyr::between(\n          qual, \n          quantile(qual, unique(q_c) - bw/2), \n          quantile(qual, unique(q_c) + bw/2)\n        ), \n        treated, \n        NA\n      )\n    )\n} \n\n\n\nThe following graph illustrates this process by plotting final test scores against qualification ones depending on the value of treated_bw.\n\n\n\nEstimation\nAfter generating the data, we can run an estimation.\nNote that to run power calculations, we need to have access to the true effects. Therefore, before running the estimation, we write a short function to compute the average treatment effect on the treated (ATET). We will add this information to the estimation results.\n\n\ncompute_true_effect_rdd <- function(data) {\n  treated_data <- data %>% \n    filter(treated) \n  return(mean(treated_data$final1 - treated_data$final0))\n}  \n\n\n\nWe then run the estimation. To do so, we only consider observations within the bandwidth and regress the final test scores on the treatment, the qualification score and their interaction. Note that we include this interaction term to allow more flexibility and to mimic an realistic estimation. Yet, we know that this interaction term does not appear in the DGP. Including it or not do not change the results. Also note that, of course, we do not include the unobserved ability in this model to create an OVB.\n\n\nestimate_rdd <- function(data, bw) {\n  data_in_bw <- data %>% \n    define_bw(bw = bw) %>% \n    filter(!is.na(treated_bw))\n  \n  reg <- lm(\n    data = data_in_bw, \n    formula = final ~ treated + qual\n  ) %>% \n    broom::tidy() %>%\n    filter(term == \"treatedTRUE\") %>%\n    rename(p_value = p.value, se = std.error) %>%\n    select(estimate, p_value, se) %>%\n    mutate(\n      true_effect = compute_true_effect_rdd(data),\n      bw = bw\n    )\n  \n  return(reg)\n}\n\n\n\nOne simulation\nWe can now run a simulation, combining generate_data_rdd and estimate_rdd. To do so we create the function compute_sim_RDD. This simple function takes as input the various parameters along with a vector of bandwidth sizes, vect_bw. If we want to run several simulations with different bandwidths, we can reuse the same data, hence why we allow to passing a vector of bandwidths and not only one bandwidth. The function returns a table with the estimate of the treatment, its p-value and standard error, the true effect and the bandwidth and intensity of the OVB considered (delta). Note for now, that we do not store the values of the other parameters for simplicity because we consider them fixed over the study.\n\n\ncompute_sim_RDD <- function(N,\n                            sigma_u,\n                            mu_h,\n                            sigma_h,\n                            sigma_e,\n                            alpha,\n                            beta,\n                            gamma,\n                            delta,\n                            q_c,\n                            vect_bw) {\n  \n  data <- generate_data_rdd(\n    N = N,\n    sigma_u = sigma_u,\n    mu_h = mu_h,\n    sigma_h = sigma_h,\n    sigma_e = sigma_e,\n    alpha = alpha,\n    beta = beta,\n    gamma = gamma,\n    delta = delta,\n    q_c = q_c\n  ) \n  \n  map_dfr(vect_bw, estimate_rdd, data = data) %>%\n    mutate(delta = delta)\n} \n\n\n\nHere is an example of an output of this function.\n\n# A tibble: 2 x 6\n  estimate p_value    se true_effect    bw delta\n     <dbl>   <dbl> <dbl>       <dbl> <dbl> <dbl>\n1     4.23 0.00553  1.49           1   0.1     1\n2     1.91 0.0882   1.11           1   0.2     1\n\nAll simulations\nWe will run the simulations for different sets of parameters by mapping our compute_sim_RDD function on each set of parameters. We thus create a table with all the values of the parameters we want to test param_rdd. Note that in this table each set of parameters appears n_iter times as we want to run the analysis \\(n_{iter}\\) times for each set of parameters.\n\n\nsimple_parameters_RDD <- tibble(\n  N = 500,\n  sigma_u = 1,\n  mu_h = 0,\n  sigma_h = 1,\n  sigma_e = 0.5,\n  alpha = 1,\n  beta = 1,\n  gamma = 0.7,\n  q_c = 0.5\n)\n\nfixed_parameters_RDD <- simple_parameters_RDD #%>% rbind(...)\n# vect_bw <- seq(0.05, 0.4, 0.05)\nvect_bw <- c(seq(0.05, 0.4, 0.05), seq(0.4, 1, 0.1))\nvect_delta <- c(3)\nn_iter <- 1000\n\nparam_rdd <- fixed_parameters_RDD %>% \n  crossing(delta = vect_delta) %>% \n  mutate(vect_bw = list(vect_bw)) %>% \n  crossing(rep_id = 1:n_iter) %>% \n  select(-rep_id)\n\n\n\nWe then run the simulations by mapping our compute_sim_RDD function on param_rdd.\n\n\ntic()\nsimulations_rdd <- pmap_dfr(param_rdd, compute_sim_RDD)\nbeep()\ntoc()\n\n# saveRDS(simulations_rdd, here(\"Outputs/simulations_rdd.RDS\"))\n\n\n\nAnalysis of the results\nQuick exploration\nFirst, we quickly explore the results.\n\n\n\nComputing bias and type M\nWe want to compare \\(\\mathbb{E}[\\beta_0 - \\widehat{\\beta_{RDD}}]\\) and \\(\\mathbb{E}[|\\beta_0 - \\widehat{\\beta_{RDD}}||signif]\\). The first term represents the bias and the second term represents the type M error. This terms depend on the effect size. To enable comparison across simulation and getting terms independent of effect sizes, we also compute the average of the ratios between the estimate and the true effect, conditional on significance.\n\n\nsummarise_simulations <- function(data) {\n  data %>%\n    mutate(significant = (p_value <= 0.05)) %>% \n    group_by(delta, bw) %>%\n    summarise(\n      power = mean(significant, na.rm = TRUE)*100, \n      type_m = mean(ifelse(significant, abs(estimate - true_effect), NA), na.rm = TRUE),\n      bias_sign = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup()\n} \n\nsummary_simulations_rdd <- summarise_simulations(simulations_rdd)\n# saveRDS(summary_simulations_rdd, here(\"Outputs/summary_simulations_rdd.RDS\"))\n\n\n\nGraph\nTo analyze our results, we build a unique and simple graph:\n\n\n\n\n\n\n",
      "last_modified": "2021-12-09T15:18:03-05:00"
    }
  ],
  "collections": []
}
