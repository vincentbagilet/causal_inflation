{
  "articles": [
    {
      "path": "crosscutting-issues.html",
      "title": "Simulations for crosscutting issues",
      "description": "In this document, we run a simulation exercise to illustrate crosscutting type M issues arising in causal and non-causal identification studies.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSummary and intuition\nAn illustrative exampleModeling choices\nData generation\nEstimation\nOne simulation\nAll simulations\n\nAnalysis of the results (proportion treated units)Quick exploration\nComputing bias and type M\nTHE graph\n\nVarying the number of clusters\n\n\nbody {\ntext-align: justify}\n\n\n\nSummary and intuition\nPower and thus type M error can also be affected by aspects that are not proper to one particular identification strategy. In this document we investigate the impact of different factors:\nThe proportion of unit treated (at number of observations constant). We all know that power is maximized when the proportion of units treated is 0.5. The further away we are from this value, the smaller the power and the larger the exaggeration ratio. (I am not certain, I need to check the formula but) The intuition is that a limited number of treated, or control, limits the variation used to estimate the effect.\nLimiting the variation in y (small number of counts in y)\nThe number of clusters. Considering a small number of clusters is to some extent comparable to considering a small number of units and thus partly acts as limiting the number of observations, thus decreasing power and increasing the exaggeration ratio.\nAn illustrative example\nFor readability and to illustrate this loss in power, we consider an example setting. For this illustration we could consider a large variety of distribution parameter for the variables. We narrow this down to an example setting, considering an analysis of the impact of voter turnout on election results, instrumenting voter turnout with rainfall on the day of the election. Our point should stand in more general settings and the choice of values is mostly for illustration.\nModeling choices\nFor simplicity, we consider several assumptions. These assumptions is not representative of the existing literature but the objective is only to calibrate our simulation with somehow realistic parameter values. Again, this illustration is very simplistic. The high level assumptions are:\nFor now, we consider only standard normal distributions\nThe DGP can be represented using the following Directed Acyclic Graph (DAG):\n\n\n\nWe thus assume that the outcome \\(y\\) for individual \\(i\\) is defined as follows:\n\\[y_{i} = \\alpha + \\beta T_{i} + \\delta u_{i} + \\epsilon_{i}\\]\nWhere \\(\\alpha\\) is a constant, \\(T_{i}\\) a dummy equal to 1 if individual \\(i\\) is treated and if they are not treated, \\(\\beta\\) the treatment effect size, \\(u\\) an unobserved variable, \\(\\delta\\) the intensity of the OVB and \\(\\epsilon\\) an error term.\nMore precisely, we set:\n\\(N\\) the number of observations \n\\(T_i = \\mathbb{1}\\{i\\text{ is treated}\\}\\) the treatment dummy. \\(p_T\\) represents the proportion of treated units.\n\\(u \\sim \\mathcal{N}(0, \\sigma_{u}^{2})\\) the unobserved variable\n\\(\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})\\) the error term\nData generation\nWe write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis.\nNote that, for readability, in this document, we only display the chunks of code that may be important to understand the assumptions behind our simulations and the way we built our simulation. We do not display all the arguably “technical” code, in particular the one used to generate tables and graphs. All this code is however openly available on the GitHub of the project.\n\n\ngenerate_data_crosscutting <- function(N,\n                                   p_treat,\n                                   sigma_u,\n                                   sigma_e,\n                                   alpha,\n                                   treatment_effect, #beta\n                                   ovb_intensity #delta\n                                   ) {\n  tibble(id = 1:N) %>%\n    mutate(\n      # treated = rbernoulli(N, p_treat),\n      treated = (id %in% sample(1:N, p_treat*N)),\n      u = rnorm(nrow(.), 0, sigma_u),\n      e = rnorm(nrow(.), 0, sigma_e),\n      y = alpha + treatment_effect*treated + ovb_intensity*u + e\n    )\n}\n\n\n\n\nFor now, we consider very simple baseline parameters, mostly standard normal distributions:\n\nN\np_treat\nsigma_u\nsigma_e\nalpha\ntreatment_effect\novb_intensity\n500\n0.5\n1\n1\n1\n0.4\n1\n\nHere is an example of data created with our data generating process:\n\nid\ntreated\nu\ne\ny\n1\nFALSE\n-1.3375867\n-0.3274887\n-0.6650755\n2\nTRUE\n0.0103900\n0.0147214\n1.4251114\n3\nFALSE\n0.9573412\n0.5174116\n2.4747528\n4\nTRUE\n2.1155976\n-1.7631278\n1.7524698\n5\nTRUE\n0.8642634\n0.0405888\n2.3048523\n6\nFALSE\n1.6054046\n-1.2803043\n1.3251003\n7\nFALSE\n1.1105260\n0.0761707\n2.1866967\n8\nFALSE\n2.1148317\n0.2971476\n3.4119794\n9\nTRUE\n1.3238984\n0.9281446\n3.6520430\n10\nTRUE\n-0.5149821\n1.1109501\n1.9959680\n\nEstimation\nAfter generating the data, we can run an estimation. We want to be able to run the estimation for different numbers of clusters. We create artificial clusters, based on the individual identification numbers id. When we do not wish to cluster the standard errors, we simply set the cluster variable to be equal to the id so that the “clustering” is at the individual level. Note that we use the function lm_robust from the estimatr package to compute this clustering.\n\n\nestimate_crosscutting <- function(data, n_clusters = NA) {\n  n_clusters_mod <- ifelse(is.na(n_clusters), nrow(data), n_clusters)\n  \n  data %>%\n    mutate(cluster = cut_number(id, n_clusters_mod, labels = FALSE)) %>%\n    lm(data = ., formula = y ~ treated) %>%\n    coeftest(vcov = vcovCL, cluster = ~cluster) %>% \n    broom::tidy() %>%\n    filter(term == \"treatedTRUE\") %>%\n    rename(p_value = p.value, se = std.error) %>%\n    select(estimate, p_value, se) %>%\n    mutate(n_clusters = n_clusters)\n}\n\n# estimate_crosscutting_1 <- function(data, n_clusters = NA) {\n#   n_clusters_mod <- ifelse(is.na(n_clusters), nrow(data), n_clusters)\n#   \n#   data %>%\n#     mutate(cluster = cut_number(id, n_clusters_mod, labels = FALSE)) %>%\n#     estimatr::lm_robust(\n#       data = .,\n#       formula = y ~ treated,\n#       clusters = cluster\n#     ) %>%\n#     broom::tidy() %>%\n#     as_tibble() %>% \n#     filter(term == \"treatedTRUE\") %>%\n#     rename(p_value = p.value, se = std.error) %>%\n#     select(estimate, p_value, se) %>%\n#     mutate(n_clusters = n_clusters)\n# }\n\n# estimate_crosscutting_2 <- function(data, n_clusters = NA) {\n# \n#   if (is.na(n_clusters)) {\n#     reg <- lm(\n#       data = data,\n#       formula = y ~ treated\n#     )\n#   } else {\n#     reg <- data %>%\n#       mutate(cluster = cut_number(id, n_clusters, labels = FALSE)) %>%\n#       estimatr::lm_robust(\n#         data = .,\n#         formula = y ~ treated,\n#         clusters = cluster\n#       )\n#   }\n# \n#   reg %>%\n#     broom::tidy() %>%\n#     as_tibble() %>% \n#     filter(term == \"treatedTRUE\") %>%\n#     rename(p_value = p.value, se = std.error) %>%\n#     select(estimate, p_value, se) %>%\n#     mutate(n_clusters = n_clusters)\n# }\n\n\n\nOne simulation\nWe can now run a simulation, combining generate_data_crosscutting and estimate_crosscutting. To do so we create the function compute_sim_crosscutting. This simple function takes as input the various parameters. It returns a table with the estimate of the treatment, its p-value and standard error, the true effect. Note for now, that we do not store the values of the other parameters for simplicity because we consider them fixed over the study.\n\n\ncompute_sim_crosscutting <- function(N,\n                                 p_treat,\n                                 sigma_u,\n                                 sigma_e,\n                                 alpha,\n                                 treatment_effect,\n                                 ovb_intensity,\n                                 n_clusters = NA) {\n  generate_data_crosscutting(\n    N = N,\n    p_treat = p_treat,\n    sigma_u = sigma_u,\n    sigma_e = sigma_e,\n    alpha = alpha,\n    treatment_effect = treatment_effect,\n    ovb_intensity = ovb_intensity\n  ) %>%\n  estimate_crosscutting(n_clusters = n_clusters) %>%\n  mutate(\n    true_effect = treatment_effect,\n    p_treat = p_treat\n  ) \n}\n\n\n\nAll simulations\nWe will run the simulations for different sets of parameters by mapping our compute_sim_p_treat function on each set of parameters. We thus create a table with all the values of the parameters we want to test, param_p_treat. First, we only vary the proportion of unit treated. We will vary the number of clusters in a second analysis.\nNote that in this table each set of parameters appears n_iter times as we want to run the analysis \\(n_{iter}\\) times for each set of parameters.\n\n\n\nWe then run the simulations by mapping our compute_sim_p_treat function on param_p_treat.\n\n\n\nAnalysis of the results (proportion treated units)\nQuick exploration\nFirst, we quickly explore the results.\n\n\n\nComputing bias and type M\nWe want to compare \\(\\mathbb{E}[\\beta_0 - \\widehat{\\beta}]\\) and \\(\\mathbb{E}[|\\beta_0 - \\widehat{\\beta}||signif]\\). The first term represents the bias and the second term represents the type M error. This terms depend on the effect size. To enable comparison across simulation and getting terms independent of effect sizes, we also compute the average of the ratios between the estimate and the true effect, conditional on significance.\n\n\nsummarise_sim_crosscutting <- function(data) {\n  data %>%\n    mutate(significant = (p_value <= 0.05)) %>%\n    group_by(p_treat, n_clusters) %>%\n    summarise(\n      power = mean(significant, na.rm = TRUE)*100,\n      type_m = mean(ifelse(significant, abs(estimate/true_effect), NA), na.rm = TRUE),\n      bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      bias_all_median = median(estimate/true_effect, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>%\n    ungroup()\n}\n\nsummary_sim_p_treat <- summarise_sim_crosscutting(sim_p_treat)\n\n\n\nTHE graph\nTo analyze our results, we build a unique and simple graph:\n\n\n\nVarying the number of clusters\nWe then reproduce a similar type of analysis and graph but varying the number of clusters.\n\n2.385 sec elapsed\n\n\n\n\n\n",
      "last_modified": "2022-03-08T17:05:30-05:00"
    },
    {
      "path": "DID.html",
      "title": "Simulations DID / Event study",
      "description": "In this document, we run a simulation exercise to illustrate how using a Difference-in-Differences (DiD) or event study approach to avoid confounders may lead to a loss in power and inflated effect sizes.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSummary and intuition\nAn illustrative exampleModeling choices\nData generation\nEstimation\nOne simulation\nAll simulations\n\nAnalysis of the resultsQuick exploration\nComputing bias and exaaggeration ratio\nMain graph\n\n\n\nbody {\ntext-align: justify}\nSummary and intuition\nIn the case of event studies, DiD or basically any study using discrete exogenous shocks, the unconfoundedness / exaggeration trade-off is mediated by the number of observations treated. In some classic DiD settings, while the number of observations is large, the number of events might be limited. Pinpointing exogenous shocks is never easy and we are sometimes only able to find a limited number of occurrences of this shock or shocks affecting a small portion of the population. More precisely, the number of observations with a non null treatment status might be small. In this instance, the variation available to identify the treatment is limited, possibly leading power to be low and exaggeration issues to arise.\nThe number of treated observations can be decomposed into two parts: the total number of observations times the proportion of observations in the treated group. Of course, if one reduces the total sample size, precision and thus power will decrease. Now, we all remember that power is maximized when the proportion of treated observations is equal to the proportion of untreated ones. If we consider a fixed number of observations, decreasing the proportion of treated observations below 0.5 will decrease precision and power.\nThe simple formula of the standard error of the difference of the averages of the outcome variable in the treated and control group illustrates this. Of course this does not represent the actual standard error of the DiD estimate but it represents something similar and can be useful to get an intuition for this trade-off. The formula is the following:\n\\[se_{\\bar{y_T} - \\bar{y_c}} = \\sqrt{\\dfrac{\\sigma_T^2}{n_T} + \\dfrac{\\sigma_C^2}{n_C}}\\] where \\(n_T\\) and \\(n_C\\) are the number of observation in the treated group and the control group respectively and \\(\\sigma_T\\) and \\(\\sigma_C\\) the standard deviations of the outcome in the treated group and the control group respectively. In many cases, we can assume that \\(\\sigma_T = \\sigma_C = \\sigma\\). Under this assumption we have:\n\\[se_{\\bar{y_T} - \\bar{y_c}} = \\dfrac{\\sigma}{\\sqrt{n}} \\times \\sqrt{\\dfrac{1}{p_T(1-p_T)}}\\] where \\(n\\) is the total number of observations and \\(p_T\\) the proportion of treated observations.\nFrom this simple formula it is obvious that the standard error of interest increases when \\(n\\) decreases and that, for \\(n\\) constant, it is minimized when the proportion of treated is 0.5. If there are less treated than control, one may think of decreasing the number of observations in the control group to get to \\(p_T = 0.5\\). Yet, this will also reduce \\(n\\) and the first equation makes clear that only reducing \\(n_C\\) will increase the standard error of interest.\nThe unbalance between the number of treated and controls is more general than only event studies and DiD but is particularly salient in this case.\nAn illustrative example\nFor readability and to illustrate this loss in power, we consider an example setting. For this illustration we could use a large variety of Data Genereting Processes (DGP), both in terms of distribution of the variables and of relations between them. We narrow this down to an example setting, considering an analysis of health impacts of air pollution. More precisely, we simulate and analyze the impacts of air pollution reduction on birthweights. Air pollution might vary with other variables that may also affect birthweight (for instance economic activity). Some of these variables might be unobserved and bias estimates of a simple regression of birthweight on pollution levels. A strategy to avoid such issues is to consider exogenous shocks to air pollution such as plant closures, plant openings, creation of a low emission zone or an urban toll, strikes, etc.\nEven if we consider an example setting for clarity, the unconfoundedness / exaggeration trade-off mediated by the number of observations treated should also arise in other settings.\nModeling choices\nTo simplify, we consider the assumptions described below. Of course these assumptions are arbitrary and we invite you to play with them. \nAs many studies in the literature, for instance Currie et al. (2015) and Lavaine and Neidell (2017), to build a panel, we aggregate observations. We look at the evolution of birthweights in zip codes in time, for instance months.\nFor clarity in the explanations, let’s assume that the exogenous shock considered is a permanent plant closure and that this reduces air pollution level. If the reader prefers, they can think of it as any permanent exogenous change in air pollution levels. For now, we will only estimate a reduced form. We are therefore not interested in modeling the effect of the plant closure on pollution levels. We consider that the plant closure leads to some air pollution reduction and want to estimate the effect of this closure on birthweight. We plan to add pollution in the future in order to compare the performance of the reduced form and a straight regression of birthweight on pollution. Yet, generating pollution is rather complex and we therefore only consider the reduced form for now.\nFor each time period, a zip code is either treated (plant closed) or not treated. Over the whole period, some zip codes experience a plant closure, others do not either because they do not have a plant that affect their air pollution levels or because their plant did not close.\nWe consider that the average birthweight in zip code \\(z\\) at time period \\(t\\), \\(w_{zt}\\), depends on a zip code fixed effect \\(\\zeta_z\\), a time fixed effect \\(\\tau_t\\) and the treatment status \\(T_i\\), ie whether a plant closed in this period or not. For now, we do not simulate omitted variable biases as we consider that the shocks are truly exogenous. Thus, birthweight is defined as follows:\n\\[w_{z,t} = \\alpha + \\beta T_{z, t} + \\zeta_z + \\tau_t + \\epsilon_{z,t}\\] \n\n\n\n\n\nTo simplify, we consider the following additional assumptions:\nThe treatment is constant in time and homogeneous across zip codes. In this case, the two ways fixed effect estimation should yield a correct estimate of the ATET (as discussed in de Chaisemartin and d’Haultfoeuille (2022) for instance)\nA proportion \\(p_{treat}\\) of zip codes are ever treated over the period. Hence, a proportion of \\(1-p_{treat}\\) zip codes are never treated over the period. We draw these zip codes at random. Note that drawing at random is not necessary here. Without loss of generality, we could assume that the non-treated zip codes are those with the larger zip codes identifiers for instance,\nWe assume that, among treated zip codes, on average half of the observations are treated. This choice is arbitrary but we choose that such that the treatment happens on average in middle of the of the time period,\nThe implementation of the treatment can be staggered or not. If it is not staggered, the treatment date is set to be in the middle of the period. For now we only analyze the non staggered version.\nMore precisely, we set:\n\\(N_z\\) the number of zip codes,\n\\(N_t\\) the number of periods (months),\n\\(\\zeta_z \\sim \\mathcal{N}(\\mu_{\\zeta}, \\sigma_{\\zeta}^{2})\\) the fixed effect for zip code \\(z\\),\n\\(\\tau_t \\sim \\mathcal{N}(\\mu_{\\tau}, \\sigma_{\\tau}^{2})\\) the fixed effect for time period \\(t\\),\n\\(\\epsilon_{zt} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})\\) some noise,\n\\(T_{zt}\\) represent the treatment allocation, it is equal to 1 if zip code \\(z\\) is treated at time \\(t\\) and 0 otherwise,\n\\(w_{z,t} = \\alpha + \\beta T_{z, t} + \\zeta_z + \\tau_t + \\epsilon_{z,t}\\) where \\(\\alpha\\) is a constant,\n\\(\\beta\\) is represents the magnitude of the treatment,\nWe define staggered as a logical variable.\nWe also create a bunch of variables that can be useful:\n\\(InTreatment_z\\) equal to 1 if zip code \\(z\\) ever gets treated,\n\\(t^{event}_z\\) equal to the date at which zip code \\(z\\) gets treated, especially useful in the staggered setting,\n\\(t^{centered}_z\\) representing the distance in terms of periods to the beginning of the treatment for zip code \\(z\\),\n\\(Post_{zt}\\) equal to 1 if the period \\(t\\) is after the treatment has begun for zip code \\(z\\). This variable is only useful for non-staggered treatment allocation case.\nData generation\nGenerating function\nWe write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis.\n\n\ngenerate_data_DID <- function(N_z,\n                              N_t,\n                              sigma_e,\n                              p_treat,\n                              staggered,\n                              alpha,\n                              beta,\n                              mu_zip_fe, \n                              sigma_zip_fe,\n                              mu_time_fe, \n                              sigma_time_fe\n                             ) {\n  \n  if (!is.logical(staggered)) {stop(\"staggered must be logical\")} \n  \n  data <- tibble(zip = 1:N_z) %>%\n    mutate(in_treatment = (zip %in% sample(1:N_z, floor(N_z*p_treat)))) %>% \n    crossing(t = 1:N_t) %>%\n    group_by(zip) %>%\n    mutate(\n      zip_fe = rnorm(1, mu_zip_fe, sigma_zip_fe),\n      # x = rnorm(1, 0, 350),\n      t_event = ifelse(staggered, sample(2:(N_t - 1), 1), floor(N_t/2)), \n        #We use 2:(N_t-1) to aalways have a pre and post period\n      t_event = ifelse(!in_treatment & staggered, NA, t_event)\n    ) %>%\n    ungroup() %>%\n    group_by(t) %>%\n    mutate(time_fe = rnorm(1, mu_time_fe, sigma_time_fe)) %>%\n    ungroup() %>%\n    mutate(\n      post = (t > t_event),\n      treated = in_treatment & post, \n      t_centered = t - t_event,\n      e = rnorm(nrow(.), 0, sigma_e),\n      birthweight0 = alpha + zip_fe + time_fe + e, #+ 1*x\n      birthweight1 = birthweight0 + beta,\n      birthweight = treated*birthweight1 + (1 - treated)*birthweight0\n    )\n  \n  return(data)\n}\n\n\n\nBaseline parameters’ values\nWe set baseline values for the parameters to emulate a somehow realistic observational study`.\nWe get “inspiration” for the values of parameters from Lavaine and Neidell (2017).\nWe consider that: - We consider a large number of zip codes (1000 zip codes) and time periods (24 months), - Birthweight is expressed in grams. In Lavaine and Neidell’s sample made of babies born in France, the average birthweight is 3228g (sd = 353). We choose alpha and sigma_e to yield a similar distribution. These values of course depend on the values of the other parameters - A usual treatment effect size in published studies is a change of about 1 to 3% in birthweight. We consider a 2% effect size. Thus, we set \\(\\beta = 3228 \\times 0.02 \\simeq 65\\) - We set time and individual fixed effects to be of half of the order of magnitude of the treatment effect and with a standard deviation roughly equal to their mean (somehow arbitrary choice), - In these type of analyses, plant closures do not happen often and therefore the proportion of treated observations is limited. As a baseline, we can assume that 5% of the plants close over the period. Translating it in terms of closures, in the two years of the study (24 months), out of the 1000 plants, 50 closed. This does not seem like a particularly large number as such closures are rare.\n\nN_z\nN_t\nsigma_e\np_treat\nstaggered\nalpha\nbeta\nmu_zip_fe\nsigma_zip_fe\nmu_time_fe\nsigma_time_fe\n5000\n24\n350\n0.05\nFALSE\n3163\n65\n33\n33\n33\n33\n\nHere is an example of data created with the data generating process and baseline parameter values, for 2 zip codes and 8 time periods and not displaying t_event, ìn_treatment, post and t_centered:\n\nzip\nt\ntreated\nbirthweight0\nbirthweight1\nbirthweight\ne\nzip_fe\ntime_fe\n1\n1\nFALSE\n3478.285\n3543.285\n3478.285\n279.62773\n62.92833\n-27.270935\n1\n2\nFALSE\n3464.416\n3529.416\n3464.416\n193.51133\n62.92833\n44.976155\n1\n3\nFALSE\n2963.249\n3028.249\n2963.249\n-216.66550\n62.92833\n-46.013694\n1\n4\nFALSE\n2979.283\n3044.283\n2979.283\n-309.09044\n62.92833\n62.445486\n1\n5\nFALSE\n3402.713\n3467.713\n3402.713\n153.79499\n62.92833\n22.989503\n1\n6\nFALSE\n3689.319\n3754.319\n3689.319\n435.42792\n62.92833\n27.962313\n1\n7\nFALSE\n3574.841\n3639.841\n3574.841\n312.53934\n62.92833\n36.373142\n1\n8\nFALSE\n3766.312\n3831.312\n3766.312\n547.38907\n62.92833\n-7.005873\n2\n1\nFALSE\n3501.871\n3566.871\n3501.871\n353.42678\n12.71544\n-27.270935\n2\n2\nFALSE\n3123.960\n3188.960\n3123.960\n-96.73133\n12.71544\n44.976155\n2\n3\nFALSE\n3156.466\n3221.466\n3156.466\n26.76459\n12.71544\n-46.013694\n2\n4\nFALSE\n2940.645\n3005.645\n2940.645\n-297.51630\n12.71544\n62.445486\n2\n5\nTRUE\n2740.060\n2805.060\n2805.060\n-458.64488\n12.71544\n22.989503\n2\n6\nTRUE\n2613.528\n2678.528\n2678.528\n-590.15009\n12.71544\n27.962313\n2\n7\nTRUE\n3476.155\n3541.155\n3541.155\n264.06649\n12.71544\n36.373142\n2\n8\nTRUE\n3044.664\n3109.664\n3109.664\n-124.04605\n12.71544\n-7.005873\n\nWe check the standard deviation and means of the parameters:\n\nStatistic\nbirthweight0\nMean\n3222.8764\nStandard Deviation\n353.1331\n\nTreatment allocations in the staggered and non staggered case, when the proportion of treated is 30%, are as follows:\n\n\n\nQuick data exploration\nWe quickly explore a data set generated with our function. First, we look at the distribution of potential outcomes.\n\n\n\nThen, we compare the average birthweight before and after the treatment, in the control and treatment group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimation\nWe then define a function to run the estimation.\n\n\nestimate_DID <- function(data) {\n  reg <- data %>% \n    mutate(\n      zip = as.factor(zip),\n      t = as.factor(t),\n      treated = as.numeric(treated),\n      in_treatment = as.numeric(in_treatment),\n      t_centered = as.factor(t_centered)\n    ) %>% \n    feols(\n      data = ., \n      fml = birthweight ~ treated | zip + t\n    ) %>% \n    broom::tidy() %>% \n    rename(p_value = p.value, se = std.error) %>% \n    select(-statistic) \n    # suppressMessages() #Warning saying that NA values dropped and \n    # #that one or two factors are removed due to colinearity\n  \n  return(reg)\n}\n\n\n\nHere is an example of an output of this function:\n\nterm\nestimate\nse\np_value\ntreated\n76.78378\n9.253189\n0\n\nOne simulation\nNote that to run power calculations, we need to have access to the true effects. Therefore, before running the estimation, we write a short function to compute the average treatment effect on the treated (ATET). We will add this information to the estimation results.\n\n\ncompute_true_effect_DID <- function(data) {\n  data %>% \n    filter(treated) %>% \n    summarise(true_effect = mean(birthweight1 - birthweight0)) %>% \n    .$true_effect\n}  \n\n\n\nWe can now run a simulation, combining generate_data_DID and estimate_DID. To do so we create the function compute_sim_DID. This simple function takes as input the various parameters. It returns a table with the estimate of the treatment, its p-value and standard error, the true effect, the proportion of treated units and whether the treatment was staggered or not. Note that for now, we do not store the values of the other parameters for simplicity because we consider them fixed over the study.\n\n\n\nHere is an example of an output of this function.\n\nterm\nestimate\nse\np_value\nN_z\nN_t\np_treat\ntrue_effect\ntreated\n70.99959\n9.277777\n0\n5000\n24\n0.05\n65\n\nAll simulations\nWe will run the simulations for different sets of parameters by mapping our compute_sim_DID function on each set of parameters. We thus create a table with all the values of the parameters we want to test, param_DID. Note that in this table each set of parameters appears N_iter times as we want to run the analysis \\(n_{iter}\\) times for each set of parameters.\n\n\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\",\"201\",\"202\",\"203\",\"204\",\"205\",\"206\",\"207\",\"208\",\"209\",\"210\",\"211\",\"212\",\"213\",\"214\",\"215\",\"216\",\"217\",\"218\",\"219\",\"220\",\"221\",\"222\",\"223\",\"224\",\"225\",\"226\",\"227\",\"228\",\"229\",\"230\",\"231\",\"232\",\"233\",\"234\",\"235\",\"236\",\"237\",\"238\",\"239\",\"240\",\"241\",\"242\",\"243\",\"244\",\"245\",\"246\",\"247\",\"248\",\"249\",\"250\",\"251\",\"252\",\"253\",\"254\",\"255\",\"256\",\"257\",\"258\",\"259\",\"260\",\"261\",\"262\",\"263\",\"264\",\"265\",\"266\",\"267\",\"268\",\"269\",\"270\",\"271\",\"272\",\"273\",\"274\",\"275\",\"276\",\"277\",\"278\",\"279\",\"280\",\"281\",\"282\",\"283\",\"284\",\"285\",\"286\",\"287\",\"288\",\"289\",\"290\",\"291\",\"292\",\"293\",\"294\",\"295\",\"296\",\"297\",\"298\",\"299\",\"300\",\"301\",\"302\",\"303\",\"304\",\"305\",\"306\",\"307\",\"308\",\"309\",\"310\",\"311\",\"312\",\"313\",\"314\",\"315\",\"316\",\"317\",\"318\",\"319\",\"320\",\"321\",\"322\",\"323\",\"324\",\"325\",\"326\",\"327\",\"328\",\"329\",\"330\",\"331\",\"332\",\"333\",\"334\",\"335\",\"336\",\"337\",\"338\",\"339\",\"340\",\"341\",\"342\",\"343\",\"344\",\"345\",\"346\",\"347\",\"348\",\"349\",\"350\",\"351\",\"352\",\"353\",\"354\",\"355\",\"356\",\"357\",\"358\",\"359\",\"360\",\"361\",\"362\",\"363\",\"364\",\"365\",\"366\",\"367\",\"368\",\"369\",\"370\",\"371\",\"372\",\"373\",\"374\",\"375\",\"376\",\"377\",\"378\",\"379\",\"380\",\"381\",\"382\",\"383\",\"384\",\"385\",\"386\",\"387\",\"388\",\"389\",\"390\",\"391\",\"392\",\"393\",\"394\",\"395\",\"396\",\"397\",\"398\",\"399\",\"400\",\"401\",\"402\",\"403\",\"404\",\"405\",\"406\",\"407\",\"408\",\"409\",\"410\",\"411\",\"412\",\"413\",\"414\",\"415\",\"416\",\"417\",\"418\",\"419\",\"420\",\"421\",\"422\",\"423\",\"424\",\"425\",\"426\",\"427\",\"428\",\"429\",\"430\",\"431\",\"432\",\"433\",\"434\",\"435\",\"436\",\"437\",\"438\",\"439\",\"440\",\"441\",\"442\",\"443\",\"444\",\"445\",\"446\",\"447\",\"448\",\"449\",\"450\",\"451\",\"452\",\"453\",\"454\",\"455\",\"456\",\"457\",\"458\",\"459\",\"460\",\"461\",\"462\",\"463\",\"464\",\"465\",\"466\",\"467\",\"468\",\"469\",\"470\",\"471\",\"472\",\"473\",\"474\",\"475\",\"476\",\"477\",\"478\",\"479\",\"480\",\"481\",\"482\",\"483\",\"484\",\"485\",\"486\",\"487\",\"488\",\"489\",\"490\",\"491\",\"492\",\"493\",\"494\",\"495\",\"496\",\"497\",\"498\",\"499\",\"500\",\"501\",\"502\",\"503\",\"504\",\"505\",\"506\",\"507\",\"508\",\"509\",\"510\",\"511\",\"512\",\"513\",\"514\",\"515\",\"516\",\"517\",\"518\",\"519\",\"520\",\"521\",\"522\",\"523\",\"524\",\"525\",\"526\",\"527\",\"528\",\"529\",\"530\",\"531\",\"532\",\"533\",\"534\",\"535\",\"536\",\"537\",\"538\",\"539\",\"540\",\"541\",\"542\",\"543\",\"544\",\"545\",\"546\",\"547\",\"548\",\"549\",\"550\",\"551\",\"552\",\"553\",\"554\",\"555\",\"556\",\"557\",\"558\",\"559\",\"560\",\"561\",\"562\",\"563\",\"564\",\"565\",\"566\",\"567\",\"568\",\"569\",\"570\",\"571\",\"572\",\"573\",\"574\",\"575\",\"576\",\"577\",\"578\",\"579\",\"580\",\"581\",\"582\",\"583\",\"584\",\"585\",\"586\",\"587\",\"588\",\"589\",\"590\",\"591\",\"592\",\"593\",\"594\",\"595\",\"596\",\"597\",\"598\",\"599\",\"600\",\"601\",\"602\",\"603\",\"604\",\"605\",\"606\",\"607\",\"608\",\"609\",\"610\",\"611\",\"612\",\"613\",\"614\",\"615\",\"616\",\"617\",\"618\",\"619\",\"620\",\"621\",\"622\",\"623\",\"624\",\"625\",\"626\",\"627\",\"628\",\"629\",\"630\",\"631\",\"632\",\"633\",\"634\",\"635\",\"636\",\"637\",\"638\",\"639\",\"640\",\"641\",\"642\",\"643\",\"644\",\"645\",\"646\",\"647\",\"648\",\"649\",\"650\",\"651\",\"652\",\"653\",\"654\",\"655\",\"656\",\"657\",\"658\",\"659\",\"660\",\"661\",\"662\",\"663\",\"664\",\"665\",\"666\",\"667\",\"668\",\"669\",\"670\",\"671\",\"672\",\"673\",\"674\",\"675\",\"676\",\"677\",\"678\",\"679\",\"680\",\"681\",\"682\",\"683\",\"684\",\"685\",\"686\",\"687\",\"688\",\"689\",\"690\",\"691\",\"692\",\"693\",\"694\",\"695\",\"696\",\"697\",\"698\",\"699\",\"700\",\"701\",\"702\",\"703\",\"704\",\"705\",\"706\",\"707\",\"708\",\"709\",\"710\",\"711\",\"712\",\"713\",\"714\",\"715\",\"716\",\"717\",\"718\",\"719\",\"720\",\"721\",\"722\",\"723\",\"724\",\"725\",\"726\",\"727\",\"728\",\"729\",\"730\",\"731\",\"732\",\"733\",\"734\",\"735\",\"736\",\"737\",\"738\",\"739\",\"740\",\"741\",\"742\",\"743\",\"744\",\"745\",\"746\",\"747\",\"748\",\"749\",\"750\",\"751\",\"752\",\"753\",\"754\",\"755\",\"756\",\"757\",\"758\",\"759\",\"760\",\"761\",\"762\",\"763\",\"764\",\"765\",\"766\",\"767\",\"768\",\"769\",\"770\",\"771\",\"772\",\"773\",\"774\",\"775\",\"776\",\"777\",\"778\",\"779\",\"780\",\"781\",\"782\",\"783\",\"784\",\"785\",\"786\",\"787\",\"788\",\"789\",\"790\",\"791\",\"792\",\"793\",\"794\",\"795\",\"796\",\"797\",\"798\",\"799\",\"800\"],[5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000,5000],[24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24],[350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350],[false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false],[3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163,3163],[65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33],[0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.004,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.006,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.008,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.03]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>N_z<\\/th>\\n      <th>N_t<\\/th>\\n      <th>sigma_e<\\/th>\\n      <th>staggered<\\/th>\\n      <th>alpha<\\/th>\\n      <th>beta<\\/th>\\n      <th>mu_zip_fe<\\/th>\\n      <th>sigma_zip_fe<\\/th>\\n      <th>mu_time_fe<\\/th>\\n      <th>sigma_time_fe<\\/th>\\n      <th>p_treat<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,5,6,7,8,9,10,11]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\nWe then run the simulations by mapping our compute_sim_IV function on param_IV.\n\n\ntic()\nsim_DID <- pmap_dfr(param_DID, compute_sim_DID)\nbeep()\ntoc()\n\n# saveRDS(sim_DID, here(\"Outputs/sim_DID.RDS\"))\n\n\n\nAnalysis of the results\nQuick exploration\nFirst, we quickly explore the results.\n\n\n\nComputing bias and exaaggeration ratio\nWe want to compare \\(\\mathbb{E}[\\beta_0/\\widehat{\\beta}]\\) and \\(\\mathbb{E}[\\beta_0/ \\widehat{\\beta}|signif]\\). The first term represents the bias and the second term represents the exaggeration ratio. These terms depend on the true effect size.\n\n\nsummarise_sim_DID <- function(data) {\n  data %>%\n    mutate(significant = (p_value <= 0.05)) %>% \n    group_by(p_treat, N_z, N_t) %>%\n    summarise(\n      power = mean(significant, na.rm = TRUE)*100, \n      type_m = mean(ifelse(significant, abs(estimate/true_effect), NA), na.rm = TRUE),\n      exag_ratio = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      bias_all_median = median(estimate/true_effect, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup() %>% \n    mutate(n_treated = p_treat*N_z*N_t)\n} \n\nsummary_sim_DID <- summarise_sim_DID(sim_DID)\n# saveRDS(summary_sim_DID, here(\"Outputs/summary_sim_DID.RDS\"))\n\n\n\nMain graph\nTo analyze our results, we build a unique and simple graph:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2022-03-08T17:05:44-05:00"
    },
    {
      "path": "experiments.html",
      "title": "Intuition, experimental studies and replication crisis",
      "description": "In this document, we analyze replications of experimental studies to illustrate the consequences of low statistical power in economics.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nAnalyzing all studies\nFocus on one particular study\n\n\nbody {\ntext-align: justify}\nTo illustrate the consequences of low power, we analyze the results from Camerer et al (2016) through the prism of statistical power. The authors of this paper replicated laboratory experiments in economics.\nThey report their replication results, alongside the original results, on the project website, we only need to run their Stata script create_studydetails.do to recover all the infomation.\nWe then compute the power of the initial analysis if the true effect is in fact equal to the replication’s.\n\n\n\nAnalyzing all studies\nWe quickly plot and analyze the results obtained, ie the distribution of the exaggeration ratio and power.\n\n\n\nThe median power would be 0.93%. The median replicated estimates is equal to 0.96 times the original estimate.\nWe then compute the number and proportion of original studies that were statistically significant.\n\nOriginal estimate statistically significant\nNumber\nProportion\nNo\n2\n0.11\nYes\n16\n0.89\n\nWe then do the same thing for the replication studies.\n\nReplication estimate statistically significant\nNumber\nProportion\nNo\n7\n0.39\nYes\n11\n0.61\n\nWe then compute the proportion of original studies that would have adequate power as defined by the customary and arbitrary 80% threshold, still assuming that the true effect is equal to the replication one.\n\nAdequate power\nNumber\nProportion\nNo\n8\n0.44\nYes\n10\n0.56\n\nFocus on one particular study\nHere, we focus on one particular study in order to illustrate in more details the problem at play. We want to simulate what could have yielded replication of the initial study if the true effect was equal to the replication estimate.\nWe select one of the studies, Abeler et al. (2011), that we initially selected at random and draw the graph of interest. The way we calculated the standard error is not perfectly accurate so we use the information available in the replication report.\n\n\n\nIn red is the estimate from the original study and its 95% confidence interval\nThe estimate is significant and has been published. Yet, it is pretty noisy.\nIn blue is the estimate from the replicated study and its 95% confidence interval\nWe notice that this second estimate is both more precise and smaller than the initial one. It still remains noisy\nLet’s assume that the true effect is actually equal to this second estimate (note that this is unlikely)\nWould the design of the initial study be good enough to detect this true effect? ie if we replicated the initial study, could we reject the null of no effect (knowing that the true effect is equal to the replicated estimate)\nIn gray is the estimate form the replicated study but with a standard error equal to the initial study’s (approximately the standard errors that would have been obtained with the design of the initial study)\nThis estimate is non significant. In this instance, we would not have been able to reject the null of no effect\nNow, if we replicate this study 500 times, running 500 lab experiments, in some cases we would get statisitcally significant estimates (the beige dots) and in some others non statistically significant ones (the green dots)\nIf we would have been a bit more lucky, we could have gotten a sample of individuals that would have yielded one of the beige estimates\nNow, we notice that, on average, statistically significant estimates overestimate the true effect by a factor 2.4783975 (average of 0.1959678 while the true effect is 0.0790704). Gelman and Carlin call this inflation factor type M error.\nIn this case, the power is basically the proportion of statistically significant estimates\nIf the study had more power, the sd would be smaller and most estimates would be statistically significative (because there is indeed a non null effect)\nBut since the power is low, if by chance the sample of individuals we get yields a statistically significant estimate, this estimate will overestimate the true effect\n\n\n\n",
      "last_modified": "2022-03-08T17:05:58-05:00"
    },
    {
      "path": "index.html",
      "title": "Unconfounded but Inflated Causal Estimates",
      "author": [],
      "contents": "\n\n          \n      \n      Unconfounded but Inflated Causal Estimates\n      \n      \n      Paper\n      Summary\n      Intuition\n      \n      \n      Simulations\n       \n      ▾\n      \n      \n      RDD\n      IV\n      Matching\n      DiD / Event study\n      Crosscutting issues\n      \n      \n      Reporting\n      \n      \n      \n      ☰\n      \n      \n      \n        \n          \n            \n              \n            \n              Unconfounded but Inflated Causal Estimates\n            \n            \n              \n                \n                    \n                      \n                         GitHub\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            Hi and welcome!\n            This website gathers code and additional material for the paper “Unconfounded but Inflated Causal Estimates” by Vincent Bagilet and Léo Zabrocki.\n            The website is still under construction. It is structured as follows:\n            A PDF version of the current version of the paper is accessible through the “Paper” tab.\n            A plain language summary is available in the “Summary” tab.\n            The “Intuition” tab describes, though an example, how inflation of statistically estimates may arise.\n            The “Simulations” tab describes the simulations for each identification strategy.\n            In the tab “Reporting” we will describe how to run power calculations. \n            All the R code for this project is available in its GitHub directory.\n            \n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Unconfounded but Inflated Causal Estimates\n            \n            \n              \n                \n                                    \n                    \n                       GitHub\n                    \n                  \n                                  \n              \n            \n            \n              Hi and welcome!\n              This website gathers code and additional material for the paper “Unconfounded but Inflated Causal Estimates” by Vincent Bagilet and Léo Zabrocki.\n              The website is still under construction. It is structured as follows:\n              A PDF version of the current version of the paper is accessible through the “Paper” tab.\n              A plain language summary is available in the “Summary” tab.\n              The “Intuition” tab describes, though an example, how inflation of statistically estimates may arise.\n              The “Simulations” tab describes the simulations for each identification strategy.\n              In the tab “Reporting” we will describe how to run power calculations. \n              All the R code for this project is available in its GitHub directory.\n              \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2022-03-08T17:05:58-05:00"
    },
    {
      "path": "IV.html",
      "title": "Simulations IV",
      "description": "In this document, we run a simulation exercise to illustrate how using an Instrumental Variable (IV) strategy to avoid confounders may lead to a loss in power and inflated effect sizes.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSummary and intuition\nAn illustrative exampleModeling choices\nData generation\nEstimation\nOne simulation\nAll simulations\n\nAnalysis of the resultsQuick exploration\nComputing bias and exaggeration ratios\nGraph\nF-statistic analysis\n\nStandard parameter values\n\n\nbody {\ntext-align: justify}\n\n\n\nSummary and intuition\nIn the case of the IV, the unconfoundedness / exaggeration trade-off is mediated by the ‘strength’ of the instrument considered. When the instrument only explains a limited portion of the variation in the explanatory variable, the IV can still be successful in avoiding confounders but power can low, potentially leading to exaggeration issues to arise.\nAn illustrative example\nTo illustrate this loss in power, we could consider a large variety of settings, distribution of the parameters or parameter values. We narrow this down to an example setting, considering only one setting and one set of parameter values. We examine an analysis of the impact of voter turnout on election results, instrumenting voter turnout with rainfall on the day of the election. Our point should stand in more general settings and the choice of values is mostly for illustration.\nA threat of confounders often arises when analyzing the link between voter turnout and election results. To estimate such an effect causally, one can consider exogeneous shocks to voter turnout such as rainfall. Some potential exclusion restriction problems have been highlighted in this instance but we abstract from them and simulate no exclusion restriction violations here.\nModeling choices\nFor simplicity, we consider several assumptions. This illustreation is not representative of the existing literature but the objective is only to calibrate our simulation with somehow realistic parameter values. Again, this illustration is very simplistic. The high level assumptions are:\nWe abstract from the panel dimension in this analysis and consider only one time period. This is could be considered as looking at the outcomes of a unique election.\nWe only consider the impact of rain on the day of the election.\nWe assume no correlation in rainfall between locations. This could be equivalent to considering only a set of remote locations.\nWe assume simplify the data generating process and thus do not add any exclusion restriction violations.\nThe DGP can be represented using the following Directed Acyclic Graph (DAG):\n\n\n\n\n\n\nThe DGP for the vote share of let’s say the republican party in location \\(i\\), \\(Share_i\\), is defined as follows:\n\\[Share_{i} = \\alpha + \\beta Turnout_{i} + \\delta u_{i} + e^{(S)}_{i}\\]\nWhere \\(\\alpha\\) is a constant, \\(u\\) represents an unobserved variable and \\(e^{(S)} \\sim \\mathcal{N}(0, \\sigma_{e_S})\\) noise. \\(\\beta\\) is the parameter of interest. We call it ‘treatment effect’.\nThe DGP for the turnout data is as follows:\n\\[Turnout_{i} = \\gamma + \\lambda Rain_{i} + \\eta u_{i} + e^{(T)}_{i}\\]\nWhere \\(\\mu\\) is a constant, \\(Rain\\) is either a continuous variable (amount of rain in location \\(i\\) on the day of the election) or a dummy variable (whether it rained or not) and \\(e^{(T)} \\sim \\mathcal{N}(0, \\sigma_{e_T})\\) noise. We refer to \\(\\lambda\\) as “IV strength”.\nThe impact on voter turnout on election outcome (share of the republican party) is estimated using 2 Stages Least Squares.\nMore precisely, we set:\n\\(N\\) the number of observations\n\\(Rain \\sim \\text{Gamma}(k, \\theta)\\), \\(Rain \\sim \\mathcal{N}(0, \\sigma_{R}^{2})\\) or \\(Rain \\sim \\text{Bernoulli}(p_R)\\) the instrument\n\\(u \\sim \\mathcal{N}(0, \\sigma_{u}^{2})\\) the unobserved variable\n\\(e^{(S)} \\sim \\mathcal{N}(0, \\sigma_{e_S}^{2})\\)\n\\(e^{(T)} \\sim \\mathcal{N}(0, \\sigma_{e_T}^{2})\\)\nWe assume that \\(\\delta = -\\eta\\) for simplicity. There is no actual basis for that and we may change that in the future. The opposite sign is just to get an upward bias, which makes the comparison between OLS and IV easier since the bias and the exaggeration go in the same direction.\nIf one abstract from the name of the variable, they can notice that this setting is actually very general.\nData generation\nGenerating function\nWe write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis.\nNote that the parameter type_rain describes whether \\(Rain\\) is a random sample from a normal or Bernoulli distribution. The distributions of rainfall heights can be approximated with a gamma distribution. The Bernoulli distribution is used if one only consider the impact of rain or no rain on voter turnout. A normal distribution does not represent actual rainfall distributions but is added to run these simulations in other contexts than linking rainfall, voter turnout and election outcomes.\ntype_rain can take the values gamma, bernoulli or normal. param_rain represents either \\(\\sigma_R\\) if \\(Rain\\) is normal, \\(p_R\\) if it is Bernoulli or a vector of shape and scale parameters for the gamma distribution.\nNote that, for readability, in this document, we only display the chunks of code that may be important to understand the assumptions behind our simulations and the way we built our simulation. We do not display all the arguably “technical” code, in particular the one used to generate tables and graphs. All this code is however openly available on the GitHub of the project.\n\n\ngenerate_data_IV <- function(N,\n                             type_rain, #\"gamma\", \"normal\" or \"bernoulli\"\n                             param_rain,\n                             sigma_u,\n                             sigma_es,\n                             sigma_et,\n                             alpha,\n                             gamma,\n                             treatment_effect,\n                             iv_strength,\n                             ovb_intensity\n                             ) {\n  \n  if (type_rain == \"bernoulli\") {\n    rain_gen <- rbernoulli(N, param_rain[1])\n  } else if (type_rain == \"normal\") {\n    rain_gen <- rnorm(N, 0, param_rain[1])\n  } else if (type_rain == \"gamma\") {\n    rain_gen <- rgamma(N, shape = param_rain[1], scale = param_rain[2])\n  } else {\n    stop(\"type_rain must be either 'bernoulli', 'gamma' or 'normal'\")\n  }\n  \n  data <- tibble(id = 1:N) %>%\n    mutate(\n      rain = rain_gen,\n      u = rnorm(nrow(.), 0, sigma_u),\n      e_s = rnorm(nrow(.), 0, sigma_es),\n      e_t = rnorm(nrow(.), 0, sigma_et),\n      turnout = gamma + iv_strength*rain - ovb_intensity*u + e_t,\n      share = alpha + treatment_effect*turnout + ovb_intensity*u + e_s\n    )\n\n  return(data)\n}\n\n\n\nBaseline parameters’ values\nWe set baseline values for the parameters to emulate a somehow realistic observational study.\nWe get “inspiration” for the values of parameters from Fujiwara et al. and Cooperman who replicates a work by Gomez et al..\nWe consider that:\nTurnout and vote share are expressed in percent\nFujiwara et al. find that “The trends specifications suggest that 1 millimeter of rainfall decreases turnout by 0.05–0.07 percentage points” and Gomez et al. (and thus Cooperman) find “a county that receives one inch of rainfall on election day is likely to have approximately 1 percentage point lower voter turnout” which is equivalent to a 1mm increase in rainfall is associated with about a 0.04 percentage points decrease in voter turnout. For simplicity in interpretation, when rainfall is not a dummy, it is expressed in centimeters. So, we will consider iv_strength in the range -0.1 and -1.3\nWe calibrate the distribution parameters to fit a mix if information from table 1 from both Fujiwara et al. and Cooperman (converting the rainfall into centimeters):\nA gamma distribution represents well the distribution of rainfall. Gamma distribution can have two parameters a shape and a scale. The mean is \\(shape \\times scale\\) and the variance \\(shape \\times scale^{2}\\). The parameters of the distribution of rainfall are comparable in both papers (mean 2.4 and standard deviation 6.6). We solve the system of mean and variance for shape and scale and get 0.13 and 18.\nThe magnitude of the effect of turnout on vote share is subject to intense debate in the literature (cf Shaw and Petrocik (2020) for instance). As underlined by Shaw and Petrocik and in Fowler (2013), some studies find large effects, others no effects or small effects. Fowler (2013) falls into the large effects category as described by the author himself. The study, for an extremely large shock in voter turnout, compulsory voting, finds “that the policy increased voter turnout by 24 percentage points which in turn increased the vote shares and seat shares of the Labor Party by 7 to 10 percentage points.” This correspond to a decrease in Republican vote share of approximately 0.3-0.4 when turnout increases by 1% (considering that his result is causal). These results being large, we consider effects that are smaller but of a similar magnitude: we simulate that when turnout increases by 1%, Republican vote share decreases by 0.1. This enable to test whether the design would be good enough to detect an effect that is not particularly large.\nWe set the intercepts and standard deviations of the errors to produce turnouts and vote shares consistent with the papers. Voter turnout parameters are roughly similar in both papers (mean 58 sd 14). The mean and standard deviation of Republican vote share are given in Fujiwara et al. (mean 55.3 and sd 14.2). We may actually take values from a recent election (eg the last presidential election)\nWe set the standard deviation of the omitted variable bias to be of the order of magnitude of the error terms. Being conservative, we set its intensity to be twice as large as the treatment effect.\nWe consider 10000 observations. This corresponds to data as the US county level as used in Hansford and Gomez (2010) for instance but here for 3 presidential elections. We could have chosen a larger sample size but this sample size is already particularly large and makes it easier to illustrate our point.\n\nWe thus consider the following parameters:\n\nN\ntype_rain\nparam_rain\nsigma_u\nsigma_es\nsigma_et\nalpha\ngamma\ntreatment_effect\niv_strength\novb_intensity\n10000\ngamma\n0.13, 18.00\n14\n14\n13\n60\n59\n-0.1\n-0.5\n0.2\n\nHere is an example of data created with our data generating process:\n\nid\nrain\nu\ne_s\ne_t\nturnout\nshare\n1\n0.0648013\n16.559769\n18.5667259\n-18.5266433\n37.12900\n78.16578\n2\n0.9851335\n-23.050229\n-0.8702574\n-20.1680574\n42.94942\n50.22475\n3\n0.0012370\n19.274290\n-5.5021400\n-4.2766684\n50.86786\n53.26593\n4\n0.0004874\n-8.224344\n14.3793498\n7.9387006\n68.58333\n65.87615\n5\n13.4136786\n-3.027730\n-19.2155438\n-7.4883359\n45.41037\n35.63787\n6\n0.0000000\n-7.723948\n-9.9733950\n0.0983265\n60.64312\n42.41750\n7\n0.0034645\n11.255022\n11.1452536\n6.7959572\n63.54322\n67.04194\n8\n0.0000727\n-3.236330\n-5.9406983\n-4.9473387\n54.69989\n47.94205\n9\n0.0422809\n16.535877\n13.6807291\n-9.4936130\n46.17807\n72.37010\n10\n14.1335688\n3.075381\n-15.8956196\n-15.0074450\n36.31069\n41.08839\n\nExploring the distribution of the data\nWe just quickly explore the distribution of the data for a baseline set of parameters. For this, we consider a mid range value for IV strength (-0.5).\n\n\n\nWe also check the standard deviation and means of the variables:\n\nStatistic\nshare\nturnout\nrain\nMean\n54.13648\n57.78330\n2.298058\nStandard Deviation\n14.41099\n13.56744\n6.270972\n\nEstimation\nAfter generating the data, we can run an estimation. We want to compare the IV and the OLS for different IV strength values. Hence, we need to estimate both an IV and an OLS and return both set of outcomes of interest.\n\n\nestimate_IV <- function(data) {\n  reg_IV <- AER::ivreg(\n    data = data, \n    formula = share ~ turnout | rain\n    ) \n  \n  fstat_IV <- summary(\n    reg_IV, \n    diagnostics = TRUE\n  )$diagnostics[\"Weak instruments\", \"statistic\"]\n  \n  reg_IV <- reg_IV %>% \n    broom::tidy() %>%\n    mutate(\n      model = \"IV\",\n      fstat = fstat_IV\n    )\n  \n  reg_OLS <- lm(\n    data = data, \n    formula = share ~ turnout\n    ) %>% \n    broom::tidy() %>%\n    mutate(\n      model = \"OLS\",\n      fstat = NA\n    )\n  \n  reg_OLS_unbiased <- lm(\n    data = data, \n    formula = share ~ turnout + u\n    ) %>% \n    broom::tidy() %>%\n    mutate(\n      model = \"OLS unbiased\",\n      fstat = NA\n    )\n  \n  reg <- reg_IV %>% \n    rbind(reg_OLS) %>% \n    rbind(reg_OLS_unbiased) %>% \n    filter(term == \"turnout\") %>%\n    rename(p_value = p.value, se = std.error) %>%\n    select(estimate, p_value, se, fstat, model) %>% \n  \n  return(reg)\n}\n\n\n\nOne simulation\nWe can now run a simulation, combining generate_data_IV and estimate_IV. To do so we create the function compute_sim_IV. This simple function takes as input the various parameters. It returns a table with the estimate of the treatment, its p-value and standard error, the F-statistic for the IV, the true effect, the IV strength and the intensity of the OVB considered (ovb_intensity). Note for now, that we do not store the values of the other parameters for simplicity because we consider them fixed over the study.\n\n\ncompute_sim_IV <- function(N,\n                           type_rain,\n                           param_rain,\n                           sigma_u,\n                           sigma_es,\n                           sigma_et,\n                           alpha,\n                           gamma,\n                           treatment_effect,\n                           iv_strength,\n                           ovb_intensity) {\n  generate_data_IV(\n    N = N,\n    type_rain = type_rain,\n    sigma_u = sigma_u,\n    param_rain = param_rain,\n    sigma_es = sigma_es,\n    sigma_et = sigma_et,\n    alpha = alpha,\n    gamma = gamma,\n    treatment_effect = treatment_effect,\n    iv_strength = iv_strength,\n    ovb_intensity = ovb_intensity\n  ) %>%\n    estimate_IV() %>%\n    mutate(\n      iv_strength = iv_strength,\n      ovb_intensity = ovb_intensity,\n      true_effect = treatment_effect\n    )\n} \n\n\n\nAll simulations\nWe will run the simulations for different sets of parameters by mapping our compute_sim_IV function on each set of parameters. We thus create a table with all the values of the parameters we want to test, param_IV. Note that in this table each set of parameters appears n_iter times as we want to run the analysis \\(n_{iter}\\) times for each set of parameters.\n\n\n\nWe then run the simulations by mapping our compute_sim_IV function on param_IV.\n\n\n\nAnalysis of the results\nQuick exploration\nFirst, we quickly explore the results.\n\n\n\nWe notice that the OLS is always biased and that the IV is never biased. However, for limited IV strengths, the distribution of the estimates flattens. The smaller the IV strength, the most like it is to get an estimate away from the true value, even though the expected value remains equal to the true effect size. \nComputing bias and exaggeration ratios\nWe want to compare \\(\\mathbb{E}[\\beta_0/\\widehat{\\beta_{IV}}]\\) and \\(\\mathbb{E}[\\beta_0/ \\widehat{\\beta_{IV}}|\\text{signif}]\\). The first term represents the bias and the second term represents the exaggeration ratio.\n\n\nsummarise_simulations <- function(data) {\n  data %>%\n    mutate(significant = (p_value <= 0.05)) %>% \n    group_by(ovb_intensity, iv_strength, model) %>%\n    summarise(\n      power = mean(significant, na.rm = TRUE)*100, \n      type_m = mean(ifelse(significant, abs(estimate/true_effect), NA), na.rm = TRUE),\n      bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      bias_all_median = median(estimate/true_effect, na.rm = TRUE),\n      median_fstat = mean(fstat, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup()\n} \n\nsummary_sim_IV <- summarise_simulations(sim_IV)\n# saveRDS(summary_sim_IV, here(\"Outputs/summary_sim_IV.RDS\"))\n\n\n\nGraph\nTo analyze our results, we build a unique and simple graph:\n\n\n\nWe notice that, if the IV strength is low, on average, statistically significant estimates overestimate the true effect. If the IV strength is too low, it might even be the case that the benefit of the IV is overturned by the exaggeration issue. The IV yields an unbiased estimate and enables to get rid of the OVB but such statistically significant estimates fall, on average, even further from the true effect.\nOf course, if one considers all estimates, as the IV is unbiased, this issue does not arise.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF-statistic analysis\nWe then run some exploratory analysis to see the link between type M and F-stat (under construction).\n\n\n\nUnsurprisingly, there is a clear positive correlation between what we call IV strength and the F-statistic. We then investigate the link between exaggeration ratios and F-statistics.\n\n\n\nWe notice that, even when the F-statistic is greater than the usual but arbitrary threshold of 10, statistically significant estimates may, on average overestimate the true effect.\nWe cannot compute directly the bias of interest against the F-statistic because the F-statistic is not a parameter of the simulations and we do not control them, only the IV strength. To overcome this, we compute the median power by binned F-statistic. However, this is not correct as we end up comparing and pulling together simulations with different parameter values. We still display the graph, keeping this limitation in mind:\n\n\n\nStandard parameter values\nFor simplicity and for communication purposes, we considered an applied example. However, our results can also hold in general settings. We illustrate this, considering that most of the variables are distributed according to standard normal distributions. We keep the same DAG as it is the classic IV DAG. We also keep the same variable names but one should abstract from their meaning as they do not represent the same measure any longer.\nWe define the following parameters:\n\nN\ntype_rain\nparam_rain\nsigma_u\nsigma_es\nsigma_et\nalpha\ngamma\ntreatment_effect\novb_intensity\n500\nnormal\n1\n1\n1\n1\n0\n0\n-1\n-0.5\n\nWe then run the whole analysis as before, with an OVB intensity of 0.4 so that it is not extremely large.\n\n\n\nThe results and the overall illustration are comparable with the political economy example.\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T20:02:40-04:00"
    },
    {
      "path": "Matching.html",
      "title": "Matching Simulations",
      "description": "In this document, we run a simulation exercise to illustrate how using a matching procedure to avoid confounding may create type M error.\"\n",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://lzabrocki.github.io/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLoading Packages\nData Generating ProcedureGeneral Approach\nFunction to Generate the Data\nEDA for One Dataset\n\nOutcome Regression Analysis\nMatching ProcedurePropensity Score Function\nSimulations\n\n\n\nbody {\ntext-align: justify}\nIn this document, we show through simulations how matching procedures targeting the common support of the data could be under-powered and lead to inflated statistically significant estimates. We illustrate this issue with fake-data similar to those from non-randomized labor training programs. In this case, treated individuals self-select themselves to get the treatment and may therefore have different characteristics from individuals who do not enroll in the program. To estimate the causal effect of the treatment on treated, researchers can rely on matching, which is a pre-processing technique to approximate an hypothetical randomized experiment. The method has three main advantages:\nContrary to outcome regression approach, it does not directly model the relationship between the treatment of interest and the outcome\nIt adjusts non-parametrically for observed confounders\nBy pruning control units not similar to treated units, matching help reveal the common support of the data upon which researchers can more confidently draw their inference. Statistical models used to analyze the resulting data will suffer less from extrapolation bias.\nThe method however relies on the strong assumption that no unmeasured confounders exist and, depending on its stringency, may discard many units from the analysis. This second limit could result in a lack of statistical power to estimate the average treatment on the treated. If journal editors and researchers favor studies based on the their statistical significance, under-powered studies based on matching procedures could lead to estimates that are too large.\nLoading Packages\nWe first load the required packages to set-up the simulations:\n\n\n# load required packages\nlibrary(knitr) # for creating the R Markdown document\nlibrary(tidyverse) # for data manipulation and visualization\nlibrary(MatchIt) # for matching analysis\nlibrary(lmtest) # for modifying regression standard errors\nlibrary(sandwich) # for robust and cluster robust standard errors\nlibrary(DT) # for displaying the data as tables\nlibrary(mediocrethemes) # vincent's custom ggplot2 theme\nlibrary(tictoc) # for measuring running time\nlibrary(beepr) # for making a sound when the code is done\nlibrary(here) # for paths management\n\n# set ggplot theme\nset_mediocre_all(pal = \"coty\")\n\n\n\nData Generating Procedure\nGeneral Approach\nTo illustrate how matching procedures could be particularly sensitive to statistically significant estimates that inflated, we simulate fake-data from a non-randomized labor training program targeting young individuals. Below are the main steps of the simulation:\nWe first create the units identifiers (id). Each unit is an individual.\nMany simulations found in the applied statistics literature test the performance on matching algorithms by first simulating covariates and then simulating the true but unknown propensity to be treated of units. Our goal here is different as we do not want to test the performance of various matching algorithms but rather illustrate how a lack of common overlap in propensity scores can result in a loss statistical power. We therefore first assign a fraction of individual (p_treat) to the treatment and then simulate the true propensity score variable true_ps for treated and control units. For treated units, we draw the propensity scores from a normal distribution \\(N(\\mu_{T}, \\sigma_{T})\\) and for control units, from a normal distribution \\(N(\\mu_{C}, \\sigma_{C})\\).\nOnce the the true propensity scores are created, we define the potential outcomes of each individual. Here, potential outcomes represent the income (in euros) of the individuals if they undertake the training program or not. The potential outcome without treatment adoption, Y(0), is simulated using the following equation: \\(Y_{0} = Wage \\times True Propensity Score + N(\\mu_{noise}, \\sigma_{noise})\\). This equation makes the potential outcomes Y(0) partly different for treated and control units.\nWe finally simulate the potential outcomes when individuals benefit from the training program. The average treatment effect on the treated (ATT) was set to a constant effect of +100 euros. The average treatment effect on the control (ATC) was set to a constant effect of +50. The constant treatment effect assumption is made to simply the illustration of the issue we are interested in. In our simulations, when we make the propensity score matching more stringent, not all treated units will be matched to similar control units. The causal estimand will no longer be the ATT and we should compute it true effect for each iteration if the causal effect was not constant.\nFunction to Generate the Data\nWe display below the code for the function generate_data_matching() which creates the required dataset. Its arguments are the desired sample size (sample_size), the proportion of treated units (p_treat), the mean and standard deviation of the propensity score distributions of treated and control units (mu_t, sigma_t, mu_c, sigma_c), the baseline wage wage, the noise of the equation for simulating the Y(0) (mu_noise, sigma_noise), the ATC and ATT (atc, att).\n\n\ngenerate_data_matching <- function(sample_size,\n                                    p_treat,\n                                    mu_t,\n                                    sigma_t,\n                                    mu_c,\n                                    sigma_c,\n                                    wage,\n                                    mu_noise,\n                                    sigma_noise,\n                                    atc,\n                                    att) {\n  data <- tibble(id = 1:sample_size) %>%\n    mutate(\n      # assign treatment status\n      treatment = rbinom(n = sample_size, size = 1, prob = p_treat),\n      # create the propensity score distributions\n      true_ps = ifelse(\n        treatment == 0,\n        rnorm(n(), mean = mu_c, sd = sigma_c),\n        rnorm(n(), mean = mu_t, sd = sigma_t)\n      ),\n      # make sure that the propensity score is between 0 and 1\n      true_ps = case_when(true_ps > 1 ~ 1,\n                          true_ps < 0 ~ 0,\n                          true_ps >= 0 & true_ps <= 1 ~ true_ps),\n      # generate the potential outcomes\n      y_0 = wage * true_ps + rnorm(n(), mean = 300, sd = 200),\n      y_0 = y_0 %>% round(., 0),\n      y_1 = ifelse(treatment == 1,\n                   y_0 + att,\n                   y_0 + atc),\n      # generate observed outcomes\n      y_obs = ifelse(treatment == 1, y_1, y_0) %>% round(., 0)\n    )\n  return(data)\n}\n\n\n\nIn our simulations, we use the following parameters to create a data of 300 units, with about 25% being treated, and with a lack of common overlap in the propensity scores for treated and control units:\n\nsample_size\np_treat\nmu_t\nsigma_t\nmu_c\nsigma_c\nwage\nmu_noise\nsigma_noise\natc\natt\n300\n0.25\n0.5\n0.1\n0.3\n0.1\n2000\n300\n200\n50\n100\n\nEDA for One Dataset\nWe run one iteration of the function generate_data_matching() to explore the resulting data with 500 units:\n\n\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\",\"201\",\"202\",\"203\",\"204\",\"205\",\"206\",\"207\",\"208\",\"209\",\"210\",\"211\",\"212\",\"213\",\"214\",\"215\",\"216\",\"217\",\"218\",\"219\",\"220\",\"221\",\"222\",\"223\",\"224\",\"225\",\"226\",\"227\",\"228\",\"229\",\"230\",\"231\",\"232\",\"233\",\"234\",\"235\",\"236\",\"237\",\"238\",\"239\",\"240\",\"241\",\"242\",\"243\",\"244\",\"245\",\"246\",\"247\",\"248\",\"249\",\"250\",\"251\",\"252\",\"253\",\"254\",\"255\",\"256\",\"257\",\"258\",\"259\",\"260\",\"261\",\"262\",\"263\",\"264\",\"265\",\"266\",\"267\",\"268\",\"269\",\"270\",\"271\",\"272\",\"273\",\"274\",\"275\",\"276\",\"277\",\"278\",\"279\",\"280\",\"281\",\"282\",\"283\",\"284\",\"285\",\"286\",\"287\",\"288\",\"289\",\"290\",\"291\",\"292\",\"293\",\"294\",\"295\",\"296\",\"297\",\"298\",\"299\",\"300\",\"301\",\"302\",\"303\",\"304\",\"305\",\"306\",\"307\",\"308\",\"309\",\"310\",\"311\",\"312\",\"313\",\"314\",\"315\",\"316\",\"317\",\"318\",\"319\",\"320\",\"321\",\"322\",\"323\",\"324\",\"325\",\"326\",\"327\",\"328\",\"329\",\"330\",\"331\",\"332\",\"333\",\"334\",\"335\",\"336\",\"337\",\"338\",\"339\",\"340\",\"341\",\"342\",\"343\",\"344\",\"345\",\"346\",\"347\",\"348\",\"349\",\"350\",\"351\",\"352\",\"353\",\"354\",\"355\",\"356\",\"357\",\"358\",\"359\",\"360\",\"361\",\"362\",\"363\",\"364\",\"365\",\"366\",\"367\",\"368\",\"369\",\"370\",\"371\",\"372\",\"373\",\"374\",\"375\",\"376\",\"377\",\"378\",\"379\",\"380\",\"381\",\"382\",\"383\",\"384\",\"385\",\"386\",\"387\",\"388\",\"389\",\"390\",\"391\",\"392\",\"393\",\"394\",\"395\",\"396\",\"397\",\"398\",\"399\",\"400\",\"401\",\"402\",\"403\",\"404\",\"405\",\"406\",\"407\",\"408\",\"409\",\"410\",\"411\",\"412\",\"413\",\"414\",\"415\",\"416\",\"417\",\"418\",\"419\",\"420\",\"421\",\"422\",\"423\",\"424\",\"425\",\"426\",\"427\",\"428\",\"429\",\"430\",\"431\",\"432\",\"433\",\"434\",\"435\",\"436\",\"437\",\"438\",\"439\",\"440\",\"441\",\"442\",\"443\",\"444\",\"445\",\"446\",\"447\",\"448\",\"449\",\"450\",\"451\",\"452\",\"453\",\"454\",\"455\",\"456\",\"457\",\"458\",\"459\",\"460\",\"461\",\"462\",\"463\",\"464\",\"465\",\"466\",\"467\",\"468\",\"469\",\"470\",\"471\",\"472\",\"473\",\"474\",\"475\",\"476\",\"477\",\"478\",\"479\",\"480\",\"481\",\"482\",\"483\",\"484\",\"485\",\"486\",\"487\",\"488\",\"489\",\"490\",\"491\",\"492\",\"493\",\"494\",\"495\",\"496\",\"497\",\"498\",\"499\",\"500\",\"501\",\"502\",\"503\",\"504\",\"505\",\"506\",\"507\",\"508\",\"509\",\"510\",\"511\",\"512\",\"513\",\"514\",\"515\",\"516\",\"517\",\"518\",\"519\",\"520\",\"521\",\"522\",\"523\",\"524\",\"525\",\"526\",\"527\",\"528\",\"529\",\"530\",\"531\",\"532\",\"533\",\"534\",\"535\",\"536\",\"537\",\"538\",\"539\",\"540\",\"541\",\"542\",\"543\",\"544\",\"545\",\"546\",\"547\",\"548\",\"549\",\"550\",\"551\",\"552\",\"553\",\"554\",\"555\",\"556\",\"557\",\"558\",\"559\",\"560\",\"561\",\"562\",\"563\",\"564\",\"565\",\"566\",\"567\",\"568\",\"569\",\"570\",\"571\",\"572\",\"573\",\"574\",\"575\",\"576\",\"577\",\"578\",\"579\",\"580\",\"581\",\"582\",\"583\",\"584\",\"585\",\"586\",\"587\",\"588\",\"589\",\"590\",\"591\",\"592\",\"593\",\"594\",\"595\",\"596\",\"597\",\"598\",\"599\",\"600\",\"601\",\"602\",\"603\",\"604\",\"605\",\"606\",\"607\",\"608\",\"609\",\"610\",\"611\",\"612\",\"613\",\"614\",\"615\",\"616\",\"617\",\"618\",\"619\",\"620\",\"621\",\"622\",\"623\",\"624\",\"625\",\"626\",\"627\",\"628\",\"629\",\"630\",\"631\",\"632\",\"633\",\"634\",\"635\",\"636\",\"637\",\"638\",\"639\",\"640\",\"641\",\"642\",\"643\",\"644\",\"645\",\"646\",\"647\",\"648\",\"649\",\"650\",\"651\",\"652\",\"653\",\"654\",\"655\",\"656\",\"657\",\"658\",\"659\",\"660\",\"661\",\"662\",\"663\",\"664\",\"665\",\"666\",\"667\",\"668\",\"669\",\"670\",\"671\",\"672\",\"673\",\"674\",\"675\",\"676\",\"677\",\"678\",\"679\",\"680\",\"681\",\"682\",\"683\",\"684\",\"685\",\"686\",\"687\",\"688\",\"689\",\"690\",\"691\",\"692\",\"693\",\"694\",\"695\",\"696\",\"697\",\"698\",\"699\",\"700\",\"701\",\"702\",\"703\",\"704\",\"705\",\"706\",\"707\",\"708\",\"709\",\"710\",\"711\",\"712\",\"713\",\"714\",\"715\",\"716\",\"717\",\"718\",\"719\",\"720\",\"721\",\"722\",\"723\",\"724\",\"725\",\"726\",\"727\",\"728\",\"729\",\"730\",\"731\",\"732\",\"733\",\"734\",\"735\",\"736\",\"737\",\"738\",\"739\",\"740\",\"741\",\"742\",\"743\",\"744\",\"745\",\"746\",\"747\",\"748\",\"749\",\"750\",\"751\",\"752\",\"753\",\"754\",\"755\",\"756\",\"757\",\"758\",\"759\",\"760\",\"761\",\"762\",\"763\",\"764\",\"765\",\"766\",\"767\",\"768\",\"769\",\"770\",\"771\",\"772\",\"773\",\"774\",\"775\",\"776\",\"777\",\"778\",\"779\",\"780\",\"781\",\"782\",\"783\",\"784\",\"785\",\"786\",\"787\",\"788\",\"789\",\"790\",\"791\",\"792\",\"793\",\"794\",\"795\",\"796\",\"797\",\"798\",\"799\",\"800\",\"801\",\"802\",\"803\",\"804\",\"805\",\"806\",\"807\",\"808\",\"809\",\"810\",\"811\",\"812\",\"813\",\"814\",\"815\",\"816\",\"817\",\"818\",\"819\",\"820\",\"821\",\"822\",\"823\",\"824\",\"825\",\"826\",\"827\",\"828\",\"829\",\"830\",\"831\",\"832\",\"833\",\"834\",\"835\",\"836\",\"837\",\"838\",\"839\",\"840\",\"841\",\"842\",\"843\",\"844\",\"845\",\"846\",\"847\",\"848\",\"849\",\"850\",\"851\",\"852\",\"853\",\"854\",\"855\",\"856\",\"857\",\"858\",\"859\",\"860\",\"861\",\"862\",\"863\",\"864\",\"865\",\"866\",\"867\",\"868\",\"869\",\"870\",\"871\",\"872\",\"873\",\"874\",\"875\",\"876\",\"877\",\"878\",\"879\",\"880\",\"881\",\"882\",\"883\",\"884\",\"885\",\"886\",\"887\",\"888\",\"889\",\"890\",\"891\",\"892\",\"893\",\"894\",\"895\",\"896\",\"897\",\"898\",\"899\",\"900\",\"901\",\"902\",\"903\",\"904\",\"905\",\"906\",\"907\",\"908\",\"909\",\"910\",\"911\",\"912\",\"913\",\"914\",\"915\",\"916\",\"917\",\"918\",\"919\",\"920\",\"921\",\"922\",\"923\",\"924\",\"925\",\"926\",\"927\",\"928\",\"929\",\"930\",\"931\",\"932\",\"933\",\"934\",\"935\",\"936\",\"937\",\"938\",\"939\",\"940\",\"941\",\"942\",\"943\",\"944\",\"945\",\"946\",\"947\",\"948\",\"949\",\"950\",\"951\",\"952\",\"953\",\"954\",\"955\",\"956\",\"957\",\"958\",\"959\",\"960\",\"961\",\"962\",\"963\",\"964\",\"965\",\"966\",\"967\",\"968\",\"969\",\"970\",\"971\",\"972\",\"973\",\"974\",\"975\",\"976\",\"977\",\"978\",\"979\",\"980\",\"981\",\"982\",\"983\",\"984\",\"985\",\"986\",\"987\",\"988\",\"989\",\"990\",\"991\",\"992\",\"993\",\"994\",\"995\",\"996\",\"997\",\"998\",\"999\",\"1000\"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],[0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,1,0,1,0,0,1,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,1,0,0,1,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,0,1,0,1,1,0,0,0,0,0,1,0,0,0,0,1,1,1,1,0,1,0,0,1,0,1,0,1,1,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,1,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,1,0,0,1,0,0,1,0,0,1,0,1,1,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,1,1,0,1,1,1,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,1,0,1,0,0,0,0,1,0,1,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,1,1,0,0,0,0,0,0,1,0,1,0,0,1,0,1,1,0,0,1,0,0,1,0,1,1,0,0,0,0,0,0,1,0,1,1,0,0,0,0,1,1,0,1,1,1,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,1,0,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,1,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0],[0.33,0.35,0.22,0.43,0,0.15,0.25,0.3,0.31,0.56,0.35,0.21,0.4,0.19,0.32,0.17,0.27,0.21,0.57,0.29,0.41,0.31,0.2,0.21,0.2,0.44,0.25,0.21,0.47,0.48,0.35,0.36,0.59,0.26,0.36,0.63,0.42,0.17,0.3,0.38,0.25,0.65,0.47,0.54,0.23,0.28,0.27,0.28,0.5,0.32,0.47,0.38,0.25,0.28,0.59,0.16,0.41,0.41,0.24,0.4,0.44,0.41,0.48,0.28,0.28,0.43,0.31,0.3,0.41,0.3,0.17,0.27,0.41,0.27,0.29,0.16,0.37,0.33,0.35,0.55,0.48,0.15,0.12,0,0.46,0.35,0.43,0.44,0.34,0.32,0.3,0.39,0.26,0.44,0.25,0.33,0.21,0.38,0.3,0.33,0.11,0.41,0.37,0.18,0.43,0.36,0.26,0.43,0.42,0.17,0.28,0.44,0.51,0.19,0.04,0.17,0.33,0.25,0.34,0.05,0.14,0.21,0.16,0.45,0.33,0.39,0.24,0.42,0.22,0.22,0.38,0.12,0.35,0.37,0.27,0.32,0.31,0.34,0.31,0.23,0.42,0.43,0.39,0.18,0.25,0.37,0.21,0.33,0.21,0.28,0.2,0.32,0.36,0.33,0.59,0.22,0.69,0.5,0.39,0.17,0.13,0.36,0.33,0.09,0.18,0.62,0.37,0.3,0.64,0.22,0.18,0.18,0.54,0.44,0.26,0.26,0.42,0.34,0.41,0.27,0.42,0.2,0.25,0.48,0.36,0.49,0.17,0.14,0.06,0.34,0.32,0.47,0.2,0.42,0.51,0.16,0.22,0.41,0.22,0.2,0.36,0.37,0.24,0.45,0.37,0.39,0.15,0.3,0.31,0.21,0.52,0.23,0.6,0.36,0.42,0.32,0.44,0.5,0.36,0.51,0.53,0.27,0.3,0.49,0.35,0.18,0.27,0.25,0.39,0.36,0.27,0.65,0.61,0.09,0.36,0.2,0.43,0.24,0.12,0.29,0.32,0.55,0.48,0.24,0.44,0.41,0.24,0.44,0.16,0.5,0.14,0.32,0.19,0.26,0.37,0.26,0.42,0.26,0.46,0.47,0.36,0.47,0.59,0.43,0.32,0.53,0.22,0.5,0.32,0.62,0.42,0.27,0.21,0.16,0.13,0.3,0.76,0.29,0.27,0.46,0.28,0.46,0.43,0.64,0.5,0.3,0.51,0.14,0.35,0.44,0.28,0.66,0.53,0.7,0.41,0.22,0.51,0.13,0.1,0.48,0.51,0.31,0.44,0.42,0.25,0.31,0.14,0.41,0.33,0.2,0.11,0.37,0.19,0.25,0.24,0.29,0.44,0.33,0.42,0.36,0.2,0.31,0.43,0.2,0.15,0.34,0.34,0.37,0.14,0.47,0.36,0.22,0.23,0.65,0.1,0.16,0.31,0.29,0.6,0.25,0.67,0.49,0.32,0.25,0.29,0.34,0.47,0.3,0.59,0.41,0.43,0.58,0.23,0.28,0.21,0.34,0.2,0.47,0.35,0.23,0.2,0.4,0.46,0.59,0.46,0.56,0.47,0.5,0.3,0.27,0.22,0.34,0.5,0.11,0.62,0.37,0.37,0.28,0.29,0.22,0.37,0.25,0.28,0.43,0.24,0.11,0.34,0.13,0.47,0.41,0.64,0.44,0.41,0.38,0.45,0.33,0.45,0.36,0.24,0.3,0.35,0.19,0.31,0.24,0.54,0.27,0.53,0.29,0.15,0.21,0.37,0.29,0.24,0.24,0.31,0.26,0.59,0.13,0.59,0.5,0.32,0.22,0.32,0.44,0.27,0.24,0.19,0.58,0.3,0.35,0.24,0.37,0.36,0.08,0.59,0.21,0.27,0.74,0.33,0.23,0.38,0.22,0.34,0.28,0.35,0.27,0.33,0.4,0.18,0.37,0.2,0.58,0.49,0.29,0.22,0.32,0.56,0.27,0.14,0.54,0.54,0.31,0.46,0.51,0.36,0.03,0.56,0.42,0.34,0.61,0.34,0.36,0.35,0.53,0.35,0.25,0.3,0.4,0.39,0.25,0.32,0.24,0.33,0.26,0.6,0.18,0.35,0.22,0.36,0.24,0.58,0.31,0.22,0.15,0.14,0.36,0.49,0.42,0.18,0.33,0.44,0.26,0.41,0.2,0.39,0.64,0.12,0.19,0.37,0.51,0.46,0.25,0.41,0.46,0.3,0.26,0.39,0.19,0.56,0.21,0.47,0.14,0.07,0.36,0.24,0.21,0.12,0.35,0.51,0.35,0.27,0.35,0.26,0.25,0.32,0.27,0.17,0.18,0.25,0.2,0.23,0.69,0.33,0.39,0.16,0.18,0.33,0.55,0.4,0.23,0.77,0.24,0.21,0.3,0.46,0.4,0.65,0.41,0.45,0.42,0.37,0.31,0.51,0.2,0.66,0.32,0.24,0.21,0.37,0.53,0.59,0.27,0.6,0.58,0.57,0.45,0.24,0.29,0.27,0.43,0.33,0.4,0.2,0.17,0.26,0.34,0.34,0.37,0.31,0.4,0.31,0.22,0.32,0.33,0.3,0.57,0.34,0.35,0.28,0.1,0.38,0.33,0.55,0.25,0.22,0.54,0.16,0.32,0.37,0.31,0.34,0.36,0.32,0.12,0.2,0.44,0.21,0.42,0.26,0.26,0.45,0.42,0.29,0.24,0.32,0.32,0.51,0.19,0.52,0.36,0.44,0.25,0.18,0.34,0.36,0.37,0.29,0.52,0.2,0.21,0.45,0.32,0.24,0.51,0.54,0.41,0.41,0.56,0.27,0.45,0.3,0.11,0.42,0.24,0.72,0.27,0.23,0.45,0.43,0.85,0.5,0.35,0.17,0.49,0.16,0.4,0.32,0.25,0.5,0.23,0.52,0.2,0.29,0.25,0.38,0.48,0.36,0.37,0.29,0.2,0.43,0.58,0.43,0.36,0.33,0.3,0.31,0.31,0.34,0.07,0.35,0.55,0.3,0.43,0.42,0.66,0.52,0.38,0.13,0.59,0.29,0.06,0.35,0.53,0.28,0.11,0.25,0.39,0.12,0.31,0.33,0.42,0.34,0.37,0.42,0.59,0.46,0.24,0.39,0.41,0.44,0.2,0.51,0.15,0.32,0.33,0.23,0.67,0.25,0.32,0.32,0.35,0.48,0.61,0.58,0.41,0.3,0.32,0.47,0.43,0.24,0.31,0.14,0.52,0.24,0.55,0.26,0.05,0.43,0.38,0.29,0.25,0.3,0.11,0.49,0.17,0.47,0.4,0.43,0.55,0.35,0.35,0.41,0.58,0.44,0.33,0.2,0.38,0.23,0.62,0.19,0.32,0.25,0.23,0.53,0.39,0.36,0.31,0.29,0.47,0.45,0.39,0.26,0.54,0.41,0.44,0.42,0.16,0.38,0.21,0.15,0.29,0.22,0.21,0.21,0.36,0.31,0.19,0.49,0.05,0.56,0.17,0.32,0.23,0.17,0.45,0.2,0.53,0.39,0.53,0.61,0.28,0.44,0.41,0.31,0.38,0.36,0.49,0.28,0.51,0.17,0.14,0.58,0.29,0.47,0.48,0.33,0.23,0.47,0.32,0.42,0.3,0.2,0.7,0.6,0.2,0.22,0.15,0.28,0.38,0.4,0.34,0.27,0.53,0.55,0.28,0.37,0.23,0.15,0.36,0.41,0.25,0.42,0.56,0.66,0.52,0.32,0.18,0.32,0.45,0.31,0.26,0.25,0.16,0.46,0.37,0.19,0.3,0.67,0.17,0.35,0.37,0.21,0.44,0.28,0.28,0.41,0.46,0.37,0.44,0.37,0.55,0.21,0.35,0.12,0.35,0.5,0.43,0.25,0.28,0.53,0.32,0.55,0.43,0.21,0.29,0.26,0.31,0.47,0.52,0.29,0.39,0.35,0.23,0.24,0.43,0.51,0.34,0.31,0.4,0.37,0.29,0.46,0.53,0.56,0.46,0.41,0.34,0.33,0.32,0.21,0.31,0.28,0.31,0.23,0.42,0.36,0.18,0.42,0.31,0.26,0.31,0.24,0.34,0.36,0.24,0.31,0.26,0.46,0.23,0.5,0.33,0.1,0.31,0.32,0.38,0.42,0.33,0.2,0.15,0.25,0.25,0.2,0.41,0.54,0.49,0.26,0.28,0.33,0.34,0.18,0.49,0.42,0.24,0.34,0.31,0.54,0.2,0.66,0.43,0.32,0.39,0.58,0.21,0.18,0.38,0.51,0.33,0.4,0.36,0.26,0.26,0.31,0.27,0.2,0.57,0.51,0.31,0.1,0.28,0.16,0.63,0.32,0.34,0.4,0.39,0.34,0.39,0.19,0.1],[1038,810,649,1103,217,484,955,893,939,1635,849,633,1002,707,960,690,928,107,1386,990,1032,1221,659,807,330,1011,1262,463,1040,725,1079,542,1472,963,360,1590,1240,806,778,1083,795,1529,1220,1590,874,881,1062,655,1352,755,1052,1361,909,545,1783,652,1250,1050,418,1220,1506,1015,1225,716,1058,1285,926,529,1262,1159,452,769,903,927,1036,484,1132,1359,618,1603,1519,720,424,234,1178,1259,1030,1130,987,933,871,1007,730,1171,779,402,797,1298,1070,1214,783,808,845,676,1405,1037,438,1188,1122,147,648,1267,1082,254,311,511,1024,923,839,385,840,939,350,1421,1092,951,644,1663,757,629,1198,433,622,1009,607,1394,974,837,704,865,1174,1512,1347,354,837,1403,544,853,423,1043,638,1124,1038,907,1573,912,1633,1193,1192,822,414,1156,712,805,983,1652,600,658,1579,516,776,793,1380,1421,872,591,1026,609,1057,699,1537,833,651,1587,898,1345,892,358,245,687,1270,1193,474,1214,1516,633,851,1221,1037,1004,928,1479,645,1083,1090,1308,790,979,785,669,1368,523,1495,962,1066,1090,1371,969,942,1276,1462,865,842,1065,870,496,1182,750,969,1029,972,1500,1438,179,771,870,1291,678,776,1209,1220,1442,1487,1157,1330,1498,686,1089,539,1382,465,733,782,578,1095,832,1342,685,950,1373,754,798,1721,1141,581,1463,676,851,982,1367,1303,630,695,285,489,1050,2099,924,1492,1298,612,1395,1487,1557,947,1021,1294,579,1016,1113,1031,1631,1304,1701,1161,625,1403,449,366,986,1101,1145,1594,1401,1107,814,661,1352,983,861,17,881,847,667,783,1086,1371,1024,602,977,574,1000,1175,482,452,954,930,1013,416,1104,736,589,982,1570,554,615,753,1066,1548,703,1669,1032,548,589,898,921,1386,1320,1286,1050,1452,1683,1044,1013,319,866,911,1304,850,871,682,1037,1263,1465,1549,1781,1197,1428,800,766,958,639,1172,310,1413,768,1430,1160,868,182,583,761,864,1250,531,574,860,492,1061,1118,1734,1087,1021,1015,1355,812,1055,888,715,708,1189,744,822,347,1576,1044,1571,678,437,862,1070,1225,484,898,936,839,1017,590,1515,1267,846,222,968,1523,745,447,524,1369,922,1218,747,1419,851,408,1544,1105,823,1771,857,850,924,900,1080,373,739,843,871,778,769,803,1017,1493,1505,836,636,758,1475,891,491,1414,1341,840,1251,1625,990,452,1504,1177,1350,1535,589,939,858,1100,838,765,918,1222,1275,1130,700,645,727,541,1472,750,881,438,1041,455,1672,1080,781,662,585,990,1387,1027,676,1003,1468,1152,1033,334,1305,1250,423,906,700,1610,1358,528,1173,1241,1125,803,849,608,1361,1008,1516,783,607,934,734,1074,437,935,1120,1320,1020,1239,850,802,1305,812,755,245,1019,751,465,1455,1094,1038,617,655,906,1372,1092,781,1758,888,969,765,1004,1340,1548,1290,1217,1274,839,944,1336,592,1433,1283,884,927,867,1470,1245,787,1709,1489,1496,1429,975,639,692,853,1179,1128,1051,739,668,853,852,1221,1068,624,995,715,1172,1018,1020,1439,1439,1344,733,662,1362,1057,1361,957,810,1184,203,1330,636,1105,1203,944,540,384,472,1147,809,1138,575,844,1183,987,806,258,326,1258,1393,720,1358,989,966,484,144,1341,1221,1310,706,1439,739,517,1458,548,782,1091,1576,1122,1023,1411,621,1221,1169,585,917,757,1612,1043,815,1147,1429,2095,1512,1130,974,1377,725,1268,1383,1041,1279,899,1517,972,830,633,1003,1261,1115,883,763,860,1163,1482,1476,1072,1103,1031,1073,455,1342,670,1178,1480,976,1122,1179,1706,1284,1023,255,1479,945,463,927,1348,708,838,861,544,200,965,842,1245,1475,1366,1266,1459,1416,789,1288,867,808,490,1411,861,1110,692,668,1529,561,837,574,1075,1441,1464,1945,1197,1038,1245,1461,1405,876,992,683,1195,1094,1524,969,715,1136,910,1027,1187,861,735,795,882,1611,869,1189,1523,1118,979,1265,1467,1476,964,860,1380,679,1699,1040,830,688,815,1256,967,1208,727,809,1151,1057,920,1011,1341,895,936,523,258,1020,632,523,750,739,760,915,1073,1029,861,1461,738,1370,398,1000,899,733,1217,1023,1215,882,1582,1789,1020,1145,1112,1032,948,1233,1311,481,1010,455,886,1449,585,965,1732,1152,992,1178,1284,1075,998,736,2084,1360,605,699,849,970,1407,771,1114,412,1417,1314,627,1296,641,759,1102,894,952,876,1430,1682,1581,944,531,797,1123,1213,686,752,554,1104,1051,815,929,1527,369,664,1329,487,1034,906,786,1105,1253,1101,1260,1302,1337,814,953,341,990,1069,1115,1073,697,1459,969,1412,1346,693,394,944,1091,1183,1546,976,1162,842,1014,716,1302,994,871,913,1463,745,1247,1126,1567,1146,1309,701,1092,1058,644,1352,835,758,669,728,1334,1008,624,1350,1142,722,724,822,652,1236,863,780,447,1445,438,1541,700,610,1161,693,627,1465,717,731,475,927,658,729,846,1526,1142,872,1107,976,1026,823,1133,1000,1001,676,1162,1457,697,1514,1428,972,1088,1442,532,936,1180,1453,1142,1047,927,947,721,813,645,232,1776,1465,915,616,861,574,1802,849,1364,1073,953,1067,1279,394,666],[1088,860,699,1153,267,534,1005,943,989,1735,899,683,1052,757,1010,740,978,157,1486,1040,1082,1271,709,857,380,1111,1312,513,1090,775,1129,592,1572,1013,410,1690,1290,856,828,1133,845,1629,1270,1690,924,931,1112,705,1452,805,1152,1411,959,645,1883,702,1300,1100,468,1270,1606,1065,1325,766,1108,1335,976,579,1312,1209,502,819,1003,977,1086,534,1182,1409,668,1703,1619,770,474,284,1278,1309,1080,1230,1037,983,921,1057,780,1271,829,452,847,1398,1120,1264,833,858,895,726,1455,1137,488,1238,1222,197,698,1317,1182,304,361,561,1074,973,889,435,890,989,400,1471,1142,1001,694,1763,807,679,1248,483,672,1109,657,1444,1024,887,754,915,1224,1562,1397,404,887,1453,594,903,473,1143,688,1174,1088,957,1623,962,1733,1293,1292,872,464,1206,812,855,1033,1752,650,708,1679,566,826,843,1480,1521,922,641,1076,659,1107,749,1587,883,701,1687,948,1395,942,408,295,737,1320,1243,524,1264,1616,683,901,1271,1087,1054,978,1529,695,1183,1140,1358,840,1029,835,719,1418,573,1595,1012,1116,1140,1421,1069,992,1376,1512,915,892,1165,920,546,1232,800,1019,1079,1022,1600,1538,229,821,920,1341,728,826,1259,1270,1542,1587,1207,1380,1548,736,1189,589,1482,515,783,832,628,1145,882,1392,735,1050,1423,804,898,1821,1191,631,1563,726,951,1032,1467,1403,680,745,335,539,1100,2199,974,1542,1348,662,1495,1587,1657,1047,1071,1394,629,1066,1213,1081,1731,1354,1801,1261,675,1503,499,416,1086,1201,1195,1644,1451,1157,864,711,1402,1033,911,67,931,897,717,833,1136,1421,1074,652,1027,624,1050,1225,532,502,1004,1030,1063,466,1204,786,639,1032,1670,604,665,803,1116,1648,753,1769,1082,598,639,948,971,1436,1370,1386,1150,1502,1783,1094,1113,369,966,961,1404,900,921,732,1087,1313,1515,1599,1881,1297,1528,850,816,1008,689,1272,360,1513,868,1530,1210,968,232,633,811,914,1300,581,624,910,542,1161,1168,1834,1137,1121,1065,1455,862,1105,938,765,758,1239,794,872,397,1676,1094,1671,728,487,912,1120,1275,534,948,986,889,1117,640,1615,1317,896,272,1018,1573,795,497,574,1469,972,1318,797,1469,901,458,1644,1155,873,1871,907,900,974,950,1130,423,789,893,921,828,819,853,1067,1593,1555,886,686,808,1575,941,541,1514,1441,890,1301,1725,1040,502,1604,1227,1400,1635,639,1039,958,1200,888,815,968,1272,1375,1180,750,695,777,591,1572,800,931,488,1091,505,1772,1130,831,712,635,1040,1487,1077,726,1053,1518,1202,1083,384,1355,1350,473,956,750,1710,1408,578,1223,1341,1225,853,899,658,1461,1058,1566,833,657,984,784,1124,487,985,1220,1420,1070,1289,900,852,1355,862,805,295,1069,801,515,1555,1144,1088,667,705,956,1472,1142,831,1858,938,1019,815,1054,1390,1648,1340,1267,1324,889,994,1386,642,1533,1333,934,977,967,1570,1345,837,1809,1589,1596,1479,1025,689,742,953,1229,1228,1101,789,718,953,902,1271,1118,674,1045,765,1222,1068,1070,1539,1489,1394,783,712,1412,1107,1461,1007,860,1234,253,1380,686,1155,1253,994,590,434,522,1197,859,1188,625,894,1283,1087,856,308,376,1308,1443,770,1458,1039,1066,534,194,1391,1321,1360,756,1539,789,567,1558,598,832,1141,1676,1172,1073,1511,671,1271,1219,635,967,807,1712,1093,865,1197,1479,2195,1562,1230,1024,1477,775,1318,1433,1091,1379,949,1567,1022,880,683,1053,1361,1165,933,813,910,1213,1582,1526,1122,1153,1081,1123,505,1392,720,1228,1580,1026,1172,1279,1806,1334,1073,305,1579,995,513,977,1398,758,888,911,594,250,1015,942,1295,1525,1466,1316,1559,1466,839,1338,917,908,540,1511,911,1160,742,718,1629,611,887,624,1125,1541,1564,2045,1247,1088,1295,1561,1455,926,1042,733,1245,1144,1624,1019,765,1186,960,1077,1237,911,785,845,932,1661,919,1239,1573,1168,1029,1365,1567,1576,1064,910,1480,729,1799,1090,880,738,865,1356,1017,1308,777,859,1251,1107,970,1061,1441,995,986,623,308,1070,682,573,800,789,810,965,1123,1079,911,1561,788,1470,448,1050,949,783,1317,1073,1315,982,1682,1889,1070,1195,1162,1082,998,1283,1411,531,1110,505,936,1549,635,1065,1832,1202,1042,1278,1334,1125,1098,786,2184,1460,655,749,899,1020,1457,821,1214,462,1517,1414,677,1346,691,809,1202,994,1002,976,1530,1782,1681,994,581,847,1223,1263,736,802,604,1204,1101,865,979,1627,419,714,1429,537,1134,956,836,1155,1303,1151,1360,1352,1387,864,1003,391,1040,1119,1165,1123,747,1509,1019,1512,1396,743,444,994,1141,1283,1646,1026,1212,892,1064,766,1402,1094,921,963,1513,795,1297,1176,1667,1196,1359,801,1142,1158,694,1402,885,808,719,778,1434,1058,674,1400,1192,772,774,872,702,1286,913,830,497,1495,488,1591,750,660,1211,743,677,1565,767,781,525,977,708,779,946,1626,1242,922,1157,1026,1126,873,1233,1050,1051,776,1212,1557,747,1614,1478,1022,1138,1542,582,986,1230,1553,1242,1097,977,997,771,863,695,282,1876,1565,965,666,911,624,1902,899,1414,1123,1003,1117,1329,444,716],[1038,810,649,1103,217,484,955,893,939,1735,849,633,1002,707,960,690,928,107,1486,990,1032,1221,659,807,330,1111,1262,463,1040,725,1079,542,1572,963,360,1690,1240,806,778,1083,795,1629,1220,1690,874,881,1062,655,1452,755,1152,1361,909,645,1883,652,1250,1050,418,1220,1606,1015,1325,716,1058,1285,926,529,1262,1159,452,769,1003,927,1036,484,1132,1359,618,1703,1619,720,424,234,1278,1259,1030,1230,987,933,871,1007,730,1271,779,402,797,1398,1070,1214,783,808,845,676,1405,1137,438,1188,1222,147,648,1267,1182,254,311,511,1024,923,839,385,840,939,350,1421,1092,951,644,1763,757,629,1198,433,622,1109,607,1394,974,837,704,865,1174,1512,1347,354,837,1403,544,853,423,1143,638,1124,1038,907,1573,912,1733,1293,1292,822,414,1156,812,805,983,1752,600,658,1679,516,776,793,1480,1521,872,591,1026,609,1057,699,1537,833,651,1687,898,1345,892,358,245,687,1270,1193,474,1214,1616,633,851,1221,1037,1004,928,1479,645,1183,1090,1308,790,979,785,669,1368,523,1595,962,1066,1090,1371,1069,942,1376,1462,865,842,1165,870,496,1182,750,969,1029,972,1600,1538,179,771,870,1291,678,776,1209,1220,1542,1587,1157,1330,1498,686,1189,539,1482,465,733,782,578,1095,832,1342,685,1050,1373,754,898,1821,1141,581,1563,676,951,982,1467,1403,630,695,285,489,1050,2199,924,1492,1298,612,1495,1587,1657,1047,1021,1394,579,1016,1213,1031,1731,1304,1801,1261,625,1503,449,366,1086,1201,1145,1594,1401,1107,814,661,1352,983,861,17,881,847,667,783,1086,1371,1024,602,977,574,1000,1175,482,452,954,1030,1013,416,1204,736,589,982,1670,554,615,753,1066,1648,703,1769,1032,548,589,898,921,1386,1320,1386,1150,1452,1783,1044,1113,319,966,911,1404,850,871,682,1037,1263,1465,1549,1881,1297,1528,800,766,958,639,1272,310,1513,868,1530,1160,968,182,583,761,864,1250,531,574,860,492,1161,1118,1834,1087,1121,1015,1455,812,1055,888,715,708,1189,744,822,347,1676,1044,1671,678,437,862,1070,1225,484,898,936,839,1117,590,1615,1267,846,222,968,1523,745,447,524,1469,922,1318,747,1419,851,408,1644,1105,823,1871,857,850,924,900,1080,373,739,843,871,778,769,803,1017,1593,1505,836,636,758,1575,891,491,1514,1441,840,1251,1725,990,452,1604,1177,1350,1635,589,1039,958,1200,838,765,918,1222,1375,1130,700,645,727,541,1572,750,881,438,1041,455,1772,1080,781,662,585,990,1487,1027,676,1003,1468,1152,1033,334,1305,1350,423,906,700,1710,1358,528,1173,1341,1225,803,849,608,1461,1008,1516,783,607,934,734,1074,437,935,1220,1420,1020,1239,850,802,1305,812,755,245,1019,751,465,1555,1094,1038,617,655,906,1472,1092,781,1858,888,969,765,1004,1340,1648,1290,1217,1274,839,944,1336,592,1533,1283,884,927,967,1570,1345,787,1809,1589,1596,1429,975,639,692,953,1179,1228,1051,739,668,953,852,1221,1068,624,995,715,1172,1018,1020,1539,1439,1344,733,662,1362,1057,1461,957,810,1184,203,1330,636,1105,1203,944,540,384,472,1147,809,1138,575,844,1283,1087,806,258,326,1258,1393,720,1458,989,1066,484,144,1341,1321,1310,706,1539,739,517,1558,548,782,1091,1676,1122,1023,1511,621,1221,1169,585,917,757,1712,1043,815,1147,1429,2195,1512,1230,974,1477,725,1268,1383,1041,1379,899,1517,972,830,633,1003,1361,1115,883,763,860,1163,1582,1476,1072,1103,1031,1073,455,1342,670,1178,1580,976,1122,1279,1806,1284,1023,255,1579,945,463,927,1348,708,838,861,544,200,965,942,1245,1475,1466,1266,1559,1416,789,1288,867,908,490,1511,861,1110,692,668,1629,561,837,574,1075,1541,1564,2045,1197,1038,1245,1561,1405,876,992,683,1195,1094,1624,969,715,1136,910,1027,1187,861,735,795,882,1611,869,1189,1523,1118,979,1365,1567,1576,1064,860,1480,679,1799,1040,830,688,815,1356,967,1308,727,809,1251,1057,920,1011,1441,995,936,623,258,1020,632,523,750,739,760,915,1073,1029,861,1561,738,1470,398,1000,899,733,1317,1023,1315,982,1682,1889,1020,1145,1112,1032,948,1233,1411,481,1110,455,886,1549,585,1065,1832,1152,992,1278,1284,1075,1098,736,2184,1460,605,699,849,970,1407,771,1214,412,1517,1414,627,1296,641,759,1202,994,952,976,1530,1782,1681,944,531,797,1223,1213,686,752,554,1204,1051,815,929,1627,369,664,1429,487,1134,906,786,1105,1253,1101,1360,1302,1337,814,953,341,990,1069,1115,1073,697,1459,969,1512,1346,693,394,944,1091,1283,1646,976,1162,842,1014,716,1402,1094,871,913,1463,745,1247,1126,1667,1146,1309,801,1092,1158,644,1352,835,758,669,728,1434,1008,624,1350,1142,722,724,822,652,1236,863,780,447,1445,438,1541,700,610,1161,693,627,1565,717,731,475,927,658,729,946,1626,1242,872,1107,976,1126,823,1233,1000,1001,776,1162,1557,697,1614,1428,972,1088,1542,532,936,1180,1553,1242,1047,927,947,721,813,645,232,1876,1565,915,616,861,574,1902,849,1364,1073,953,1067,1279,394,666]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>id<\\/th>\\n      <th>treatment<\\/th>\\n      <th>true_ps<\\/th>\\n      <th>y_0<\\/th>\\n      <th>y_1<\\/th>\\n      <th>y_obs<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5,6]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\nAbout 23.3% of units are treated. We display below the true propensity score distributions by treatment status:\n\n\n\nThe distribution of potential outcomes Y(0) should be different across the two groups:\n\n\n\nWe can also see how the observed revenue is distributed across the two groups:\n\n\n\nWe can check whether the ATT and ATC were correctly simulated. The ATT is computed such as:\n\n\n# checking att\nmean(data$y_1[data$treatment==1]) - mean(data$y_0[data$treatment==1])\n\n\n[1] 100\n\nand the ATC:\n\n\n# checking atc\nmean(data$y_1[data$treatment==0]) - mean(data$y_0[data$treatment==0])\n\n\n[1] 50\n\nThe data have been correctly simulated.\nOutcome Regression Analysis\nBefore moving to the matching procedure, readers might be interested to see what would happen if we analyze our simulated datasets with a simple outcome regression model? Would we recover the true answer?\nWe first create a regression function to run a simple regression model where we simply regress the observed income on the treatment indicator:\n\n\noutcome_regression <- function(data) {\n  data %>%\n    lm(\n      y_obs ~ treatment,\n      data = .\n    ) %>%\n    broom::tidy(., conf.int = TRUE) %>%\n    filter(term == \"treatment\") %>%\n    select(estimate, p.value, conf.low, conf.high)\n}\n\n\n\nWe then simulate 1000 datasets of 300 units and run the regression model:\n\n\n# first simulate simulation id\ndata_sim_ex <- tibble(sim_id = 1:1000) %>%\n  # then simulate data\n  mutate(data = map(\n    sim_id,\n    ~ pmap_dfr(baseline_param_match, generate_data_matching)\n    )\n  ) %>%\n  # finally run the reg analysis\n  mutate(results = map(data, ~ outcome_regression(.)))\n\n# unnest the results\ndata_sim_ex <- data_sim_ex %>%\n  select(-data) %>%\n  unnest(results)\n\n# saveRDS(data_sim_ex, here(\"Outputs/data_sim_ex.RDS\"))\n\n\n\nWe plot the distribution of estimates:\n\n\ndata_sim_ex <- readRDS(here(\"Outputs/data_sim_ex.RDS\"))\n\ndata_sim_ex %>%\n  ggplot(., aes(x = estimate)) +\n  geom_density(colour = NA) +\n  geom_vline(xintercept = mean(data_sim_ex$estimate)) +\n  annotate(\"text\", x = 540, y = 0.009, label = \"Mean of Estimates\") + \n  annotate(\"text\", x = 125, y = 0.009, label = \"True ATT\") + \n  geom_vline(xintercept = 100, colour = \"#EAA95C\") +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  ggtitle(\"Distribution of Outcome Regression Estimates\") + \n  xlab(\"Estimates of Treatment Effect (in euros)\") + ylab(\"Density\") +\n  labs(fill = 'Status:')\n\n\n\n\nWith an outcome regression analysis, the average of estimates is equal to 499! The outcome regression analysis suffers from extrapolation bias.\nMatching Procedure\nWe now implement a simple matching where:\nWe implement below a propensity score matching procedure where:\nEach treated is matched to its most similar control unit. This is a 1:1 nearest neighbor matching without replacement.\nThe distance metric used for the matching is the propensity score.\nWe vary the matching distance (the caliper), which is expressed in standard deviation of the propensity score distribution. Lower value of the caliper implies a stricter matching procedure.\nPropensity Score Function\nWe display below the code for the function ps_function() which runs the matching procedure. It takes two inputs: (i) a dataset and (ii) the value of the caliper.\n\n\n# propensity score analysis function\nps_function <- function(data, caliper_value) {\n  # implements the propensisty score matching\n  matching_results <- matchit(\n    treatment ~ id,\n    distance = data$true_ps,\n    caliper = caliper_value,\n    data = data\n  )\n  # retrieves the matched dataset\n  data_matched <- match.data(matching_results)\n  \n  # computes the proportion of matched treated units\n  proportion_matched <-\n    sum(data_matched$treatment) / sum(data$treatment) * 100\n  \n  # compute the true causal effect for matched units\n  true_effect <-\n    mean(data_matched$y_1[data_matched$treatment == 1]) - mean(data_matched$y_0[data_matched$treatment == 1])\n  \n  # estimate the causal effect with a simple regression model\n  model_fit <- lm(y_obs ~ treatment,\n                  data = data_matched,\n                  weights = weights)\n  \n  ps_att <-\n    broom::tidy(coeftest(model_fit, vcov. = vcovCL, cluster = ~ subclass),\n                conf.int = TRUE) %>%\n    filter(term == \"treatment\") %>%\n    select(term, estimate, p.value, conf.low, conf.high)\n  \n  # return relevant statistics\n  return(\n    bind_cols(\n      ps_att,\n      proportion_matched = proportion_matched,\n      true_effect = true_effect\n    )\n  )\n}\n\n\n\nWe run the function on the dataset we previously created:\n\n\n# testing the function\nps_function(data, caliper = 0.5) %>% \n  mutate_at(vars(-term), ~ round(., 1)) %>% \n  kable(., align = c(\"l\", rep('c', 6)))\n\n\nterm\nestimate\np.value\nconf.low\nconf.high\nproportion_matched\ntrue_effect\ntreatment\n174.8\n0\n132.1\n217.5\n74.7\n100\n\nThe function returns the estimate for the ATT, the associated \\(p\\)-value and 95% confidence interval, the proportion of matched treated unit and the true value of the ATT.\nSimulations\nWe implement Monte-Carlo 300 simulations for different values of the caliper (it currently takes 24 minutes to run on a laptop computer):\n\n\nsim_matching <- tibble(sim_id = 1:1000) %>%\n  # then simulate data\n  mutate(data = map(\n    sim_id,\n    ~ pmap_dfr(baseline_param_match, generate_data_matching)\n  )) %>%\n  # generate caliper\n  crossing(caliper = c(0.01, seq(0.05, 0.4, 0.05), seq(0.4, 1, 0.1))) %>%\n  # finally run the matching analysis\n  mutate(results = map2(data, caliper, ~ ps_function(.x, .y)))\n\nsim_matching <- sim_matching %>%\n  select(-data) %>%\n  unnest(results)\n\n# saveRDS(sim_matching, here(\"Outputs/sim_matching.RDS\"))\n\n\n\nOnce the simulations have been run, we compute the summary statistics using the summarise_simulations() function. We denote \\(\\tau\\) the true value of the causal estimand and \\(\\widehat{\\tau}\\) its estimate. To illastrue the consequences of a loss of statistical power with lower values of the caliper, we compare \\(\\mathbb{E}\\left[\\left|\\frac{\\widehat{tau}}{\\tau}\\right|\\right]\\) and \\(\\mathbb{E}\\left[\\left|\\frac{\\widehat{\\tau}}{\\tau}\\right| | signif \\right]\\). The first term represents the bias and the second term represents the type M error.\n\n\n# load simulation results\nsim_matching <- readRDS(here(\"Outputs/sim_matching.RDS\"))\n\n# function to compute power, type m error and bias\nsummarise_sim_matching <- function(data) {\n  data %>%\n    mutate(significant = (p.value <= 0.05)) %>% \n    group_by(caliper) %>%\n    summarise(\n      proportion_matched = mean(proportion_matched),\n      power = mean(significant, na.rm = TRUE)*100, \n      type_m = mean(ifelse(significant, abs(estimate/true_effect), NA), na.rm = TRUE),\n      bias_signif = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup()\n} \n\n\n\nWe apply the function to data_simulations and plot the results:\n\n\n\n\n\n\nThe blue line indicates the inflation of all estimates, regardless of their statistical significance. As the value of the caliper increases, estimates are more biased: this is due to the fact that we are comparing units that are less similar. The yellow line represents the inflation of statistically significant estimates at the 5% level. We clearly see with this line the danger of editorial policies biased toward small \\(p\\)-values: with low values of the caliper, statistically significant estimates are inflated!\nWhy statistically significant estimates are inflated with low values of the caliper? The figure below gives the answer: as the value of the caliper decreases, the sample size of the matched sample is reduced and thereby the statistical power shrinks. Only large estimates can be statistically significant but these estimates are misleading.\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T19:56:58-04:00"
    },
    {
      "path": "RDD.html",
      "title": "Simulations RDD",
      "description": "In this document, we run a simulation exercise to illustrate how using a Regression Discontinuity Design (RDD) to avoid confounders may lead to a loss in power and inflated effect sizes.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSummary and intuition\nAn illustrative exampleModeling choices\nData generation\nEstimation\nOne simulation\nAll simulations\n\nAnalysis of the resultsQuick exploration\nComputing the bias and exaggeration ratio\nGraph\n\n\n\nbody {\ntext-align: justify}\nSummary and intuition\nIn the case of the RDD, the trade-off between avoiding confounding and inflated effect sizes due to low power issues is mediated by the size of the bandwidth considered in the analysis. The underlying idea is that the smaller the bandwidth, the more comparable units are and therefore the smaller the risk of confounding is. Yet, with a smaller bandwidth, sample size and thus power decrease, increasing the exaggeration ratio.\nAn illustrative example\nTo illustrate this trade-off, we consider a standard application of the RD design in economics of education where a grant or additional lessons are assigned based on the score obtained by students on a standardized test. Students with test scores below a given threshold receive the treatment while those above do not. Yet, students far above and far below the threshold may differ along unobserved characteristics such as ability. To limit this bias, the effect of the treatment is estimated by comparing the outcomes of students just below and just above this threshold. This enable to limit disparities in terms of unobserved characteristics.\nThistlewaite and Campbell (1960) introduced the concept of RDD using this type of quasi-experiment. In their paper, they take advantage of a sharp discontinuity in the assignment of an award (a Certificate of Merit) based on qualifying scores at a test. This type of analysis is still used today and many papers leveraging similar methodologies have been published since this seminal work. For instance, Jacob and Lefgren (2004) exploit this type of discontinuity to study the impact of summer school and grade retention programs on test scores. Students who score below a given score are required to attend a summer school and to retake the test. Students who do not pass the second have to repeat the grade.\nModeling choices\nIn the present analysis, we build our simulations to replicate a similar type of quasi-experiment. In our fictional example, all students scoring below a cutoff \\(C\\) in a qualification test are required to take additional lessons. We want to estimate the effect of these additional lessons on scores on a final test taken by all students a year later.\nWe assume that the final score of student \\(i\\), \\(Final_i\\), is correlated with their qualification score \\(Qual_i\\) and their treatment status \\(T_i\\), ie whether student \\(i\\) received additional lessons or not. We further assume that both qualification and final test scores are affected by students’ unobserved ability \\(U_i\\) in a non linear way.\nThe DGP can be represented using the following Directed Acyclic Graph (DAG):\n\n\n\nFinal test scores are thus defined as follows:\n\\[Final_{i} = \\alpha^{f} + \\beta T_i + \\gamma Qual_{i} +  \\delta^f f(U_i) + \\epsilon_{i}\\] Where \\(\\alpha^f\\) is a constant, \\(f\\) a non linear function and \\(e \\sim \\mathcal{N}(0, \\sigma_{e})\\) noise. The parameter of interest is \\(\\beta\\). Translating this into a potential outcomes framework, we have:\n\\(Final_i(0) = \\alpha^f + \\gamma Qual_{i} + \\delta^f f(U_i) + \\epsilon_{i}\\)\n\\(Final_i(1) = \\alpha^f + \\gamma Qual_{i} + \\beta + \\delta^f f(U_i) + \\epsilon_{i}\\)\nTo simplify, we consider the following assumptions:\nFull compliance and a sharp treatment allocation such that \\(T_i = \\mathbb{I}[Qual_{i} < C]\\). All students with a qualification score below the threshold are treated and receive additional lessons. None of the students with a qualification score above the threshold are treated.\nThe unobserved ability affects qualification and final test scores in a cubic way. A large ability has a strong positive impact on test scores. Similarly a particularly low ability strongly impacts test scores negatively. An average ability does not have much impact on test scores. Such a functional form seems realistic. Note that ability creates an OVB only if it has a non linear impact on test scores.\nWe assume constant treatment effects. This assumption is not necessary and our results hold if we consider non-constant treatment effects. We thus may drop this assumption in the future.\nWe assume that the unobserved availability affects the qualification and final score in a similar way and therefore with the same intensity \\(\\delta\\). However, since the unobserved ability affects the final score through the qualification score, we adjust for that so that the ability has actually the same effect on both test scores. As a consequence, \\(\\delta^f= \\delta \\times (1 - \\gamma)\\).\nMore precisely, we set:\n\\(N\\) the number of students\n\\(U \\sim \\mathcal{U}(-b_u, b_u)\\) the unobserved ability.\n\\(Qual_i = \\alpha^q + \\delta U_i^{3} + e^q_i\\) where \\(e^q \\sim \\mathcal{N}(0, \\sigma_q^{2})\\)\n\\(T_i = \\mathbb{I}[Qual_{i} < q_c]\\) where for now and for simplicity, \\(q_c\\) is a fixed grade threshold given as the quantile in the qualification score distribution.\n\\(e^f \\sim \\mathcal{N}(0, \\sigma_f^2)\\)\n\\(Final_{i} = \\alpha^f + \\beta T_i + \\gamma Qual_{i} + \\delta^f U_i^{3} + e^f_{i}\\) (where \\(\\delta^f = \\delta (1-\\gamma)\\))\nData generation\nGenerating function\nWe write a simple function that generates the data. It takes as input the values of the different parameters and returns a data frame containing all the variables for this analysis.\nOnce the fake data is generated, to make things more realistic we consider our data as if it was actual data. We do not take advantage of our knowledge of the data generating process in the estimation procedure. However, we observe both potential outcomes and the unobserved ability. Note that, in a real world setting, one would generally know the value of the threshold (and thus of \\(q_c\\)). Based on that and to simplify the computation of the bandwidth, we store \\(q_c\\).\n\n\ngenerate_data_RDD <- function(N, \n                              bound_u,\n                              alpha_q, \n                              sigma_q, \n                              sigma_f, \n                              alpha_f, \n                              beta,\n                              gamma,\n                              delta,\n                              q_c) {\n  \n  data <- tibble(id = 1:N) %>% \n    mutate(\n      u = runif(nrow(.), -bound_u, bound_u),\n      e_q = rnorm(nrow(.), 0, sigma_q),\n      qual = alpha_q + delta*u^3 + e_q,\n      e_f = rnorm(nrow(.), 0, sigma_f),\n      treated = qual < quantile(qual, q_c),\n      final0 = alpha_f + gamma*qual + delta*(1-gamma)*u^3 + e_f,\n      final1 = final0 + beta,\n      final = final0 + beta*treated,\n      q_c = q_c\n    )\n}\n\n\n\nDefining the bandwidth\nIn a RDD, the model is estimated only for observations close enough to the threshold, ie in a given bandwidth. We therefore create a function to define this bandwidth by adding a variable to the data set treated_bw that is equal to NA if the observations is outside of the bandwidth, TRUE if the observation falls in the bandwidth and the student is treated and FALSE if the observation falls in the bandwidth and the student is not treated. The bandwidth parameter bw represents the proportion of units that are in the bandwidth. If bw = 0.1, 10% of the students are in the bandwidth for instance.\n\n\ndefine_bw <- function (data, bw) {\n  data <- data %>% \n    mutate(\n      treated_bw = ifelse(\n        dplyr::between(\n          qual, \n          quantile(qual, unique(q_c) - bw/2), \n          quantile(qual, unique(q_c) + bw/2)\n        ), \n        treated, \n        NA\n      )\n    )\n} \n\n\n\nBaseline parameters’ values\nWe set baseline values for the parameters to emulate a somehow realistic observational study in this field. We make the following assumptions:\nWe assumes that grades are SAT scores. One can think of the qualifying exam as a state level exam that gives the opportunity to students with lower grades to receive additional lessons. For simplicity, we assume that the scores have a mean of 1060 and standard error of 200 (based on statistics provided by the Department of Education). Since these scores depend on the unobserved ability, we adjust the values of the parameters to get appropriate distributions.\nTypical treatment effect sizes in economics of education are of the order of magnitude of 0.1 sd. Kraft 2020, reviewing 747 RCTs of education intervention finds that the median effect size is 0.1 sd. Interestingly, he finds that “larger studies with broad achievement measures have systematically smaller effect sizes”. This might hint to publication bias as he underlines. In studies with more than 2000 individuals, the median effect is 0.03 sd. The same median effect size is observed in preregistered studies. We therefore consider an effect size of 0.03 sd, ie \\(\\beta = 6 = 200\\times 0.03\\).\nWe assume that the unobserved ability is uniformly distributed between -2.5 and 2.5. We chose this values because it produces the right relationships between the variables.\nWe consider that the threshold is located at the center of the distribution (\\(q_c = 0.5\\)). The bandwidth is symmetric around the cutoff. Considering a cutoff in the middle of the distribution enables us to consider very wide bandwidths, up to including the whole sample in the analysis. Based on the functional form chosen for the effect of \\(U\\) on grades (\\(f: U \\mapsto U^3\\)), choosing a cutoff in the middle of the distribution enables to have units that are relatively similar in terms of unobserved variable close to the cut-off and different far away from it.\nThe set of parameters may produce test score outside of the range 0-100 in some iterations but that does not affect the analysis. We add the parameter value for delta separately as we will vary the value later and will reuse the vector baseline_param_RDD.\n\nN\nbound_u\nalpha_q\nsigma_q\nsigma_f\nalpha_f\nbeta\ngamma\nq_c\ndelta\n10000\n2.5\n1060\n100\n80\n540\n6\n0.5\n0.5\n30\n\nHere is an example of data created with our data generating process:\n\nid\nu\ne_q\nqual\ne_f\ntreated\nfinal0\nfinal1\nfinal\nq_c\n1\n2.0779949\n-79.70242\n1249.4850\n-4.548884\nFALSE\n1294.7873\n1300.7873\n1294.7873\n0.5\n2\n0.6324039\n6.51651\n1074.1041\n16.765798\nFALSE\n1097.6117\n1103.6117\n1097.6117\n0.5\n3\n-1.2121860\n10.68097\n1017.2456\n69.341049\nTRUE\n1091.2461\n1097.2461\n1097.2461\n0.5\n4\n-1.1414686\n-46.58832\n968.7934\n21.039500\nTRUE\n1023.1270\n1029.1270\n1029.1270\n0.5\n5\n-1.8997477\n-159.37910\n694.9329\n-5.346115\nTRUE\n779.2763\n785.2763\n785.2763\n0.5\n6\n0.0908274\n-40.97945\n1019.0430\n40.875984\nTRUE\n1090.4087\n1096.4087\n1096.4087\n0.5\n7\n-0.0649454\n-132.41446\n927.5773\n-60.113724\nTRUE\n943.6708\n949.6708\n949.6708\n0.5\n8\n1.5960237\n-36.34014\n1145.6260\n-19.746879\nFALSE\n1154.0492\n1160.0492\n1154.0492\n0.5\n9\n2.0110618\n69.80429\n1373.8086\n36.908192\nFALSE\n1385.8146\n1391.8146\n1385.8146\n0.5\n10\n1.3556211\n28.66920\n1163.4063\n27.404462\nFALSE\n1186.4762\n1192.4762\n1186.4762\n0.5\n\nWe check the standard deviation and means of the generated exam scores to make sure that they correspond to w to make:\n\nStatistic\nqual\nfinal0\nMean\n1060.5111\n1071.1901\nStandard Deviation\n205.6935\n202.5777\n\nExploring the data generated\nThe following graph illustrates this process by plotting final test scores against qualification ones depending on the value of treated_bw.\n\n\n\nThen, we quickly look at the distributions of the different variables to check that they have a shape similar to what we expect.\n\n\n\nWe then look at relation between the qualifying score and the unobserved ability. This enables us to understand how where the bias comes form:\n\n\n\nEstimation\nAfter generating the data, we can run an estimation.\nNote that to run power calculations, we need to have access to the true effects. Therefore, before running the estimation, we write a short function to compute the average treatment effect on the treated (ATET). We will add this information to the estimation results.\n\n\ncompute_true_effect_RDD <- function(data) {\n  treated_data <- data %>% \n    filter(treated) \n  return(mean(treated_data$final1 - treated_data$final0))\n}  \n\n\n\nWe then run the estimation. To do so, we only consider observations within the bandwidth and regress the final test scores on the treatment, the qualification score and their interaction. Note that we include this interaction term to allow more flexibility and to mimic an realistic estimation. Yet, we know that this interaction term does not appear in the DGP. Including it or not do not change the results. Also note that, of course, we do not include the unobserved ability in this model to create an OVB.\n\n\nestimate_RDD <- function(data, bw) {\n  data_in_bw <- data %>% \n    define_bw(bw = bw) %>% \n    filter(!is.na(treated_bw))\n  \n  reg <- lm(\n    data = data_in_bw, \n    formula = final ~ treated + qual\n  ) %>% \n    broom::tidy() %>%\n    filter(term == \"treatedTRUE\") %>%\n    rename(p_value = p.value, se = std.error) %>%\n    select(estimate, p_value, se) %>%\n    mutate(\n      true_effect = compute_true_effect_RDD(data),\n      bw = bw\n    )\n  \n  return(reg)\n}\n\n\n\nOne simulation\nWe can now run a simulation, combining generate_data_RDD and estimate_RDD. To do so we create the function compute_sim_RDD. This simple function takes as input the various parameters along with a vector of bandwidth sizes, vect_bw. If we want to run several simulations with different bandwidths, we can reuse the same data, hence why we allow to passing a vector of bandwidths and not only one bandwidth. The function returns a table with the estimate of the treatment, its p-value and standard error, the true effect and the bandwidth and intensity of the OVB considered (delta). Note for now, that we do not store the values of the other parameters for simplicity because we consider them fixed over the study.\n\n\ncompute_sim_RDD <- function(N,\n                            bound_u,\n                            alpha_q,\n                            sigma_q,\n                            sigma_f,\n                            alpha_f,\n                            beta,\n                            gamma,\n                            delta,\n                            q_c,\n                            vect_bw) {\n  \n  data <- generate_data_RDD(\n    N = N,\n    bound_u = bound_u,\n    alpha_q = alpha_q,\n    sigma_q = sigma_q,\n    sigma_f = sigma_f,\n    alpha_f = alpha_f,\n    beta = beta,\n    gamma = gamma,\n    delta = delta,\n    q_c = q_c\n  ) \n  \n  map_dfr(vect_bw, estimate_RDD, data = data) %>%\n    mutate(delta = delta)\n} \n\n\n\nHere is an example of an output of this function.\n\nestimate\np_value\nse\ntrue_effect\nbw\ndelta\n4.412760\n0.6939302\n11.210111\n6\n0.1\n30\n8.641417\n0.2654314\n7.757401\n6\n0.2\n30\n\nAll simulations\nWe will run the simulations for different sets of parameters by mapping our compute_sim_RDD function on each set of parameters. We thus create a table with all the values of the parameters we want to test param_rdd. Note that in this table each set of parameters appears n_iter times as we want to run the analysis \\(n_{iter}\\) times for each set of parameters.\n\n\n# simple_param_RDD <- tibble(\n#   N = 1000,\n#   bound_u = 1,\n#   alpha_q = 0,\n#   sigma_q = 1,\n#   sigma_f = 0.5,\n#   alpha_f = 1,\n#   beta = 0.7,\n#   gamma = 0.7,\n#   q_c = 0.5,\n#   delta = 3,\n#   vect_bw = 0.1\n# )\n\nfixed_param_RDD <- baseline_param_RDD %>% #%>% rbind(...)\n  mutate(vect_bw = 0.1)\n# vect_bw <- seq(0.05, 0.4, 0.05)\nvect_bw <- c(seq(0.1, 0.4, 0.05), seq(0.4, 0.9, 0.1))\n# vect_delta <- c(3)\nn_iter <- 1000\n\nparam_rdd <- fixed_param_RDD %>% \n  select(-vect_bw) %>% #parameters we modify\n  # crossing(delta = vect_delta) %>% \n  mutate(vect_bw = list(vect_bw)) %>% \n  crossing(rep_id = 1:n_iter) %>% \n  select(-rep_id)\n\n\n\nWe then run the simulations by mapping our compute_sim_RDD function on param_rdd.\n\n\ntic()\nsim_rdd <- pmap_dfr(param_rdd, compute_sim_RDD)\nbeep()\ntoc()\n\n# saveRDS(sim_rdd, here(\"Outputs/sim_rdd.RDS\"))\n\n\n\nAnalysis of the results\nQuick exploration\nFirst, we quickly explore the results. In the following figure, we can see that for small bandwidth estimates are unbiased but imprecise while for large bandwidths estimates are precise but biased.\n\n\n\nWhen the bandwidth is relatively small, estimates are spread out and the mean of statistically significant estimates is larger than the true effect. Note that the average of all estimates, significant and non-significant, is close to the true effect. Applying a statistical significance filter leads to overestimate the true effect in this case.\n\n\n\nComputing the bias and exaggeration ratio\nWe want to compare \\(\\mathbb{E}\\left[\\frac{\\widehat{\\beta_{RDD}}}{\\beta_0}\\right]\\) and \\(\\mathbb{E}\\left[\\frac{\\widehat{\\beta_{RDD}}}{\\beta_0} | \\text{signif} \\right]\\). The first term represents the bias and the second term represents the exaggeration ratio. This terms depend on the true effect size. To enable comparison across simulations and getting terms independent of effect sizes, we also compute the average of the ratios between the estimate and the true effect, conditional on significance.\n\n\nsummarise_simulations <- function(data) {\n  data %>%\n    mutate(significant = (p_value <= 0.05)) %>% \n    group_by(delta, bw) %>%\n    summarise(\n      power = mean(significant, na.rm = TRUE)*100, \n      type_m = mean(ifelse(significant, estimate/true_effect, NA), na.rm = TRUE),\n      bias_all = mean(estimate/true_effect, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup()\n}\n\nsummary_sim_rdd <- summarise_simulations(sim_rdd)\n# saveRDS(summary_sim_rdd, here(\"Outputs/summary_sim_rdd.RDS\"))\n\n\n\nGraph\nTo analyze our results, we build a unique and simple graph:\n\n\n\nWe notice that, the smaller the bandwidth size, the closer the average of all estimates is to the true effect. Yet, when the bandwidth gets small significant estimates overestimate the true effect. This arises because of a loss of power, as shown in the graph below.\n\n\n\nWe can then look in more details to the distribution of the estimates for different bandwidths. Statistically significant estimates, when power is low (ie when the bandwidth is small) are located in the tail of the distribution all estimates that is itself centered around the true effect.\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T19:54:59-04:00"
    },
    {
      "path": "reporting.html",
      "title": "Computing and reporting power calculations",
      "description": "Under construction. In this document, we will discuss and illustrate how to run power calculations.",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPost estimation analysis\n\n\nbody {\ntext-align: justify}\nPost estimation analysis\nLet’s focus on the example of described for the RDD simulations, studying the impact of a school teaching program on student final scores. Assume that using real world data, we find an estimate of the treatment effect to be equal to 0.22 with standard deviation of 0.2. We want to compute what could be the power and exaggeration. These values depend on the true effect size. We therefore compute them for a range of credible true effect sizes. Another way to look at the problem is to wonder whether, if the true effect was smaller, the design of this study would be “good enough” to detect an effect and by how much we can expect the estimate to be inflated.\nReplicating the analysis with the same design would yield an estimate with a similar standard error as the original study. We therefore postulate different true effect sizes and feed them to retrodesign:\n\n\nse <- 0.2\n\nretro <- retrodesign::retro_design(as.list(seq(0.05, 0.4, by = 0.01)), se) %>%\n  unnest(cols = c(effect_size, power, type_s, type_m)) %>%\n  select(-type_s) %>% \n  mutate(power = power * 100) %>%\n  rename(\n    \"Statistical Power (%)\" = power,\n    \"Type-M Error (Exaggeration Ratio)\" = type_m\n  ) %>%\n  pivot_longer(\n    cols = -c(effect_size),\n    names_to = \"statistic\",\n    values_to = \"value\"\n  )\n\n\n\nWe can then build simple graphs representing what would be the power and exaggeration ratio for a range of hypothetical true effect sizes:\n\n\nretro %>% \n  ggplot(aes(x = effect_size, y  = value)) +\n  geom_line(size = 1.1) +\n  facet_wrap( ~ statistic, scales = \"free\") +\n  # geom_vline(aes(xintercept = 0.4)) +\n  geom_vline(aes(xintercept = 0.22)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 7)) +\n  labs(\n    title = \"Evolution of power and exaggeration with true effect size\",\n    x =\"Hypothetical True Effect Size\",\n    y = \"\",\n    caption = paste(\"Standard error =\", se)\n  )\n\n\n\n\n\n\n\n",
      "last_modified": "2022-03-08T17:07:32-05:00"
    },
    {
      "path": "summary.html",
      "title": "Summaries",
      "description": "This page gathers a set of summaries intended for different audiences.\n",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://vincentbagilet.github.io/"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPlain language summary\nA Twitter summary\nAbstract\n\nPlain language summary\nIn this paper, we show that, combined with current academic publication practices, front line empirical methods, efficient to identify how a factor causes another, may be more likely to exaggerate the size of the effect of interest.\nEmpirical studies often aim to get a sense of how a factor causes another. For instance, one may want to evaluate the impact of a professional training program on wages. Such effects are often challenging to estimate. A simple difference between the wages of people who participated in the program or not may not reflect the actual wage increase brought by the program. It might be the case that people who participated in the program would have earned higher wages even if they did not take the training. To measure the actual magnitude of the effect of the program, researchers use a particular set of methods. These methods while convincing may be imprecise: they can produce results that are far away from the true effect. \nOn the other hand, previous research has shown that publication practices favor results that are very likely different from zero. If the true effect is close to zero a published result will likely be far away from zero. If the study is imprecise, it will also be far away from the true effect. Publication practices will make this result more likely to be published. The publish result will be far away from the true effect: it will exaggerate it. \nThe set of methods mentioned above enable to convincingly measure the effect of a factor on another. However, they are also more subject to the publication problem and may be more likely to exaggerate effect sizes. In this paper, we show that there is a trade-off between these two aspects.\nTo do so we build simulations, generating fake data representative of real life situations. We have to rely on simulations because to evaluate how far the result of an analysis is from the true effect, one needs to know this true effect. In real life cases, the true effect is never known.\nTo avoid published effects to exaggerate true effect sizes, we advocate computing and reporting a very simple calculation that may help evaluate the risk of exaggeration.\n\n\n\n\n\n\n\n\n\nA Twitter summary\nTweet 1/N\nWe published a working paper arguing that causal inference methods create a trade-off between confounding and exaggerating true effect sizes.\nThe same aspect that makes causal identification strategies credible can create another type of bias.\nTweet 2/N\nWhen power is low, the distribution of estimates is spread out. Only estimates that are 2 sd away from 0 are significant. Significant estimates overestimate the true effect size.\n\n\n\nTweet 3/N\nCausal id strat throw out part of the variation, reducing power, leading significant estimates to exaggerate true effects sizes. We build fake data MC simulations to illustrate this.\nTweet 4/N\nRDD discards variation, only considering observations within the bandwidth, decreasing the effective sample size.\nOn average significant estimates may never get close to the true effect.\n\n\n\nTweet 5/N\nIV only uses part of the variation in the treatment, the portion explained by the instrument. When the “strength” of the instrument is low, the IV is imprecise.\nA “naive” OLS can, on average, produce significant estimates that are closer to the true effect than the IV.\n\n\n\nTweet 6/N\nIn DiD event studies, the variation used to identify an effect sometimes only comes from a limited number of treated observations. Power can thus be low.\n\n\n\nTweet 7/N\nMatching prunes treated units that cannot be matched to untreated ones, reducing the effective sample size.\nOn average significant estimates may never get close to the true effect.\n\n\n\nTweet 8/N\nA systematic reporting of pre and post analysis power calculations in observational studies would help gauge the risk of falling into this low power trap.\nTweet N/N\nThe paper summed up in a picture:\n\n\n\nAbstract\nConvincing research designs make empirical economics credible. To avoid confounding, quasi-experimental studies focus on specific sources of variation. This often leads to a reduction in statistical power. Yet, published estimates can overestimate true effects sizes when power is low. Using fake data simulations, we show that for all causal inference methods, there can be a trade-off between confounding and exaggerating true effect sizes due to a loss in power. We then discuss how reporting power calculations could help address this issue.\n\n\n\n",
      "last_modified": "2022-04-04T20:09:57-04:00"
    }
  ],
  "collections": []
}
